{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7104655,"sourceType":"datasetVersion","datasetId":4095790},{"sourceId":9626459,"sourceType":"datasetVersion","datasetId":5876191},{"sourceId":10410576,"sourceType":"datasetVersion","datasetId":6451663},{"sourceId":10461904,"sourceType":"datasetVersion","datasetId":6476936}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Analisi di Dataset e Task","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"Configurazioni preliminari.","metadata":{}},{"cell_type":"code","source":"!pip install datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:36:07.815362Z","iopub.execute_input":"2025-01-22T16:36:07.815652Z","iopub.status.idle":"2025-01-22T16:36:11.335436Z","shell.execute_reply.started":"2025-01-22T16:36:07.815628Z","shell.execute_reply":"2025-01-22T16:36:11.334226Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (18.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\nRequirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from datasets import load_dataset\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:36:11.336957Z","iopub.execute_input":"2025-01-22T16:36:11.337273Z","iopub.status.idle":"2025-01-22T16:36:12.721105Z","shell.execute_reply.started":"2025-01-22T16:36:11.337248Z","shell.execute_reply":"2025-01-22T16:36:12.720341Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## Benchmarck GLUE\n\nGLUE, **General Language Understanding Evaluation**, è un benchmark progettato per valutare le capacità di comprensione del linguaggio naturale dei LLM. Include una raccolta di **nove** compiti di comprensione di frasi in inglese che coprono una grande varietà di domini linguistici e task. ","metadata":{}},{"cell_type":"markdown","source":"### 1. CoLA\nIl dataset CoLA (Corpus of Linguistic Acceptability) permette di valutare la capacità di un modello di distinguere tra frasi linguisticamente accettabili e non accettabili in inglese.\n\n**Caratteristiche del dataset**  \n\n**Task**:  Accettabilità linguistica.   \n       Valutare se una frase è grammaticalmente e sintatticamente corretta secondo i principi della lingua inglese.  \n       \n**Tipo di task**:  Classificazione binaria. Ogni frase è etichettata come grammaticalmente accettabile o non accettabile.  \n\n**Dominio**:  Le frasi provengono da diversi domini.  \n\n**Struttura del dataset**:  Ogni esempio contiene:  \n                        - sentence: la frase in lingua inglese da analizzare.  \n                        - label: etichetta binaria pari a 1 se la frase è accettabile o a 0 se non è accettabile.  \n                        - idx: indice identificativo dell'esempio. \n\n**Nota bene**\n\nClassi sbilanciate\nLa metrica principale per CoLA è il Matthew's Correlation Coefficient (MCC), preferito all' accuratezza visto che le classi sono sbilanciate.\nIl test set cotiene solo etichette pari a -1","metadata":{}},{"cell_type":"code","source":"# Ottenimento del dataset\n\ncola_dataset = load_dataset(\"glue\", \"cola\")\n\nprint(cola_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:36:12.722649Z","iopub.execute_input":"2025-01-22T16:36:12.723113Z","iopub.status.idle":"2025-01-22T16:36:15.510493Z","shell.execute_reply.started":"2025-01-22T16:36:12.723060Z","shell.execute_reply":"2025-01-22T16:36:15.509541Z"}},"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['sentence', 'label', 'idx'],\n        num_rows: 8551\n    })\n    validation: Dataset({\n        features: ['sentence', 'label', 'idx'],\n        num_rows: 1043\n    })\n    test: Dataset({\n        features: ['sentence', 'label', 'idx'],\n        num_rows: 1063\n    })\n})\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"def analyze_data(name, data, target):\n    \n    print(f\"--- Analisi {name} ---\")\n    \n    df = pd.DataFrame(data)\n    \n    # Dimensioni\n    print(f\"Numero di esempi nel {name}: {len(df)}\\n\")\n    \n    # Prime righe\n    print(\"Prime 5 righe:\")\n    print(df.head(), \"\\n\")\n    \n    # Dati mancanti\n    print(\"Dati mancanti per colonna:\")\n    print(df.isnull().sum(), \"\\n\")\n    \n    \n    # Distribuzione delle etichette\n    print(\"Distribuzione delle classi:\")\n    label_counts = df[target].value_counts()\n    label_percentages = (label_counts / len(df)) * 100\n    summary_table = pd.DataFrame({\n        'Classe': label_counts.index,\n        'Conteggio': label_counts.values,\n        'Percentuale': label_percentages.values\n    })\n    print(summary_table, \"\\n\\n\")\n    \n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:36:15.511891Z","iopub.execute_input":"2025-01-22T16:36:15.512194Z","iopub.status.idle":"2025-01-22T16:36:15.517751Z","shell.execute_reply.started":"2025-01-22T16:36:15.512167Z","shell.execute_reply":"2025-01-22T16:36:15.516854Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train_data = cola_dataset[\"train\"]\nval_data = cola_dataset[\"validation\"]\ntest_data = cola_dataset[\"test\"]\n\nprint(\"--- Dimensioni del dataset ---\")\nprint(f\"Train set: {len(train_data)} esempi\")\nprint(f\"Validation set: {len(val_data)} esempi\")\nprint(f\"Test set: {len(test_data)} esempi\")\nprint(f\"Totale: {len(train_data) + len(val_data) + len(test_data)} esempi\\n\")\n\n# Analisi dei tre split del dataset\nanalyze_data(\"Train\", train_data, \"label\")\nanalyze_data(\"Validation\", val_data, \"label\")\nanalyze_data(\"Test\", test_data, \"label\")\nprint('')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:36:15.518564Z","iopub.execute_input":"2025-01-22T16:36:15.518883Z","iopub.status.idle":"2025-01-22T16:36:15.918189Z","shell.execute_reply.started":"2025-01-22T16:36:15.518859Z","shell.execute_reply":"2025-01-22T16:36:15.917202Z"}},"outputs":[{"name":"stdout","text":"--- Dimensioni del dataset ---\nTrain set: 8551 esempi\nValidation set: 1043 esempi\nTest set: 1063 esempi\nTotale: 10657 esempi\n\n--- Analisi Train ---\nNumero di esempi nel Train: 8551\n\nPrime 5 righe:\n                                            sentence  label  idx\n0  Our friends won't buy this analysis, let alone...      1    0\n1  One more pseudo generalization and I'm giving up.      1    1\n2   One more pseudo generalization or I'm giving up.      1    2\n3     The more we study verbs, the crazier they get.      1    3\n4          Day by day the facts are getting murkier.      1    4 \n\nDati mancanti per colonna:\nsentence    0\nlabel       0\nidx         0\ndtype: int64 \n\nDistribuzione delle classi:\n   Classe  Conteggio  Percentuale\n0       1       6023    70.436206\n1       0       2528    29.563794 \n\n\n--- Analisi Validation ---\nNumero di esempi nel Validation: 1043\n\nPrime 5 righe:\n                                            sentence  label  idx\n0    The sailors rode the breeze clear of the rocks.      1    0\n1  The weights made the rope stretch over the pul...      1    1\n2         The mechanical doll wriggled itself loose.      1    2\n3        If you had eaten more, you would want less.      1    3\n4           As you eat the most, you want the least.      0    4 \n\nDati mancanti per colonna:\nsentence    0\nlabel       0\nidx         0\ndtype: int64 \n\nDistribuzione delle classi:\n   Classe  Conteggio  Percentuale\n0       1        721    69.127517\n1       0        322    30.872483 \n\n\n--- Analisi Test ---\nNumero di esempi nel Test: 1063\n\nPrime 5 righe:\n                                            sentence  label  idx\n0                      Bill whistled past the house.     -1    0\n1              The car honked its way down the road.     -1    1\n2                    Bill pushed Harry off the sofa.     -1    2\n3               the kittens yawned awake and played.     -1    3\n4  I demand that the more John eats, the more he ...     -1    4 \n\nDati mancanti per colonna:\nsentence    0\nlabel       0\nidx         0\ndtype: int64 \n\nDistribuzione delle classi:\n   Classe  Conteggio  Percentuale\n0      -1       1063        100.0 \n\n\n\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"### 2. SST-2\nIl dataset SST-2 (Stanford Sentiment Treebank 2) contiene recensioni di film annotate con sentiment positivo e negativo. \n\n**Caratteristiche del dataset**  \n\n**Task**:  Sentiment analisys.   \n         Valutare se una recensione esprime un sentimento positivo o negativo. \n       \n**Tipo di task**:  Classificazione binaria. Ogni frase è etichettata come positiva (1) o negativa (0).\n\n**Dominio**:  Le frasi provengono da recensioni cinematografiche\n\n**Struttura del dataset**:  Ogni esempio contiene:  \n                        - sentence: la recensione in lingua inglese da analizzare.  \n                        - label: etichetta binaria pari a 1 se il sentiment è positivo o a 0 se è negativo.  \n                        - idx: indice identificativo dell'esempio. \n\n**Nota bene**\n- Classi bilanciate\n- Il test set cotiene solo etichette pari a -1","metadata":{}},{"cell_type":"code","source":"# Ottenimento del dataset\n\nsst2_dataset = load_dataset(\"glue\", \"sst2\")\n\nprint(sst2_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:36:15.919203Z","iopub.execute_input":"2025-01-22T16:36:15.919651Z","iopub.status.idle":"2025-01-22T16:36:17.121920Z","shell.execute_reply.started":"2025-01-22T16:36:15.919610Z","shell.execute_reply":"2025-01-22T16:36:17.120959Z"}},"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['sentence', 'label', 'idx'],\n        num_rows: 67349\n    })\n    validation: Dataset({\n        features: ['sentence', 'label', 'idx'],\n        num_rows: 872\n    })\n    test: Dataset({\n        features: ['sentence', 'label', 'idx'],\n        num_rows: 1821\n    })\n})\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"train_data = sst2_dataset[\"train\"]\nval_data = sst2_dataset[\"validation\"]\ntest_data = sst2_dataset[\"test\"]\n\nprint(\"--- Dimensioni del dataset ---\")\nprint(f\"Train set: {len(train_data)} esempi\")\nprint(f\"Validation set: {len(val_data)} esempi\")\nprint(f\"Test set: {len(test_data)} esempi\")\nprint(f\"Totale: {len(train_data) + len(val_data) + len(test_data)} esempi\\n\")\n\n# Analisi dei tre split del dataset\nanalyze_data(\"Train\", train_data, \"label\")\nanalyze_data(\"Validation\", val_data, \"label\")\nanalyze_data(\"Test\", test_data, \"label\")\nprint('')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:36:17.122839Z","iopub.execute_input":"2025-01-22T16:36:17.123161Z","iopub.status.idle":"2025-01-22T16:36:19.219843Z","shell.execute_reply.started":"2025-01-22T16:36:17.123125Z","shell.execute_reply":"2025-01-22T16:36:19.218539Z"}},"outputs":[{"name":"stdout","text":"--- Dimensioni del dataset ---\nTrain set: 67349 esempi\nValidation set: 872 esempi\nTest set: 1821 esempi\nTotale: 70042 esempi\n\n--- Analisi Train ---\nNumero di esempi nel Train: 67349\n\nPrime 5 righe:\n                                            sentence  label  idx\n0       hide new secretions from the parental units       0    0\n1               contains no wit , only labored gags       0    1\n2  that loves its characters and communicates som...      1    2\n3  remains utterly satisfied to remain the same t...      0    3\n4  on the worst revenge-of-the-nerds clichés the ...      0    4 \n\nDati mancanti per colonna:\nsentence    0\nlabel       0\nidx         0\ndtype: int64 \n\nDistribuzione delle classi:\n   Classe  Conteggio  Percentuale\n0       1      37569    55.782565\n1       0      29780    44.217435 \n\n\n--- Analisi Validation ---\nNumero di esempi nel Validation: 872\n\nPrime 5 righe:\n                                            sentence  label  idx\n0    it 's a charming and often affecting journey .       1    0\n1                 unflinchingly bleak and desperate       0    1\n2  allows us to hope that nolan is poised to emba...      1    2\n3  the acting , costumes , music , cinematography...      1    3\n4                  it 's slow -- very , very slow .       0    4 \n\nDati mancanti per colonna:\nsentence    0\nlabel       0\nidx         0\ndtype: int64 \n\nDistribuzione delle classi:\n   Classe  Conteggio  Percentuale\n0       1        444    50.917431\n1       0        428    49.082569 \n\n\n--- Analisi Test ---\nNumero di esempi nel Test: 1821\n\nPrime 5 righe:\n                                            sentence  label  idx\n0             uneasy mishmash of styles and genres .     -1    0\n1  this film 's relationship to actual tension is...     -1    1\n2  by the end of no such thing the audience , lik...     -1    2\n3  director rob marshall went out gunning to make...     -1    3\n4  lathan and diggs have considerable personal ch...     -1    4 \n\nDati mancanti per colonna:\nsentence    0\nlabel       0\nidx         0\ndtype: int64 \n\nDistribuzione delle classi:\n   Classe  Conteggio  Percentuale\n0      -1       1821        100.0 \n\n\n\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"### 3. MRPC \nIl dataset MRPC (Microsoft Research Paraphrase Corpus) permette di valutare la capacità di un modello di distinguere tra coppie di frasi che esprimono lo stesso significato (parafrasi) e coppie di frasi che non lo fanno.  \n\n**Caratteristiche del dataset**  \n\n*Task*: Identificazione delle parafrasi.  \nDeterminare se due frasi esprimono lo stesso significato.  \n\n*Tipo di task*: Classificazione binaria. Ogni coppia di frasi è etichettata come parafrasi (1) o non parafrasi (0).  \n\n*Dominio*: Le coppie di frasi provengono da notizie online, come articoli di MSN e CNN.  \n\n*Struttura del dataset*: Ogni esempio contiene:  \n- sentence1: la prima frase della coppia.  \n- sentence2: la seconda frase della coppia.  \n- label: etichetta binaria pari a 1 se le frasi sono parafrasi o a 0 se non lo sono.  \n- idx: indice identificativo dell'esempio.  \n\n\n**Nota bene**  \n- Classi sbilanciate: La maggioranza delle coppie è costituita da parafrasi.  \n- Metrica principale: La metrica comunemente utilizzata per valutare il modello è l'F1-score, che tiene conto dello sbilanciamento delle classi e della precisione.  ","metadata":{}},{"cell_type":"code","source":"# Ottenimento del dataset\n\nmrpc_dataset = load_dataset(\"glue\", \"mrpc\")\n\nprint(mrpc_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:36:19.222504Z","iopub.execute_input":"2025-01-22T16:36:19.222811Z","iopub.status.idle":"2025-01-22T16:36:20.395425Z","shell.execute_reply.started":"2025-01-22T16:36:19.222784Z","shell.execute_reply":"2025-01-22T16:36:20.394638Z"}},"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 3668\n    })\n    validation: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 408\n    })\n    test: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 1725\n    })\n})\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"train_data = mrpc_dataset[\"train\"]\nval_data = mrpc_dataset[\"validation\"]\ntest_data = mrpc_dataset[\"test\"]\n\nprint(\"--- Dimensioni del dataset ---\")\nprint(f\"Train set: {len(train_data)} esempi\")\nprint(f\"Validation set: {len(val_data)} esempi\")\nprint(f\"Test set: {len(test_data)} esempi\")\nprint(f\"Totale: {len(train_data) + len(val_data) + len(test_data)} esempi\\n\")\n\n# Analisi dei tre split del dataset\nanalyze_data(\"Train\", train_data, \"label\")\nanalyze_data(\"Validation\", val_data, \"label\")\nanalyze_data(\"Test\", test_data, \"label\")\nprint('')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:36:20.396804Z","iopub.execute_input":"2025-01-22T16:36:20.397052Z","iopub.status.idle":"2025-01-22T16:36:20.671785Z","shell.execute_reply.started":"2025-01-22T16:36:20.397029Z","shell.execute_reply":"2025-01-22T16:36:20.670740Z"}},"outputs":[{"name":"stdout","text":"--- Dimensioni del dataset ---\nTrain set: 3668 esempi\nValidation set: 408 esempi\nTest set: 1725 esempi\nTotale: 5801 esempi\n\n--- Analisi Train ---\nNumero di esempi nel Train: 3668\n\nPrime 5 righe:\n                                           sentence1  \\\n0  Amrozi accused his brother , whom he called \" ...   \n1  Yucaipa owned Dominick 's before selling the c...   \n2  They had published an advertisement on the Int...   \n3  Around 0335 GMT , Tab shares were up 19 cents ...   \n4  The stock rose $ 2.11 , or about 11 percent , ...   \n\n                                           sentence2  label  idx  \n0  Referring to him as only \" the witness \" , Amr...      1    0  \n1  Yucaipa bought Dominick 's in 1995 for $ 693 m...      0    1  \n2  On June 10 , the ship 's owners had published ...      1    2  \n3  Tab shares jumped 20 cents , or 4.6 % , to set...      0    3  \n4  PG & E Corp. shares jumped $ 1.63 or 8 percent...      1    4   \n\nDati mancanti per colonna:\nsentence1    0\nsentence2    0\nlabel        0\nidx          0\ndtype: int64 \n\nDistribuzione delle classi:\n   Classe  Conteggio  Percentuale\n0       1       2474    67.448201\n1       0       1194    32.551799 \n\n\n--- Analisi Validation ---\nNumero di esempi nel Validation: 408\n\nPrime 5 righe:\n                                           sentence1  \\\n0  He said the foodservice pie business doesn 't ...   \n1  Magnarelli said Racicot hated the Iraqi regime...   \n2  The dollar was at 116.92 yen against the yen ,...   \n3  The AFL-CIO is waiting until October to decide...   \n4  No dates have been set for the civil or the cr...   \n\n                                           sentence2  label  idx  \n0  \" The foodservice pie business does not fit ou...      1    9  \n1  His wife said he was \" 100 percent behind Geor...      0   18  \n2  The dollar was at 116.78 yen JPY = , virtually...      0   25  \n3  The AFL-CIO announced Wednesday that it will d...      1   32  \n4  No dates have been set for the criminal or civ...      0   33   \n\nDati mancanti per colonna:\nsentence1    0\nsentence2    0\nlabel        0\nidx          0\ndtype: int64 \n\nDistribuzione delle classi:\n   Classe  Conteggio  Percentuale\n0       1        279    68.382353\n1       0        129    31.617647 \n\n\n--- Analisi Test ---\nNumero di esempi nel Test: 1725\n\nPrime 5 righe:\n                                           sentence1  \\\n0  PCCW 's chief operating officer , Mike Butcher...   \n1  The world 's two largest automakers said their...   \n2  According to the federal Centers for Disease C...   \n3  A tropical storm rapidly developed in the Gulf...   \n4  The company didn 't detail the costs of the re...   \n\n                                           sentence2  label  idx  \n0  Current Chief Operating Officer Mike Butcher a...      1    0  \n1  Domestic sales at both GM and No. 2 Ford Motor...      1    1  \n2  The Centers for Disease Control and Prevention...      1    2  \n3  A tropical storm rapidly developed in the Gulf...      0    3  \n4  But company officials expect the costs of the ...      0    4   \n\nDati mancanti per colonna:\nsentence1    0\nsentence2    0\nlabel        0\nidx          0\ndtype: int64 \n\nDistribuzione delle classi:\n   Classe  Conteggio  Percentuale\n0       1       1147    66.492754\n1       0        578    33.507246 \n\n\n\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"### 4. QQP  \nIl dataset QQP (Quora Question Pairs) permette di valutare la capacità di un modello di identificare se due domande poste su Quora hanno lo stesso significato o se sono distinte.  \n\n**Caratteristiche del dataset**  \n\n*Task*: Identificazione delle parafrasi.  \nDeterminare se due domande esprimono lo stesso significato. \n\n*Tipo di task*: Classificazione binaria. Ogni coppia di domande è etichettata come duplicate (1) o non duplicate (0). \n\n*Dominio*: Le domande provengono dalla piattaforma Quora, un sito di domande e risposte.  \n\n*Struttura del dataset*: Ogni esempio contiene:  \n- **question1**: la prima domanda della coppia.  \n- **question2**: la seconda domanda della coppia.  \n- **label**: etichetta binaria pari a 1 se le domande sono duplicate o a 0 se non lo sono.  \n- **id**: indice identificativo dell'esempio.  \n\n**Nota bene**  \n- Classi sbilanciate: Le domande duplicate rappresentano circa il 37% del dataset, mentre il 63% delle coppie non sono duplicate.  \n- Metrica principale: Le metriche comunemente utilizzate sono l'**F1-score** e l'**accuratezza**.\n- Grande numero di esempi.\n- Il test set cotiene solo etichette pari a -1","metadata":{}},{"cell_type":"code","source":"# Ottenimento del dataset\n\nqqp_dataset = load_dataset(\"glue\", \"qqp\")\n\nprint(qqp_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:36:20.672888Z","iopub.execute_input":"2025-01-22T16:36:20.673277Z","iopub.status.idle":"2025-01-22T16:36:21.764013Z","shell.execute_reply.started":"2025-01-22T16:36:20.673240Z","shell.execute_reply":"2025-01-22T16:36:21.762848Z"}},"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['question1', 'question2', 'label', 'idx'],\n        num_rows: 363846\n    })\n    validation: Dataset({\n        features: ['question1', 'question2', 'label', 'idx'],\n        num_rows: 40430\n    })\n    test: Dataset({\n        features: ['question1', 'question2', 'label', 'idx'],\n        num_rows: 390965\n    })\n})\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"train_data = qqp_dataset[\"train\"]\nval_data = qqp_dataset[\"validation\"]\ntest_data = qqp_dataset[\"test\"]\n\nprint(\"--- Dimensioni del dataset ---\")\nprint(f\"Train set: {len(train_data)} esempi\")\nprint(f\"Validation set: {len(val_data)} esempi\")\nprint(f\"Test set: {len(test_data)} esempi\")\nprint(f\"Totale: {len(train_data) + len(val_data) + len(test_data)} esempi\\n\")\n\n# Analisi dei tre split del dataset\nanalyze_data(\"Train\", train_data, \"label\")\nanalyze_data(\"Validation\", val_data, \"label\")\nanalyze_data(\"Test\", test_data, \"label\")\nprint('')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:36:21.765008Z","iopub.execute_input":"2025-01-22T16:36:21.765317Z","iopub.status.idle":"2025-01-22T16:36:51.634492Z","shell.execute_reply.started":"2025-01-22T16:36:21.765292Z","shell.execute_reply":"2025-01-22T16:36:51.633479Z"}},"outputs":[{"name":"stdout","text":"--- Dimensioni del dataset ---\nTrain set: 363846 esempi\nValidation set: 40430 esempi\nTest set: 390965 esempi\nTotale: 795241 esempi\n\n--- Analisi Train ---\nNumero di esempi nel Train: 363846\n\nPrime 5 righe:\n                                           question1  \\\n0  How is the life of a math student? Could you d...   \n1                How do I control my horny emotions?   \n2       What causes stool color to change to yellow?   \n3                        What can one do after MBBS?   \n4  Where can I find a power outlet for my laptop ...   \n\n                                           question2  label  idx  \n0  Which level of prepration is enough for the ex...      0    0  \n1                 How do you control your horniness?      1    1  \n2  What can cause stool to come out as little balls?      0    2  \n3                       What do i do after my MBBS ?      1    3  \n4  Would a second airport in Sydney, Australia be...      0    4   \n\nDati mancanti per colonna:\nquestion1    0\nquestion2    0\nlabel        0\nidx          0\ndtype: int64 \n\nDistribuzione delle classi:\n   Classe  Conteggio  Percentuale\n0       0     229468    63.067342\n1       1     134378    36.932658 \n\n\n--- Analisi Validation ---\nNumero di esempi nel Validation: 40430\n\nPrime 5 righe:\n                                           question1  \\\n0            Why are African-Americans so beautiful?   \n1  I want to pursue PhD in Computer Science about...   \n2      Is there a reason why we should travel alone?   \n3  Why are people so obsessed with having a girlf...   \n4  What are some good baby girl names starting wi...   \n\n                                           question2  label  idx  \n0                    Why are hispanics so beautiful?      0    0  \n1  I handle social media for a non-profit. Should...      0    1  \n2             What are some reasons to travel alone?      1    2  \n3                How can a single male have a child?      0    3  \n4  What are some good baby girl names starting wi...      0    4   \n\nDati mancanti per colonna:\nquestion1    0\nquestion2    0\nlabel        0\nidx          0\ndtype: int64 \n\nDistribuzione delle classi:\n   Classe  Conteggio  Percentuale\n0       0      25545     63.18328\n1       1      14885     36.81672 \n\n\n--- Analisi Test ---\nNumero di esempi nel Test: 390965\n\nPrime 5 righe:\n                                           question1  \\\n0  Would the idea of Trump and Putin in bed toget...   \n1  What are the top ten Consumer-to-Consumer E-co...   \n2  Why don't people simply 'Google' instead of as...   \n3          Is it safe to invest in social trade biz?   \n4  If the universe is expanding then does matter ...   \n\n                                           question2  label  idx  \n0  Do you think that if Donald Trump were elected...     -1    0  \n1  What are the top ten Consumer-to-Business E-co...     -1    1  \n2  Why do people ask Quora questions instead of j...     -1    2  \n3                           Is social trade geniune?     -1    3  \n4  If universe and space is expanding? Does that ...     -1    4   \n\nDati mancanti per colonna:\nquestion1    0\nquestion2    0\nlabel        0\nidx          0\ndtype: int64 \n\nDistribuzione delle classi:\n   Classe  Conteggio  Percentuale\n0      -1     390965        100.0 \n\n\n\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"### 5. STS-B  \nIl dataset STS-B (Semantic Textual Similarity Benchmark) permette di valutare la capacità di un modello di determinare il grado di somiglianza semantica tra due frasi.  \n\n**Caratteristiche del dataset**  \n\n*Task*: Valutazione della similarità semantica.  \nDeterminare quanto due frasi siano simili nel significato, assegnando un punteggio su una scala continua.  \n\n*Tipo di task*: Regressione. Il modello prevede un punteggio di similarità compreso tra 0 (frasi completamente diverse) e 5 (frasi semanticamente identiche).  \n\n*Dominio*: Le frasi provengono da molteplici fonti, tra cui notizie, forum, e sottotitoli, per garantire diversità semantica e stilistica.  \n\n*Struttura del dataset*: Ogni esempio contiene:  \n- **sentence1**: la prima frase della coppia.  \n- **sentence2**: la seconda frase della coppia.  \n- **label**: il punteggio di similarità semantica, un valore **reale** tra 0 e 5.  \n- **idx**: indice identificativo dell'esempio.  \n\n**Nota bene**  \n- **Classi sbilanciate**\n- **Metrica principale**: La performance del modello viene valutata usando la **correlazione di Pearson** e la **correlazione di Spearman**, che misurano il grado di accordo tra i punteggi previsti dal modello e i punteggi annotati.  \n- Il test set ha tutte le etichette pari a -1.0 . ","metadata":{}},{"cell_type":"code","source":"# Ottenimento del dataset\n\nstsb_dataset = load_dataset(\"glue\", \"stsb\")\n\nprint(stsb_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:36:51.635513Z","iopub.execute_input":"2025-01-22T16:36:51.635850Z","iopub.status.idle":"2025-01-22T16:36:52.780423Z","shell.execute_reply.started":"2025-01-22T16:36:51.635817Z","shell.execute_reply":"2025-01-22T16:36:52.779506Z"}},"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 5749\n    })\n    validation: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 1500\n    })\n    test: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 1379\n    })\n})\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"def analyze_data_stsb(name, data,target):\n    print(f\"--- Analisi {name} ---\")\n    \n    df = pd.DataFrame(data)\n    \n    # Dimensioni\n    print(f\"Numero di esempi nel {name}: {len(df)}\\n\")\n    \n    # Prime righe\n    print(\"Prime 5 righe:\")\n    print(df.head(), \"\\n\")\n    \n    # Dati mancanti\n    print(\"Dati mancanti per colonna:\")\n    print(df.isnull().sum(), \"\\n\")\n    \n    # Distribuzione delle etichette\n    print(\"Distribuzione delle classi (intervalli di punteggio):\")\n    bins = [-1, 0, 1, 2, 3, 4, 5, 6, 7]\n    labels = ['-1-0','0-1', '1-2', '2-3', '3-4', '4-5', '5-6', '6-7']\n    df['target_range'] = pd.cut(df[target], bins=bins, labels=labels, right=False)\n    \n    range_counts = df['target_range'].value_counts(sort=False)\n    range_percentages = (range_counts / len(df)) * 100\n    summary_table = pd.DataFrame({\n        'Intervallo': range_counts.index,\n        'Conteggio': range_counts.values,\n        'Percentuale': range_percentages.values\n    })\n    print(summary_table, \"\\n\\n\")\n    \n    return df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:36:52.781342Z","iopub.execute_input":"2025-01-22T16:36:52.781623Z","iopub.status.idle":"2025-01-22T16:36:52.787834Z","shell.execute_reply.started":"2025-01-22T16:36:52.781592Z","shell.execute_reply":"2025-01-22T16:36:52.786853Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"train_data = stsb_dataset[\"train\"]\nval_data = stsb_dataset[\"validation\"]\ntest_data = stsb_dataset[\"test\"]\n\nprint(\"--- Dimensioni del dataset ---\")\nprint(f\"Train set: {len(train_data)} esempi\")\nprint(f\"Validation set: {len(val_data)} esempi\")\nprint(f\"Test set: {len(test_data)} esempi\")\nprint(f\"Totale: {len(train_data) + len(val_data) + len(test_data)} esempi\\n\")\n\n# Analisi dei tre split del dataset\nanalyze_data_stsb(\"Train\", train_data, \"label\")\nanalyze_data_stsb(\"Validation\", val_data, \"label\")\nanalyze_data_stsb(\"Test\", test_data, \"label\")\nprint('')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:36:52.788761Z","iopub.execute_input":"2025-01-22T16:36:52.789062Z","iopub.status.idle":"2025-01-22T16:36:53.159230Z","shell.execute_reply.started":"2025-01-22T16:36:52.789029Z","shell.execute_reply":"2025-01-22T16:36:53.158403Z"}},"outputs":[{"name":"stdout","text":"--- Dimensioni del dataset ---\nTrain set: 5749 esempi\nValidation set: 1500 esempi\nTest set: 1379 esempi\nTotale: 8628 esempi\n\n--- Analisi Train ---\nNumero di esempi nel Train: 5749\n\nPrime 5 righe:\n                                       sentence1  \\\n0                         A plane is taking off.   \n1                A man is playing a large flute.   \n2  A man is spreading shreded cheese on a pizza.   \n3                   Three men are playing chess.   \n4                    A man is playing the cello.   \n\n                                           sentence2  label  idx  \n0                        An air plane is taking off.   5.00    0  \n1                          A man is playing a flute.   3.80    1  \n2  A man is spreading shredded cheese on an uncoo...   3.80    2  \n3                         Two men are playing chess.   2.60    3  \n4                 A man seated is playing the cello.   4.25    4   \n\nDati mancanti per colonna:\nsentence1    0\nsentence2    0\nlabel        0\nidx          0\ndtype: int64 \n\nDistribuzione delle classi (intervalli di punteggio):\n  Intervallo  Conteggio  Percentuale\n0       -1-0          0     0.000000\n1        0-1        891    15.498348\n2        1-2        882    15.341799\n3        2-3        982    17.081232\n4        3-4       1588    27.622195\n5        4-5       1140    19.829536\n6        5-6        266     4.626892\n7        6-7          0     0.000000 \n\n\n--- Analisi Validation ---\nNumero di esempi nel Validation: 1500\n\nPrime 5 righe:\n                              sentence1  \\\n0     A man with a hard hat is dancing.   \n1      A young child is riding a horse.   \n2  A man is feeding a mouse to a snake.   \n3        A woman is playing the guitar.   \n4         A woman is playing the flute.   \n\n                                  sentence2  label  idx  \n0      A man wearing a hard hat is dancing.   5.00    0  \n1                A child is riding a horse.   4.75    1  \n2  The man is feeding a mouse to the snake.   5.00    2  \n3                  A man is playing guitar.   2.40    3  \n4                 A man is playing a flute.   2.75    4   \n\nDati mancanti per colonna:\nsentence1    0\nsentence2    0\nlabel        0\nidx          0\ndtype: int64 \n\nDistribuzione delle classi (intervalli di punteggio):\n  Intervallo  Conteggio  Percentuale\n0       -1-0          0     0.000000\n1        0-1        344    22.933333\n2        1-2        254    16.933333\n3        2-3        273    18.200000\n4        3-4        365    24.333333\n5        4-5        208    13.866667\n6        5-6         56     3.733333\n7        6-7          0     0.000000 \n\n\n--- Analisi Test ---\nNumero di esempi nel Test: 1379\n\nPrime 5 righe:\n                                       sentence1  \\\n0                    A girl is styling her hair.   \n1       A group of men play soccer on the beach.   \n2  One woman is measuring another woman's ankle.   \n3                A man is cutting up a cucumber.   \n4                       A man is playing a harp.   \n\n                                          sentence2  label  idx  \n0                      A girl is brushing her hair.   -1.0    0  \n1  A group of boys are playing soccer on the beach.   -1.0    1  \n2           A woman measures another woman's ankle.   -1.0    2  \n3                      A man is slicing a cucumber.   -1.0    3  \n4                      A man is playing a keyboard.   -1.0    4   \n\nDati mancanti per colonna:\nsentence1    0\nsentence2    0\nlabel        0\nidx          0\ndtype: int64 \n\nDistribuzione delle classi (intervalli di punteggio):\n  Intervallo  Conteggio  Percentuale\n0       -1-0       1379        100.0\n1        0-1          0          0.0\n2        1-2          0          0.0\n3        2-3          0          0.0\n4        3-4          0          0.0\n5        4-5          0          0.0\n6        5-6          0          0.0\n7        6-7          0          0.0 \n\n\n\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"### 6. MNLI  \nIl dataset MNLI (Multi-Genre Natural Language Inference) permette di verificare se due frasi sono una la contraddizione dell'altra, una la conseguenza dell'altra o sono neutrali fra loro.\n\n**Caratteristiche del dataset**  \n\n*Task*: Inferenza logica.\nValutare se, data una coppia di frasi (premessa e ipotesi), la relazione tra di esse sia conseguenza, contraddizione o neutralità.  \n\n*Tipo di task*: Classificazione multi-classe (3 classi: Entailment, Neutral, Contradiction).  \n\n*Dominio*:  Le frasi provengono da una varietà di generi testuali, tra cui fiction, transcripts di discorsi, scritti di viaggio, pagine di Wikipedia.\n\n*Struttura del dataset*: Ogni esempio contiene:  \n- **premise**: la frase principale (premessa).  \n- **hypothesis**: la frase secondaria (ipotesi).  \n- **label**: la relazione logica tra la premessa e l’ipotesi (0 = Entailment, 1 = Neutral, 2 = Contradiction).\n- **idx**: indice identificativo dell’esempio.  \n\n**Nota bene**  \n- **Set di test e di validationseparati**: MNLI dispone di due tipi set di test e validation distinti:  \n  - **Matched**: contiene esempi che appartengono agli stessi generi testuali del training set.  \n  - **Mismatched**: contiene esempi provenienti da generi testuali differenti rispetto al training set.  \n- Il test set contiene tutte le etichette pari a -1 .","metadata":{}},{"cell_type":"code","source":"# Ottenimento del dataset\n\nmnli_dataset = load_dataset(\"glue\", \"mnli\")\n\nprint(mnli_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:36:53.160061Z","iopub.execute_input":"2025-01-22T16:36:53.160419Z","iopub.status.idle":"2025-01-22T16:36:54.340587Z","shell.execute_reply.started":"2025-01-22T16:36:53.160378Z","shell.execute_reply":"2025-01-22T16:36:54.339765Z"}},"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['premise', 'hypothesis', 'label', 'idx'],\n        num_rows: 392702\n    })\n    validation_matched: Dataset({\n        features: ['premise', 'hypothesis', 'label', 'idx'],\n        num_rows: 9815\n    })\n    validation_mismatched: Dataset({\n        features: ['premise', 'hypothesis', 'label', 'idx'],\n        num_rows: 9832\n    })\n    test_matched: Dataset({\n        features: ['premise', 'hypothesis', 'label', 'idx'],\n        num_rows: 9796\n    })\n    test_mismatched: Dataset({\n        features: ['premise', 'hypothesis', 'label', 'idx'],\n        num_rows: 9847\n    })\n})\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"train_data = mnli_dataset[\"train\"]\nval_data = mnli_dataset[\"validation_matched\"]\ntest_data = mnli_dataset[\"test_matched\"]\n\nprint(\"--- Dimensioni del dataset ---\")\nprint(f\"Train set: {len(train_data)} esempi\")\nprint(f\"Validation set: {len(val_data)} esempi\")\nprint(f\"Test set: {len(test_data)} esempi\")\nprint(f\"Totale: {len(train_data) + len(val_data) + len(test_data)} esempi\\n\")\n\n# Analisi dei tre split del dataset\nanalyze_data(\"Train\", train_data, \"label\")\nanalyze_data(\"Validation\", val_data, \"label\")\nanalyze_data(\"Test\", test_data, \"label\")\nprint('')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:36:54.341398Z","iopub.execute_input":"2025-01-22T16:36:54.341676Z","iopub.status.idle":"2025-01-22T16:37:09.879745Z","shell.execute_reply.started":"2025-01-22T16:36:54.341652Z","shell.execute_reply":"2025-01-22T16:37:09.878627Z"}},"outputs":[{"name":"stdout","text":"--- Dimensioni del dataset ---\nTrain set: 392702 esempi\nValidation set: 9815 esempi\nTest set: 9796 esempi\nTotale: 412313 esempi\n\n--- Analisi Train ---\nNumero di esempi nel Train: 392702\n\nPrime 5 righe:\n                                             premise  \\\n0  Conceptually cream skimming has two basic dime...   \n1  you know during the season and i guess at at y...   \n2  One of our number will carry out your instruct...   \n3  How do you know? All this is their information...   \n4  yeah i tell you what though if you go price so...   \n\n                                          hypothesis  label  idx  \n0  Product and geography are what make cream skim...      1    0  \n1  You lose the things to the following level if ...      0    1  \n2  A member of my team will execute your orders w...      0    2  \n3                  This information belongs to them.      0    3  \n4           The tennis shoes have a range of prices.      1    4   \n\nDati mancanti per colonna:\npremise       0\nhypothesis    0\nlabel         0\nidx           0\ndtype: int64 \n\nDistribuzione delle classi:\n   Classe  Conteggio  Percentuale\n0       2     130903    33.333928\n1       1     130900    33.333164\n2       0     130899    33.332909 \n\n\n--- Analisi Validation ---\nNumero di esempi nel Validation: 9815\n\nPrime 5 righe:\n                                             premise  \\\n0                     The new rights are nice enough   \n1  This site includes a list of all award winners...   \n2  uh i don't know i i have mixed emotions about ...   \n3  yeah i i think my favorite restaurant is alway...   \n4         i don't know um do you do a lot of camping   \n\n                                          hypothesis  label  idx  \n0         Everyone really likes the newest benefits       1    0  \n1  The Government Executive articles housed on th...      2    1  \n2  I like him for the most part, but would still ...      0    2  \n3  My favorite restaurants are always at least a ...      2    3  \n4                                    I know exactly.      2    4   \n\nDati mancanti per colonna:\npremise       0\nhypothesis    0\nlabel         0\nidx           0\ndtype: int64 \n\nDistribuzione delle classi:\n   Classe  Conteggio  Percentuale\n0       0       3479    35.445746\n1       2       3213    32.735609\n2       1       3123    31.818645 \n\n\n--- Analisi Test ---\nNumero di esempi nel Test: 9796\n\nPrime 5 righe:\n                                             premise  \\\n0  Hierbas, ans seco, ans dulce, and frigola are ...   \n1  The extent of the behavioral effects would dep...   \n2  Timely access to information is in the best in...   \n3  Based in the Auvergnat spa town of Vichy, the ...   \n4  Built in 1870, its canopy of stained glass and...   \n\n                                          hypothesis  label  idx  \n0           Hierbas is a name worth looking out for.     -1    0  \n1  Many people would be very unhappy to loose con...     -1    1  \n2  It is in everyone's best interest to have acce...     -1    2  \n3  The French government passed anti-Jewish laws ...     -1    3  \n4  It was constructed in 1870 and has the oldest ...     -1    4   \n\nDati mancanti per colonna:\npremise       0\nhypothesis    0\nlabel         0\nidx           0\ndtype: int64 \n\nDistribuzione delle classi:\n   Classe  Conteggio  Percentuale\n0      -1       9796        100.0 \n\n\n\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"### 7. QNLI  \nIl dataset QNLI (Question-answering Natural Language Inference) permette di valutare la capacità di un modello di determinare se una frase contenente un contesto risponde a una domanda specifica.  \n\n**Caratteristiche del dataset**  \n\n*Task*: Inferenza domanda-contesto.  \nValutare se, data una coppia composta da una domanda e una frase contestuale, la frase contiene la risposta alla domanda.  \n\n*Tipo di task*: Classificazione binaria.  \nOgni coppia è etichettata con 1 se il contesto contiene la risposta alla domanda, 0 altrimenti.    \n\n*Dominio*:  Le frasi provengono da Wikipedia, le domande sono state create da annotatori umani.  \n\n*Struttura del dataset*: Ogni esempio contiene:  \n- **question**: la domanda formulata da un annotatore.  \n- **sentence**: una frase estratta dal paragrafo che potrebbe contenere la risposta.  \n- **label**: etichetta binaria che indica se il contesto risponde alla domanda (1 = sì, 0 = no).  \n- **idx**: indice identificativo dell’esempio.  \n\n**Nota bene**  \n- Il test set ha tutte le etichette pari a -1 .","metadata":{}},{"cell_type":"code","source":"# Ottenimento del dataset\n\nqnli_dataset = load_dataset(\"glue\", \"qnli\")\n\nprint(qnli_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:37:09.880889Z","iopub.execute_input":"2025-01-22T16:37:09.881300Z","iopub.status.idle":"2025-01-22T16:37:11.172518Z","shell.execute_reply.started":"2025-01-22T16:37:09.881262Z","shell.execute_reply":"2025-01-22T16:37:11.171592Z"}},"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['question', 'sentence', 'label', 'idx'],\n        num_rows: 104743\n    })\n    validation: Dataset({\n        features: ['question', 'sentence', 'label', 'idx'],\n        num_rows: 5463\n    })\n    test: Dataset({\n        features: ['question', 'sentence', 'label', 'idx'],\n        num_rows: 5463\n    })\n})\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"train_data = qnli_dataset[\"train\"]\nval_data = qnli_dataset[\"validation\"]\ntest_data = qnli_dataset[\"test\"]\n\nprint(\"--- Dimensioni del dataset ---\")\nprint(f\"Train set: {len(train_data)} esempi\")\nprint(f\"Validation set: {len(val_data)} esempi\")\nprint(f\"Test set: {len(test_data)} esempi\")\nprint(f\"Totale: {len(train_data) + len(val_data) + len(test_data)} esempi\\n\")\n\n# Analisi dei tre split del dataset\nanalyze_data(\"Train\", train_data, \"label\")\nanalyze_data(\"Validation\", val_data, \"label\")\nanalyze_data(\"Test\", test_data, \"label\")\nprint('')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:37:11.173376Z","iopub.execute_input":"2025-01-22T16:37:11.173615Z","iopub.status.idle":"2025-01-22T16:37:15.469315Z","shell.execute_reply.started":"2025-01-22T16:37:11.173595Z","shell.execute_reply":"2025-01-22T16:37:15.468404Z"}},"outputs":[{"name":"stdout","text":"--- Dimensioni del dataset ---\nTrain set: 104743 esempi\nValidation set: 5463 esempi\nTest set: 5463 esempi\nTotale: 115669 esempi\n\n--- Analisi Train ---\nNumero di esempi nel Train: 104743\n\nPrime 5 righe:\n                                            question  \\\n0           When did the third Digimon series begin?   \n1  Which missile batteries often have individual ...   \n2  What two things does Popper argue Tarski's the...   \n3  What is the name of the village 9 miles north ...   \n4           What famous palace is located in London?   \n\n                                            sentence  label  idx  \n0  Unlike the two seasons before it and most of t...      1    0  \n1  When MANPADS is operated by specialists, batte...      1    1  \n2  He bases this interpretation on the fact that ...      0    2  \n3  On 31 December 1853, the Ottoman forces at Cal...      0    3  \n4  London contains four World Heritage Sites: the...      1    4   \n\nDati mancanti per colonna:\nquestion    0\nsentence    0\nlabel       0\nidx         0\ndtype: int64 \n\nDistribuzione delle classi:\n   Classe  Conteggio  Percentuale\n0       0      52377    50.005251\n1       1      52366    49.994749 \n\n\n--- Analisi Validation ---\nNumero di esempi nel Validation: 5463\n\nPrime 5 righe:\n                                            question  \\\n0  What came into force after the new constitutio...   \n1  What is the first major city in the stream of ...   \n2  What is the minimum required if you want to te...   \n3  How was Temüjin kept imprisoned by the Tayichi...   \n4  What did Herr Gott, dich loben wir become know...   \n\n                                            sentence  label  idx  \n0  As of that day, the new constitution heralding...      0    0  \n1  The most important tributaries in this area ar...      1    1  \n2  In most provinces a second Bachelor's Degree s...      1    2  \n3  The Tayichi'ud enslaved Temüjin (reportedly wi...      0    3  \n4  He paraphrased the Te Deum as \"Herr Gott, dich...      1    4   \n\nDati mancanti per colonna:\nquestion    0\nsentence    0\nlabel       0\nidx         0\ndtype: int64 \n\nDistribuzione delle classi:\n   Classe  Conteggio  Percentuale\n0       1       2761    50.539996\n1       0       2702    49.460004 \n\n\n--- Analisi Test ---\nNumero di esempi nel Test: 5463\n\nPrime 5 righe:\n                                            question  \\\n0  What organization is devoted to Jihad against ...   \n1  In what century was the Yarrow-Schlick-Tweedy ...   \n2  The largest brand of what store in the UK is l...   \n3           What does the IPCC rely on for research?   \n4  What is the principle about relating spin and ...   \n\n                                            sentence  label  idx  \n0  For some decades prior to the First Palestine ...     -1    0  \n1  In the late 19th century, the Yarrow-Schlick-T...     -1    1  \n2  Close to Newcastle, the largest indoor shoppin...     -1    2  \n3  In principle, this means that any significant ...     -1    3  \n4  Thus in the case of two fermions there is a st...     -1    4   \n\nDati mancanti per colonna:\nquestion    0\nsentence    0\nlabel       0\nidx         0\ndtype: int64 \n\nDistribuzione delle classi:\n   Classe  Conteggio  Percentuale\n0      -1       5463        100.0 \n\n\n\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"### 8. RTE  \nIl dataset RTE (Recognizing Textual Entailment) permette di valutare la capacità di un modello di determinare se una frase implica logicamente un'altra.  \n\n**Caratteristiche del dataset**  \n\n*Task*: Inferenza testuale.  \nValutare se, data una coppia di frasi (premessa e ipotesi), la premessa implica logicamente l'ipotesi.  \n\n*Tipo di task*: Classificazione binaria.  \nOgni coppia è etichettata con 1 se l'ipotesi è una conseguenza logica della premessa, 0 altrimenti.  \n\n*Dominio*:  Le coppie di frasi provengono da varie fonti, inclusi notiziari, report scientifici, Wikipedia e dati generati per competizioni di inferenza testuale.  \n\n*Struttura del dataset*: Ogni esempio contiene:  \n- **sentece1**: la frase principale (premessa).  \n- **sentence2**: la frase secondaria (ipotesi).  \n- **label**: etichetta binaria che indica se la premessa implica l'ipotesi (1 = sì, 0 = no).  \n- **idx**: indice identificativo dell’esempio.  \n\n**Nota bene**    \n- **Dimensioni ridotte**.\n- Il test set ha tutte le etichette pari a -1 .","metadata":{}},{"cell_type":"code","source":"# Ottenimento del dataset\n\nrte_dataset = load_dataset(\"glue\", \"rte\")\n\nprint(rte_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:37:15.470338Z","iopub.execute_input":"2025-01-22T16:37:15.470686Z","iopub.status.idle":"2025-01-22T16:37:16.650743Z","shell.execute_reply.started":"2025-01-22T16:37:15.470661Z","shell.execute_reply":"2025-01-22T16:37:16.649906Z"}},"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 2490\n    })\n    validation: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 277\n    })\n    test: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 3000\n    })\n})\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"train_data = rte_dataset[\"train\"]\nval_data = rte_dataset[\"validation\"]\ntest_data = rte_dataset[\"test\"]\n\nprint(\"--- Dimensioni del dataset ---\")\nprint(f\"Train set: {len(train_data)} esempi\")\nprint(f\"Validation set: {len(val_data)} esempi\")\nprint(f\"Test set: {len(test_data)} esempi\")\nprint(f\"Totale: {len(train_data) + len(val_data) + len(test_data)} esempi\\n\")\n\n# Analisi dei tre split del dataset\nanalyze_data(\"Train\", train_data, \"label\")\nanalyze_data(\"Validation\", val_data, \"label\")\nanalyze_data(\"Test\", test_data, \"label\")\nprint('')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:37:16.651511Z","iopub.execute_input":"2025-01-22T16:37:16.651800Z","iopub.status.idle":"2025-01-22T16:37:16.921139Z","shell.execute_reply.started":"2025-01-22T16:37:16.651763Z","shell.execute_reply":"2025-01-22T16:37:16.920294Z"}},"outputs":[{"name":"stdout","text":"--- Dimensioni del dataset ---\nTrain set: 2490 esempi\nValidation set: 277 esempi\nTest set: 3000 esempi\nTotale: 5767 esempi\n\n--- Analisi Train ---\nNumero di esempi nel Train: 2490\n\nPrime 5 righe:\n                                           sentence1  \\\n0  No Weapons of Mass Destruction Found in Iraq Yet.   \n1  A place of sorrow, after Pope John Paul II die...   \n2  Herceptin was already approved to treat the si...   \n3  Judie Vivian, chief executive at ProMedica, a ...   \n4  A man is due in court later charged with the m...   \n\n                                           sentence2  label  idx  \n0         Weapons of Mass Destruction Found in Iraq.      1    0  \n1  Pope Benedict XVI is the new leader of the Rom...      0    1  \n2      Herceptin can be used to treat breast cancer.      0    2  \n3  The previous name of Ho Chi Minh City was Saigon.      0    3  \n4  Paul Stewart Hutchinson is accused of having s...      1    4   \n\nDati mancanti per colonna:\nsentence1    0\nsentence2    0\nlabel        0\nidx          0\ndtype: int64 \n\nDistribuzione delle classi:\n   Classe  Conteggio  Percentuale\n0       0       1249    50.160643\n1       1       1241    49.839357 \n\n\n--- Analisi Validation ---\nNumero di esempi nel Validation: 277\n\nPrime 5 righe:\n                                           sentence1  \\\n0  Dana Reeve, the widow of the actor Christopher...   \n1  Yet, we now are discovering that antibiotics a...   \n2  Cairo is now home to some 15 million people - ...   \n3  The Amish community in Pennsylvania, which num...   \n4  Security forces were on high alert after an el...   \n\n                                           sentence2  label  idx  \n0                 Christopher Reeve had an accident.      1    0  \n1   Bacteria is winning the war against antibiotics.      0    1  \n2  15 million tonnes of rubbish are produced dail...      1    2  \n3  Pennsylvania has the biggest Amish community i...      1    3  \n4  Security forces were on high alert after a cam...      0    4   \n\nDati mancanti per colonna:\nsentence1    0\nsentence2    0\nlabel        0\nidx          0\ndtype: int64 \n\nDistribuzione delle classi:\n   Classe  Conteggio  Percentuale\n0       0        146    52.707581\n1       1        131    47.292419 \n\n\n--- Analisi Test ---\nNumero di esempi nel Test: 3000\n\nPrime 5 righe:\n                                           sentence1  \\\n0  Mangla was summoned after Madhumita's sister N...   \n1  Authorities in Brazil say that more than 200 p...   \n2  A mercenary group faithful to the warmongering...   \n3  The British ambassador to Egypt, Derek Plumbly...   \n4  Tibone estimated diamond production at four mi...   \n\n                                           sentence2  label  idx  \n0                       Shukla is related to Mangla.     -1    0  \n1  Authorities in Brazil hold 200 people as hostage.     -1    1  \n2  An interior ministry worker was killed by a me...     -1    2  \n3                    Derek Plumbly resides in Egypt.     -1    3  \n4        Botswana is a business partner of De Beers.     -1    4   \n\nDati mancanti per colonna:\nsentence1    0\nsentence2    0\nlabel        0\nidx          0\ndtype: int64 \n\nDistribuzione delle classi:\n   Classe  Conteggio  Percentuale\n0      -1       3000        100.0 \n\n\n\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"### 9. WNLI  \nIl dataset WNLI (Winograd Natural Language Inference) deriva dal Winograd Schema Challenge, un compito di comprensione della lettura progettato per valutare la capacità di un modello di risolvere ambiguità pronominali basate sul contesto.  \n\n**Caratteristiche del dataset**  \n\n*Task*: Risoluzione delle ambiguità pronominali.  \nData una frase contenente un pronome ambiguo e una frase ipotesi in cui il pronome è sostituito da un possibile referente dire se la frase ipotesi è implicata dalla frase originale.  \n\n*Tipo di task*: Classificazione binaria.  \nOgni coppia di frasi è etichettata con 1 se la frase ipotesi è implicata dalla frase originale, 0 altrimenti.  \n\n*Dominio*:  Le frasi provengono da libri di narrativa.\n\n*Struttura del dataset*: Ogni esempio contiene:  \n- **sentence1**: la frase originale contenente il pronome ambiguo.  \n- **sentence2**: la frase ipotesi in cui il pronome è stato sostituito con un possibile referente.  \n- **label**: etichetta binaria che indica se l’ipotesi è implicata dalla premessa (1 = sì, 0 = no).  \n- **idx**: indice identificativo dell’esempio.  \n\n**Nota bene**  \n- **Difficoltà progettuale**: Gli esempi sono costruiti manualmente per eludere semplici metodi statistici, richiedendo un’interpretazione contestuale accurata.   \n- Il test set ha tutte le etichette poste a -1.\n\n","metadata":{}},{"cell_type":"code","source":"# Ottenimento del dataset\n\nwnli_dataset = load_dataset(\"glue\", \"wnli\")\n\nprint(wnli_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:37:16.921881Z","iopub.execute_input":"2025-01-22T16:37:16.922207Z","iopub.status.idle":"2025-01-22T16:37:18.009729Z","shell.execute_reply.started":"2025-01-22T16:37:16.922180Z","shell.execute_reply":"2025-01-22T16:37:18.008943Z"}},"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 635\n    })\n    validation: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 71\n    })\n    test: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 146\n    })\n})\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"train_data = wnli_dataset[\"train\"]\nval_data = wnli_dataset[\"validation\"]\ntest_data = wnli_dataset[\"test\"]\n\nprint(\"--- Dimensioni del dataset ---\")\nprint(f\"Train set: {len(train_data)} esempi\")\nprint(f\"Validation set: {len(val_data)} esempi\")\nprint(f\"Test set: {len(test_data)} esempi\")\nprint(f\"Totale: {len(train_data) + len(val_data) + len(test_data)} esempi\\n\")\n\n# Analisi dei tre split del dataset\nanalyze_data(\"Train\", train_data, \"label\")\nanalyze_data(\"Validation\", val_data, \"label\")\nanalyze_data(\"Test\", test_data, \"label\")\nprint('')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:37:18.010566Z","iopub.execute_input":"2025-01-22T16:37:18.010899Z","iopub.status.idle":"2025-01-22T16:37:18.073321Z","shell.execute_reply.started":"2025-01-22T16:37:18.010865Z","shell.execute_reply":"2025-01-22T16:37:18.072584Z"}},"outputs":[{"name":"stdout","text":"--- Dimensioni del dataset ---\nTrain set: 635 esempi\nValidation set: 71 esempi\nTest set: 146 esempi\nTotale: 852 esempi\n\n--- Analisi Train ---\nNumero di esempi nel Train: 635\n\nPrime 5 righe:\n                                           sentence1  \\\n0  I stuck a pin through a carrot. When I pulled ...   \n1  John couldn't see the stage with Billy in fron...   \n2  The police arrested all of the gang members. T...   \n3  Steve follows Fred's example in everything. He...   \n4  When Tatyana reached the cabin, her mother was...   \n\n                                           sentence2  label  idx  \n0                             The carrot had a hole.      1    0  \n1                                  John is so short.      1    1  \n2  The police were trying to stop the drug trade ...      1    2  \n3                       Steve influences him hugely.      0    3  \n4  mother was careful not to disturb her, undress...      0    4   \n\nDati mancanti per colonna:\nsentence1    0\nsentence2    0\nlabel        0\nidx          0\ndtype: int64 \n\nDistribuzione delle classi:\n   Classe  Conteggio  Percentuale\n0       0        323    50.866142\n1       1        312    49.133858 \n\n\n--- Analisi Validation ---\nNumero di esempi nel Validation: 71\n\nPrime 5 righe:\n                                           sentence1  \\\n0  The drain is clogged with hair. It has to be c...   \n1  Jane knocked on Susan's door but she did not a...   \n2  Beth didn't get angry with Sally, who had cut ...   \n3  No one joins Facebook to be sad and lonely. Bu...   \n4  The man couldn't lift his son because he was s...   \n\n                                    sentence2  label  idx  \n0                 The hair has to be cleaned.      0    0  \n1                       Susan did not answer.      1    1  \n2           Sally stopped and counted to ten.      0    2  \n3  That's exactly how Facebook makes us feel.      1    3  \n4                       The son was so heavy.      1    4   \n\nDati mancanti per colonna:\nsentence1    0\nsentence2    0\nlabel        0\nidx          0\ndtype: int64 \n\nDistribuzione delle classi:\n   Classe  Conteggio  Percentuale\n0       0         40    56.338028\n1       1         31    43.661972 \n\n\n--- Analisi Test ---\nNumero di esempi nel Test: 146\n\nPrime 5 righe:\n                                           sentence1  \\\n0  Maude and Dora had seen the trains rushing acr...   \n1  Maude and Dora had seen the trains rushing acr...   \n2  Maude and Dora had seen the trains rushing acr...   \n3  Maude and Dora had seen the trains rushing acr...   \n4  Maude and Dora had seen the trains rushing acr...   \n\n                                           sentence2  label  idx  \n0  Horses ran away when Maude and Dora came in si...     -1    0  \n1     Horses ran away when the trains came in sight.     -1    1  \n2      Horses ran away when the puffs came in sight.     -1    2  \n3      Horses ran away when the roars came in sight.     -1    3  \n4   Horses ran away when the whistles came in sight.     -1    4   \n\nDati mancanti per colonna:\nsentence1    0\nsentence2    0\nlabel        0\nidx          0\ndtype: int64 \n\nDistribuzione delle classi:\n   Classe  Conteggio  Percentuale\n0      -1        146        100.0 \n\n\n\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"## Dataset per la sentiment analysis","metadata":{}},{"cell_type":"markdown","source":"### 1. SemEval 2017\n\nIl dataset **SemEval 2017** è un dataset creato per un task della competizione Semantic Evaluetion del 2017. Consente di valutare i modelli sul task di sentiment analysis su testi provenienti da Twitter e quindi classificarli con positivi, negativi o neutri.\n\n**Caratteristiche del dataset**\n\n*Task*: Sentiment analysis su tweet.  \n\n*Tipo di task*: Classificazione multiclasse. Ogni tweet è etichettato con una delle tre categorie di sentiment.\n\n*Dominio*: I tweet provengono da Twitter e trattano di una varietà di argomenti, inclusi eventi di attualità, opinioni personali, e discussioni su temi popolari.\n\n*Struttura del dataset*: Ogni esempio contiene:\n- **id**: l'identificativo univoco del tweet.\n- **sentiment**: l'etichetta di sentiment (positivo, negativo o neutro).\n- **text**: il testo del tweet.\n\n**Nota bene**\n- **Classi sbilanciate**.\n- **Poci esempi**.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Percorsi dei file (modifica questi percorsi in base alla tua struttura)\ntrain_file = \"/kaggle/input/semeval-2017/twitter-2016train-A.txt\"\nvalidation_file = \"/kaggle/input/semeval-2017/twitter-2016dev-A.txt\"\ntest_file = \"/kaggle/input/semeval-2017/twitter-2016devtest-A.txt\"\n\n# Carica i file in DataFrame\ncolumns = ['id', 'sentiment', 'text']\ntrain_data = pd.read_csv(train_file, sep='\\t', names=columns, header=None, encoding='utf-8')\nval_data = pd.read_csv(validation_file, sep='\\t', names=columns, header=None, encoding='utf-8')\ntest_data = pd.read_csv(test_file, sep='\\t', names=columns, header=None, encoding='utf-8')\n\nprint(\"--- Dimensioni del dataset ---\")\nprint(f\"Train set: {len(train_data)} esempi\")\nprint(f\"Validation set: {len(val_data)} esempi\")\nprint(f\"Test set: {len(test_data)} esempi\")\nprint(f\"Totale: {len(train_data) + len(val_data) + len(test_data)} esempi\\n\")\n\n# Analisi dei tre split del dataset\nanalyze_data(\"Train\", train_data, \"sentiment\")\nanalyze_data(\"Validation\", val_data, \"sentiment\")\nanalyze_data(\"Test\", test_data, \"sentiment\")\nprint('')\n","metadata":{"execution":{"iopub.status.busy":"2025-01-22T16:43:03.032359Z","iopub.execute_input":"2025-01-22T16:43:03.032740Z","iopub.status.idle":"2025-01-22T16:43:03.132700Z","shell.execute_reply.started":"2025-01-22T16:43:03.032706Z","shell.execute_reply":"2025-01-22T16:43:03.131820Z"},"trusted":true},"outputs":[{"name":"stdout","text":"--- Dimensioni del dataset ---\nTrain set: 5868 esempi\nValidation set: 1966 esempi\nTest set: 2000 esempi\nTotale: 9834 esempi\n\n--- Analisi Train ---\nNumero di esempi nel Train: 5868\n\nPrime 5 righe:\n                   id sentiment  \\\n0  628949369883000832  negative   \n1  628976607420645377  negative   \n2  629023169169518592  negative   \n3  629179223232479232  negative   \n4  629186282179153920   neutral   \n\n                                                text  \n0  dear @Microsoft the newOoffice for Mac is grea...  \n1  @Microsoft how about you make a system that do...  \n2  I may be ignorant on this issue but... should ...  \n3  Thanks to @microsoft, I just may be switching ...  \n4  If I make a game as a #windows10 Universal App...   \n\nDati mancanti per colonna:\nid           0\nsentiment    0\ntext         0\ndtype: int64 \n\nDistribuzione delle classi:\n     Classe  Conteggio  Percentuale\n0  positive       3017    51.414451\n1   neutral       2001    34.100204\n2  negative        850    14.485344 \n\n\n--- Analisi Validation ---\nNumero di esempi nel Validation: 1966\n\nPrime 5 righe:\n                   id sentiment  \\\n0  638060586258038784   neutral   \n1  638061181823922176  positive   \n2  638083821364244480   neutral   \n3  638091450132078593  positive   \n4  638125563790557184  positive   \n\n                                                text  \n0  05 Beat it - Michael Jackson - Thriller (25th ...  \n1  Jay Z joins Instagram with nostalgic tribute t...  \n2  Michael Jackson: Bad 25th Anniversary Edition ...  \n3  I liked a @YouTube video http://t.co/AaR3pjp2P...  \n4  18th anniv of Princess Diana's death. I still ...   \n\nDati mancanti per colonna:\nid           0\nsentiment    0\ntext         0\ndtype: int64 \n\nDistribuzione delle classi:\n     Classe  Conteggio  Percentuale\n0  positive        829    42.166836\n1   neutral        746    37.945066\n2  negative        391    19.888098 \n\n\n--- Analisi Test ---\nNumero di esempi nel Test: 2000\n\nPrime 5 righe:\n                   id sentiment  \\\n0  637641175948763136   neutral   \n1  637651487762554881   neutral   \n2  637666734300905472  negative   \n3  637668142110654468   neutral   \n4  637708370129125377  positive   \n\n                                                text  \n0  @SeeMonterey LOST - Sony cell phone with holid...  \n1  @PersonaSoda well yeah, that's third parties. ...  \n2  Sony rewards app is like a lot of 19 y.o femal...  \n3  @fakethom Have android tab and don't use phone...  \n4  Finally I get my ps4 back I sent it to Sony ca...   \n\nDati mancanti per colonna:\nid           0\nsentiment    0\ntext         0\ndtype: int64 \n\nDistribuzione delle classi:\n     Classe  Conteggio  Percentuale\n0  positive        994        49.70\n1   neutral        681        34.05\n2  negative        325        16.25 \n\n\n\n","output_type":"stream"}],"execution_count":36},{"cell_type":"markdown","source":"### 2. Sentiment140\n\nIl dataset **Sentiment140** è stato creato per l'analisi del sentiment sui tweet,  annotati manualmente con etichette positivo, negativo o neutro.  Le etichette di sentiment sono generate automaticamente basandosi sulle emoticon presenti nei tweet.\n\n**Caratteristiche del dataset**\n\n- **Task**: Sentiment analysis sui tweet.  \n\n- **Tipo di task**: Classificazione binaria. Ogni tweet è etichettato come positivo (4), neutro (2) o negativo (0).\n\n- **Dominio**: I tweet provengono da Twitter e trattano una vasta gamma di argomenti, tra cui notizie, eventi, opinioni e discussioni su temi vari.\n\n- **Struttura del dataset**: Ogni esempio contiene:\n    - **sentiment**: etichetta binaria che indica se il sentiment del tweet è positivo (4), neutro (2) o negativo (0).\n    - **id**: identificativo univoco del tweet.\n    - **date**: data e ora di pubblicazione del tweet.\n    - **query**: tipo di ricerca che ha generato il tweet (in genere \"TwitterSearch\").\n    - **user**: nome utente di chi ha scritto il tweet.\n    - **text**: il testo del tweet.\n\n**Nota bene**\n- Il training set contiene due tipi etichette pari a positivo (4) e negativo (0), il test set contiene tre tipi di etichette positivo (4), neutro (2) e negativo (0).","metadata":{}},{"cell_type":"code","source":"# Ottenimento del dataset\n\nsent140_dataset = load_dataset(\"stanfordnlp/sentiment140\")\n\nprint(sent140_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:43:09.452470Z","iopub.execute_input":"2025-01-22T16:43:09.452810Z","iopub.status.idle":"2025-01-22T16:44:24.781337Z","shell.execute_reply.started":"2025-01-22T16:43:09.452766Z","shell.execute_reply":"2025-01-22T16:44:24.780324Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/6.84k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a8844c29d354a6ba9d6d73e048a409e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentiment140.py:   0%|          | 0.00/4.03k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a1967e170c4465b96beab2d5184debe"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository for stanfordnlp/sentiment140 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/stanfordnlp/sentiment140.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/81.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2f4af29586246f89785e5efc22d3666"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1600000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a891d2e5404463899a9070bd8f9eb9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/498 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc35e47aa6da49ac84a12663fd994942"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'date', 'user', 'sentiment', 'query'],\n        num_rows: 1600000\n    })\n    test: Dataset({\n        features: ['text', 'date', 'user', 'sentiment', 'query'],\n        num_rows: 498\n    })\n})\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"train_data = sent140_dataset[\"train\"]\ntest_data = sent140_dataset[\"test\"]\n\nprint(\"--- Dimensioni del dataset ---\")\nprint(f\"Train set: {len(train_data)} esempi\")\nprint(f\"Test set: {len(test_data)} esempi\")\nprint(f\"Totale: {len(train_data) + len(test_data)} esempi\\n\")\n\n# Analisi dei tre split del dataset\nanalyze_data(\"Train\", train_data, \"sentiment\")\nanalyze_data(\"Test\", test_data, \"sentiment\")\nprint('')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:44:24.782542Z","iopub.execute_input":"2025-01-22T16:44:24.782880Z","iopub.status.idle":"2025-01-22T16:45:38.259455Z","shell.execute_reply.started":"2025-01-22T16:44:24.782845Z","shell.execute_reply":"2025-01-22T16:45:38.258688Z"}},"outputs":[{"name":"stdout","text":"--- Dimensioni del dataset ---\nTrain set: 1600000 esempi\nTest set: 498 esempi\nTotale: 1600498 esempi\n\n--- Analisi Train ---\nNumero di esempi nel Train: 1600000\n\nPrime 5 righe:\n                                                text  \\\n0  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n1  is upset that he can't update his Facebook by ...   \n2  @Kenichan I dived many times for the ball. Man...   \n3    my whole body feels itchy and like its on fire    \n4  @nationwideclass no, it's not behaving at all....   \n\n                           date             user  sentiment     query  \n0  Mon Apr 06 22:19:45 PDT 2009  _TheSpecialOne_          0  NO_QUERY  \n1  Mon Apr 06 22:19:49 PDT 2009    scotthamilton          0  NO_QUERY  \n2  Mon Apr 06 22:19:53 PDT 2009         mattycus          0  NO_QUERY  \n3  Mon Apr 06 22:19:57 PDT 2009          ElleCTF          0  NO_QUERY  \n4  Mon Apr 06 22:19:57 PDT 2009           Karoli          0  NO_QUERY   \n\nDati mancanti per colonna:\ntext         0\ndate         0\nuser         0\nsentiment    0\nquery        0\ndtype: int64 \n\nDistribuzione delle classi:\n   Classe  Conteggio  Percentuale\n0       0     800000         50.0\n1       4     800000         50.0 \n\n\n--- Analisi Test ---\nNumero di esempi nel Test: 498\n\nPrime 5 righe:\n                                                text  \\\n0  @stellargirl I loooooooovvvvvveee my Kindle2. ...   \n1  Reading my kindle2...  Love it... Lee childs i...   \n2  Ok, first assesment of the #kindle2 ...it fuck...   \n3  @kenburbary You'll love your Kindle2. I've had...   \n4  @mikefish  Fair enough. But i have the Kindle2...   \n\n                           date      user  sentiment    query  \n0  Mon May 11 03:17:40 UTC 2009    tpryan          4  kindle2  \n1  Mon May 11 03:18:03 UTC 2009    vcu451          4  kindle2  \n2  Mon May 11 03:18:54 UTC 2009    chadfu          4  kindle2  \n3  Mon May 11 03:19:04 UTC 2009     SIX15          4  kindle2  \n4  Mon May 11 03:21:41 UTC 2009  yamarama          4  kindle2   \n\nDati mancanti per colonna:\ntext         0\ndate         0\nuser         0\nsentiment    0\nquery        0\ndtype: int64 \n\nDistribuzione delle classi:\n   Classe  Conteggio  Percentuale\n0       4        182    36.546185\n1       0        177    35.542169\n2       2        139    27.911647 \n\n\n\n","output_type":"stream"}],"execution_count":38},{"cell_type":"markdown","source":"### 3. Amazon Product Reviews\n\nIl dataset **Amazon Product Reviews (2023)** contiene recensioni di prodotti tratte da Amazon, ed è stato progettato per valutare i modelli sul task di analisi del sentiment. Le recensioni sono suddivise in numerose categorie di prodotti, ciascuna delle quali consente di ottenere un dataset specifico. Maggiori informazioni: https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023.\n\n\n**Caratteristiche del dataset**\n\n- **Task**: Sentiment analysis.  \n  Determinare quanto sia buona una recensione, assegnando un punteggio che va da 1 a 5, dove 1 indica una recensione molto negativa e 5 una recensione molto positiva.\n  \n- **Tipo di task**: **Classificazione multiclasse**. Ogni recensione è etichettata con un punteggio da 1.0 a 5.0.\n\n- **Dominio**: Le recensioni coprono una vasta gamma di categorie di prodotti, come elettronica, abbigliamento, giocattoli, articoli per la casa, e molto altro.\n\n- **Struttura del dataset**: Il dataset contiene molte features, quelle strettamente necessarie sono:\n  - **rating**: il rating numerico assegnato dal recensore al prodotto, compreso tra 1.0 e 5.0.\n  - **text**: il testo della recensione.\n\n**Nota bene**  \n- **Classi sbilanciate**.\n- I dati sono inseriti in un unico file, non solo  divisi in training set,validation set e testd set.\n","metadata":{}},{"cell_type":"code","source":"# Ottenimento del dataset\ndataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_review_Magazine_Subscriptions\", trust_remote_code=True)\n\n# Mantengo solo le features rilevanti\ndataset = pd.DataFrame({\n    'text': dataset['full']['text'], \n    'rating': dataset['full']['rating'], \n})\n\nprint(dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:45:38.261243Z","iopub.execute_input":"2025-01-22T16:45:38.261601Z","iopub.status.idle":"2025-01-22T16:45:41.594687Z","shell.execute_reply.started":"2025-01-22T16:45:38.261564Z","shell.execute_reply":"2025-01-22T16:45:41.593650Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/30.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf4305dbadb140eb8586b0d5adc7c9f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Amazon-Reviews-2023.py:   0%|          | 0.00/39.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ea6c6a6d5794b34b7bac3c32f1744c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Magazine_Subscriptions.jsonl:   0%|          | 0.00/33.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43133ccc391444cea27433ea696da1cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating full split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"194865d2155a41d484953b36b536170e"}},"metadata":{}},{"name":"stdout","text":"                                                    text  rating\n0                    Wonderful recipes in this magazine.     5.0\n1      Great sports magazine that's on my 9 year olds...     4.0\n2      \"Joy of Kosher\" magazine fills a much-needed n...     5.0\n3      I've been addicted to Martha Stewart's Everyda...     5.0\n4                                          Too many ads!     1.0\n...                                                  ...     ...\n71492  I subscribe to three car magazines. Road and T...     5.0\n71493  Though the magazine covers the industry well I...     4.0\n71494  My daughter wanted to subscribe to a magazine ...     5.0\n71495  Dear Sirs,<br /><br />Two days ago I ordered H...     2.0\n71496  I've been backpacking for years & I've subscri...     5.0\n\n[71497 rows x 2 columns]\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_data, temp_data = train_test_split(dataset, test_size=0.2, random_state=42)\n\nval_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n\nprint(\"--- Dimensioni del dataset ---\")\nprint(f\"Train set: {len(train_data)} esempi\")\nprint(f\"Validation set: {len(val_data)} esempi\")\nprint(f\"Test set: {len(test_data)} esempi\")\nprint(f\"Totale: {len(train_data) + len(val_data) + len(test_data)} esempi\\n\")\n\n# Analisi dei tre split del dataset\nanalyze_data_stsb(\"Train\", train_data, \"rating\")\nanalyze_data_stsb(\"Validation\", val_data, \"rating\")\nanalyze_data_stsb(\"Test\", test_data, \"rating\")\nprint('')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:45:41.596065Z","iopub.execute_input":"2025-01-22T16:45:41.596400Z","iopub.status.idle":"2025-01-22T16:45:41.891787Z","shell.execute_reply.started":"2025-01-22T16:45:41.596364Z","shell.execute_reply":"2025-01-22T16:45:41.890643Z"}},"outputs":[{"name":"stdout","text":"--- Dimensioni del dataset ---\nTrain set: 57197 esempi\nValidation set: 7150 esempi\nTest set: 7150 esempi\nTotale: 71497 esempi\n\n--- Analisi Train ---\nNumero di esempi nel Train: 57197\n\nPrime 5 righe:\n                                                    text  rating\n20189   The writing isn't great, but it's lovely anyway.     5.0\n8477                                      Great product.     5.0\n59215                                   Only 2 showed up     1.0\n40333  Time slants news to the Liberal Left plus this...     4.0\n11092  This is a really great magazine for history bu...     5.0 \n\nDati mancanti per colonna:\ntext      0\nrating    0\ndtype: int64 \n\nDistribuzione delle classi (intervalli di punteggio):\n  Intervallo  Conteggio  Percentuale\n0       -1-0          0     0.000000\n1        0-1          0     0.000000\n2        1-2       7718    13.493715\n3        2-3       3166     5.535255\n4        3-4       4060     7.098274\n5        4-5       6561    11.470881\n6        5-6      35692    62.401874\n7        6-7          0     0.000000 \n\n\n--- Analisi Validation ---\nNumero di esempi nel Validation: 7150\n\nPrime 5 righe:\n                                                    text  rating\n70436  I have been buying copies of this magazine in ...     5.0\n64052  NG standard for young people. Easy to read, fu...     5.0\n57310  My daughter has been receiving this as a gift ...     4.0\n48427  I really enjoyed the first issue. Sure, it is ...     5.0\n7917   I haven't gotten it. I love these shows and wo...     1.0 \n\nDati mancanti per colonna:\ntext      0\nrating    0\ndtype: int64 \n\nDistribuzione delle classi (intervalli di punteggio):\n  Intervallo  Conteggio  Percentuale\n0       -1-0          0     0.000000\n1        0-1          0     0.000000\n2        1-2        947    13.244755\n3        2-3        370     5.174825\n4        3-4        499     6.979021\n5        4-5        894    12.503497\n6        5-6       4440    62.097902\n7        6-7          0     0.000000 \n\n\n--- Analisi Test ---\nNumero di esempi nel Test: 7150\n\nPrime 5 righe:\n                                                    text  rating\n44880                    Good magazine, pretty pictures.     5.0\n34981  I find myself becoming less and less of a fan ...     1.0\n50484             Love reading, Lots of helpful hints...     5.0\n32498  The main target audience of Writer's Digest ap...     2.0\n67734                       I like the helpful how to's.     5.0 \n\nDati mancanti per colonna:\ntext      0\nrating    0\ndtype: int64 \n\nDistribuzione delle classi (intervalli di punteggio):\n  Intervallo  Conteggio  Percentuale\n0       -1-0          0     0.000000\n1        0-1          0     0.000000\n2        1-2       1020    14.265734\n3        2-3        417     5.832168\n4        3-4        474     6.629371\n5        4-5        751    10.503497\n6        5-6       4488    62.769231\n7        6-7          0     0.000000 \n\n\n\n","output_type":"stream"}],"execution_count":40},{"cell_type":"markdown","source":"## Dataset per la classificazione","metadata":{}},{"cell_type":"markdown","source":"### 1. AG News\n\nIl dataset **AG News** è una raccolta di articoli di notizie che permette di valutare i modelli NLP sul task di classificazione di testi in categorie tematiche. \n\nMaggiori informazioni: [AG News Dataset](https://huggingface.co/datasets/ag_news).\n\n  \n\n**Caratteristiche del dataset**\n\n- **Task**: Classificazione.  \n  Assegnare ogni articolo a una delle quattro categorie predefinite: **World**, **Sports**, **Business**, e **Sci/Tech**.\n\n- **Tipo di task**: **Classificazione multiclasse**. Ogni articolo è associato a una sola categoria.\n\n- **Dominio**: Le notizie trattano 4 argomenti: notizie internazionali, notizie sportive, economia e affari, scienza e tecnologia.\n\n- **Struttura del dataset**:  \n Ogni esempio contiene:\n  - **label**: La categoria tematica assegnata all'articolo:  0: **World**, 1: **Sports**, 2: **Business**, 3: **Sci/Tech**).\n  - **text**: Il titolo dell'articolo seguito da una sua breve descrizione.\n\n**Nota bene**  \n- I dati sono organizzati in training set e test set. Non è fornito un validation set.","metadata":{}},{"cell_type":"code","source":"# Ottenimento del dataset\n\nag_dataset = load_dataset(\"ag_news\")\n\nprint(ag_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:45:41.892830Z","iopub.execute_input":"2025-01-22T16:45:41.893144Z","iopub.status.idle":"2025-01-22T16:45:43.972137Z","shell.execute_reply.started":"2025-01-22T16:45:41.893112Z","shell.execute_reply":"2025-01-22T16:45:43.971317Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/8.07k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fbc88189c1842b68b2553d52fb201d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/18.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f062fc59de74f3780962b167f958582"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/1.23M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"108a18a33180460082bebaeb53c6cb87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a95b61af7060498094e23bd691cde6cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62806e0c5b424fe4b737e086d930ba09"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 120000\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 7600\n    })\n})\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"train_data = ag_dataset[\"train\"]\ntest_data = ag_dataset[\"test\"]\n\nprint(\"--- Dimensioni del dataset ---\")\nprint(f\"Train set: {len(train_data)} esempi\")\nprint(f\"Test set: {len(test_data)} esempi\")\nprint(f\"Totale: {len(train_data) + len(test_data)} esempi\\n\")\n\n# Analisi dei tre split del dataset\nanalyze_data(\"Train\", train_data, \"label\")\nanalyze_data(\"Test\", test_data, \"label\")\nprint('')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:45:43.973161Z","iopub.execute_input":"2025-01-22T16:45:43.973410Z","iopub.status.idle":"2025-01-22T16:45:46.941027Z","shell.execute_reply.started":"2025-01-22T16:45:43.973385Z","shell.execute_reply":"2025-01-22T16:45:46.939931Z"}},"outputs":[{"name":"stdout","text":"--- Dimensioni del dataset ---\nTrain set: 120000 esempi\nTest set: 7600 esempi\nTotale: 127600 esempi\n\n--- Analisi Train ---\nNumero di esempi nel Train: 120000\n\nPrime 5 righe:\n                                                text  label\n0  Wall St. Bears Claw Back Into the Black (Reute...      2\n1  Carlyle Looks Toward Commercial Aerospace (Reu...      2\n2  Oil and Economy Cloud Stocks' Outlook (Reuters...      2\n3  Iraq Halts Oil Exports from Main Southern Pipe...      2\n4  Oil prices soar to all-time record, posing new...      2 \n\nDati mancanti per colonna:\ntext     0\nlabel    0\ndtype: int64 \n\nDistribuzione delle classi:\n   Classe  Conteggio  Percentuale\n0       2      30000         25.0\n1       3      30000         25.0\n2       1      30000         25.0\n3       0      30000         25.0 \n\n\n--- Analisi Test ---\nNumero di esempi nel Test: 7600\n\nPrime 5 righe:\n                                                text  label\n0  Fears for T N pension after talks Unions repre...      2\n1  The Race is On: Second Private Team Sets Launc...      3\n2  Ky. Company Wins Grant to Study Peptides (AP) ...      3\n3  Prediction Unit Helps Forecast Wildfires (AP) ...      3\n4  Calif. Aims to Limit Farm-Related Smog (AP) AP...      3 \n\nDati mancanti per colonna:\ntext     0\nlabel    0\ndtype: int64 \n\nDistribuzione delle classi:\n   Classe  Conteggio  Percentuale\n0       2       1900         25.0\n1       3       1900         25.0\n2       1       1900         25.0\n3       0       1900         25.0 \n\n\n\n","output_type":"stream"}],"execution_count":42},{"cell_type":"markdown","source":"### 2. Emotion Dataset\n\nIl dataset **Emotion Dataset** è una raccolta di tweet che permette di valutare modelli NLP sul task di analisi delle emozioni. Ogni tweet è etichettato con una delle sei emozioni predefinite. Maggiori informazioni: [Emotion Dataset](https://huggingface.co/datasets/dair-ai/emotion).\n\n\n**Caratteristiche del dataset**\n\n- **Task**: Rilevazione delle emozioni.  \n  Classificare ogni tweet in base all'emozione predominante.\n\n- **Tipo di task**: **Classificazione multiclasse**. Ogni tweet è associato a una sola emozione.\n\n- **Dominio**: I tweet coprono una vasta gamma di argomenti, riflettendo emozioni umane comuni tra cui gioia, tristezza, rabbia, paura, amore, sorpresa.\n\n- **Struttura del dataset**:  \n  Ogni esempio contiene:\n  - **text**: Il testo del tweet.\n  - **label**: L'emozione associata al tweet, rappresentata come una stringa.\n\n**Nota bene**  \n- **Classi sbilanciate**.","metadata":{}},{"cell_type":"code","source":"# Ottenimento del dataset\n\nemotion_dataset = load_dataset(\"dair-ai/emotion\")\n\nprint(emotion_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:45:46.943454Z","iopub.execute_input":"2025-01-22T16:45:46.943766Z","iopub.status.idle":"2025-01-22T16:45:48.667942Z","shell.execute_reply.started":"2025-01-22T16:45:46.943741Z","shell.execute_reply":"2025-01-22T16:45:48.667020Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/9.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"242c57eb27404fcca2fc949c0acc68b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/1.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aaf97e06d4b142d8b7a4c385fae1e9ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/127k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b4de160d1b149ad996a845650459748"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/129k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc216110d6d345739b8c46367fbf46d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/16000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a1bf6c134b444fabd223a3835442382"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bcd76b4229140cf8d72923646cda908"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"420edfbb2ef447529477f39929a552d2"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 16000\n    })\n    validation: Dataset({\n        features: ['text', 'label'],\n        num_rows: 2000\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 2000\n    })\n})\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"train_data = emotion_dataset[\"train\"]\nval_data = emotion_dataset[\"validation\"]\ntest_data = emotion_dataset[\"test\"]\n\nprint(\"--- Dimensioni del dataset ---\")\nprint(f\"Train set: {len(train_data)} esempi\")\nprint(f\"Validation set: {len(val_data)} esempi\")\nprint(f\"Test set: {len(test_data)} esempi\")\nprint(f\"Totale: {len(train_data) + len(val_data) + len(test_data)} esempi\\n\")\n\n# Analisi dei tre split del dataset\nanalyze_data(\"Train\", train_data, \"label\")\nanalyze_data(\"Validation\", val_data, \"label\")\nanalyze_data(\"Test\", test_data, \"label\")\nprint('')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:45:48.668936Z","iopub.execute_input":"2025-01-22T16:45:48.669192Z","iopub.status.idle":"2025-01-22T16:45:49.222239Z","shell.execute_reply.started":"2025-01-22T16:45:48.669171Z","shell.execute_reply":"2025-01-22T16:45:49.221243Z"}},"outputs":[{"name":"stdout","text":"--- Dimensioni del dataset ---\nTrain set: 16000 esempi\nValidation set: 2000 esempi\nTest set: 2000 esempi\nTotale: 20000 esempi\n\n--- Analisi Train ---\nNumero di esempi nel Train: 16000\n\nPrime 5 righe:\n                                                text  label\n0                            i didnt feel humiliated      0\n1  i can go from feeling so hopeless to so damned...      0\n2   im grabbing a minute to post i feel greedy wrong      3\n3  i am ever feeling nostalgic about the fireplac...      2\n4                               i am feeling grouchy      3 \n\nDati mancanti per colonna:\ntext     0\nlabel    0\ndtype: int64 \n\nDistribuzione delle classi:\n   Classe  Conteggio  Percentuale\n0       1       5362     33.51250\n1       0       4666     29.16250\n2       3       2159     13.49375\n3       4       1937     12.10625\n4       2       1304      8.15000\n5       5        572      3.57500 \n\n\n--- Analisi Validation ---\nNumero di esempi nel Validation: 2000\n\nPrime 5 righe:\n                                                text  label\n0  im feeling quite sad and sorry for myself but ...      0\n1  i feel like i am still looking at a blank canv...      0\n2                     i feel like a faithful servant      2\n3                  i am just feeling cranky and blue      3\n4  i can have for a treat or if i am feeling festive      1 \n\nDati mancanti per colonna:\ntext     0\nlabel    0\ndtype: int64 \n\nDistribuzione delle classi:\n   Classe  Conteggio  Percentuale\n0       1        704        35.20\n1       0        550        27.50\n2       3        275        13.75\n3       4        212        10.60\n4       2        178         8.90\n5       5         81         4.05 \n\n\n--- Analisi Test ---\nNumero di esempi nel Test: 2000\n\nPrime 5 righe:\n                                                text  label\n0  im feeling rather rotten so im not very ambiti...      0\n1          im updating my blog because i feel shitty      0\n2  i never make her separate from me because i do...      0\n3  i left with my bouquet of red and yellow tulip...      1\n4    i was feeling a little vain when i did this one      0 \n\nDati mancanti per colonna:\ntext     0\nlabel    0\ndtype: int64 \n\nDistribuzione delle classi:\n   Classe  Conteggio  Percentuale\n0       1        695        34.75\n1       0        581        29.05\n2       3        275        13.75\n3       4        224        11.20\n4       2        159         7.95\n5       5         66         3.30 \n\n\n\n","output_type":"stream"}],"execution_count":44},{"cell_type":"markdown","source":"### 3. Yahoo Answers Topics\n\nIl dataset **Yahoo Answers Topics** è una raccolta di domande e risposte tratte dalla piattaforma Yahoo Answers, progettata per valutare i modelli NLP sul task di classificazione in categorie tematiche.  \nMaggiori informazioni: [Yahoo Answers Topics Dataset](https://huggingface.co/datasets/yahoo_answers_topics).\n\n\n\n**Caratteristiche del dataset**\n\n- **Task**: Classificazione.  \n  Assegnare ogni domanda a una delle dieci categorie predefinite.\n\n- **Tipo di task**: **Classificazione multiclasse**. Ogni domanda è associata a una sola categoria.\n\n- **Dominio**: Le domande coprono un'ampia gamma di argomenti suddivisi in 10 categorie:  \n  0: **Society & Culture**,  \n  1: **Science & Mathematics**,  \n  2: **Health**,  \n  3: **Education & Reference**,  \n  4: **Computers & Internet**,  \n  5: **Sports**,  \n  6: **Business & Finance**,  \n  7: **Entertainment & Music**,  \n  8: **Family & Relationships**,  \n  9: **Politics & Government**.\n\n- **Struttura del dataset**:  \n  Ogni esempio contiene:\n  - **id**: identificativo dell'esempio \n  - **topic**: La categoria tematica assegnata alla domanda (da 0 a 9).\n  - **question_title**: Il titolo della domanda.\n  - **question_content**: Il contenuto dettagliato della domanda.\n  - **best_answer**: La risposta considerata migliore.\n\n---\n\n**Nota bene**  \n- I dati sono organizzati in training set e test set. Non è fornito un validation set. ","metadata":{}},{"cell_type":"code","source":"# Ottenimento del dataset\n\nyahoo_dataset = load_dataset(\"community-datasets/yahoo_answers_topics\")\n\nprint(yahoo_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:46:06.702309Z","iopub.execute_input":"2025-01-22T16:46:06.702623Z","iopub.status.idle":"2025-01-22T16:46:21.071492Z","shell.execute_reply.started":"2025-01-22T16:46:06.702598Z","shell.execute_reply":"2025-01-22T16:46:21.070472Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/5.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a2660fa6c7e48048bfa7a524ed8e045"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00002.parquet:   0%|          | 0.00/241M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b83dee42cd744564bbb756753367ffe2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00001-of-00002.parquet:   0%|          | 0.00/270M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea25e6e1a4f94380ab4a368d505aafe2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/21.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bedd9d34edf4a2da3dbe36b3865934c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1400000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b90997c5e3640f7a00db26100342680"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/60000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eaf96cf65c5f47e6a28cb2efb30389b7"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'topic', 'question_title', 'question_content', 'best_answer'],\n        num_rows: 1400000\n    })\n    test: Dataset({\n        features: ['id', 'topic', 'question_title', 'question_content', 'best_answer'],\n        num_rows: 60000\n    })\n})\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"train_data = yahoo_dataset[\"train\"]\ntest_data = yahoo_dataset[\"test\"]\n\nprint(\"--- Dimensioni del dataset ---\")\nprint(f\"Train set: {len(train_data)} esempi\")\nprint(f\"Test set: {len(test_data)} esempi\")\nprint(f\"Totale: {len(train_data)  + len(test_data)} esempi\\n\")\n\n# Analisi dei tre split del dataset\nanalyze_data(\"Train\", train_data, \"topic\")\nanalyze_data(\"Test\", test_data, \"topic\")\nprint('')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:46:21.072985Z","iopub.execute_input":"2025-01-22T16:46:21.073382Z","iopub.status.idle":"2025-01-22T16:47:29.769222Z","shell.execute_reply.started":"2025-01-22T16:46:21.073345Z","shell.execute_reply":"2025-01-22T16:47:29.768249Z"}},"outputs":[{"name":"stdout","text":"--- Dimensioni del dataset ---\nTrain set: 1400000 esempi\nTest set: 60000 esempi\nTotale: 1460000 esempi\n\n--- Analisi Train ---\nNumero di esempi nel Train: 1400000\n\nPrime 5 righe:\n   id  topic                                     question_title  \\\n0   0      4  why doesn't an optical mouse work on a glass t...   \n1   1      5       What is the best off-road motorcycle trail ?   \n2   2      2             What is Trans Fat? How to reduce that?   \n3   3      6                         How many planes Fedex has?   \n4   4      6  In the san francisco bay area, does it make se...   \n\n                                    question_content  \\\n0                          or even on some surfaces?   \n1                  long-distance trail throughout CA   \n2  I heard that tras fat is bad for the body.  Wh...   \n3  I heard that it is the largest airline in the ...   \n4  the prices of rent and the price of buying doe...   \n\n                                         best_answer  \n0  Optical mice use an LED and a camera to rapidl...  \n1  i hear that the mojave road is amazing!<br />\\...  \n2  Trans fats occur in manufactured foods during ...  \n3  according to the www.fedex.com web site:\\nAir ...  \n4  renting vs buying depends on your goals. <br /...   \n\nDati mancanti per colonna:\nid                  0\ntopic               0\nquestion_title      0\nquestion_content    0\nbest_answer         0\ndtype: int64 \n\nDistribuzione delle classi:\n   Classe  Conteggio  Percentuale\n0       4     140000         10.0\n1       5     140000         10.0\n2       2     140000         10.0\n3       6     140000         10.0\n4       1     140000         10.0\n5       7     140000         10.0\n6       3     140000         10.0\n7       8     140000         10.0\n8       9     140000         10.0\n9       0     140000         10.0 \n\n\n--- Analisi Test ---\nNumero di esempi nel Test: 60000\n\nPrime 5 righe:\n   id  topic                                     question_title  \\\n0   0      8                       What makes friendship click?   \n1   1      1                      Why does Zebras have stripes?   \n2   2      3           What did the itsy bitsy sipder climb up?   \n3   3      3  What is the difference between a Bachelors and...   \n4   4      2                              Why do women get PMS?   \n\n                                    question_content  \\\n0                     How does the spark keep going?   \n1  What is the purpose or those stripes? Who do t...   \n2                                                      \n3                                                      \n4                                                      \n\n                                         best_answer  \n0  good communication is what does it.  Can you m...  \n1  this provides camouflage - predator vision is ...  \n2                                         waterspout  \n3  One difference between a Bachelors and a Maste...  \n4  Premenstrual syndrome (PMS) is a group of symp...   \n\nDati mancanti per colonna:\nid                  0\ntopic               0\nquestion_title      0\nquestion_content    0\nbest_answer         0\ndtype: int64 \n\nDistribuzione delle classi:\n   Classe  Conteggio  Percentuale\n0       8       6000         10.0\n1       1       6000         10.0\n2       3       6000         10.0\n3       2       6000         10.0\n4       4       6000         10.0\n5       7       6000         10.0\n6       6       6000         10.0\n7       9       6000         10.0\n8       0       6000         10.0\n9       5       6000         10.0 \n\n\n\n","output_type":"stream"}],"execution_count":46},{"cell_type":"markdown","source":"### 4. Toxic Comment Classification\n\nIl dataset **Toxic Comment Classification** è una raccolta di commenti provenienti da discussioni online, progettata per valutare i modelli NLP sul task di classificazione multilabel di commenti tossici.  \nMaggiori informazioni: [Toxic Comment Classification Dataset](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge).\n  \n  \n**Caratteristiche del dataset**\n\n- **Task**: Classificazione multilabel.  \n  Identificare la presenza di uno o più tipi di tossicità all'interno di un commento.\n\n- **Tipo di task**: **Classificazione multilabel**. Ogni commento può appartenere a una o più delle seguenti categorie: **toxic**, **severe_toxic**, **obscene**, **threat**, **insult**, **identity_hate**.\n\n- **Dominio**: I commenti provangono da Wikipedia.\n\n- **Struttura del dataset**:  \n  Ogni esempio contiene:\n  - **id**: identificatore univoco del commento.  \n  - **comment_text**: il testo del commento.  \n  - **toxic**, **severe_toxic**, **obscene**, **threat**, **insult**, **identity_hate**: Colonne binarie che indicano se il commento appartiene alla rispettiva categoria (1 = sì, 0 = no).\n\n\n**Nota bene**  \n- I dati sono organizzati in training set e test set. Non è fornito un validation set.  \n- Il dataset è sbilanciato.","metadata":{}},{"cell_type":"code","source":"# Ottenimento del dataset\n\ntoxic_dataset = pd.read_csv('/kaggle/input/toxisity-detection-dataset/train.csv')\n\nprint(toxic_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:47:29.770987Z","iopub.execute_input":"2025-01-22T16:47:29.771240Z","iopub.status.idle":"2025-01-22T16:47:31.443102Z","shell.execute_reply.started":"2025-01-22T16:47:29.771217Z","shell.execute_reply":"2025-01-22T16:47:31.442266Z"}},"outputs":[{"name":"stdout","text":"                      id                                       comment_text  \\\n0       0000997932d777bf  Explanation\\nWhy the edits made under my usern...   \n1       000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n2       000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n3       0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...   \n4       0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n...                  ...                                                ...   \n159566  ffe987279560d7ff  \":::::And for the second time of asking, when ...   \n159567  ffea4adeee384e90  You should be ashamed of yourself \\n\\nThat is ...   \n159568  ffee36eab5c267c9  Spitzer \\n\\nUmm, theres no actual article for ...   \n159569  fff125370e4aaaf3  And it looks like it was actually you who put ...   \n159570  fff46fc426af1f9a  \"\\nAnd ... I really don't think you understand...   \n\n        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n0           0             0        0       0       0              0  \n1           0             0        0       0       0              0  \n2           0             0        0       0       0              0  \n3           0             0        0       0       0              0  \n4           0             0        0       0       0              0  \n...       ...           ...      ...     ...     ...            ...  \n159566      0             0        0       0       0              0  \n159567      0             0        0       0       0              0  \n159568      0             0        0       0       0              0  \n159569      0             0        0       0       0              0  \n159570      0             0        0       0       0              0  \n\n[159571 rows x 8 columns]\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"import pandas as pd\n\ndef analyze_data_toxic(name, data, class_columns):\n    print(f\"--- Analisi {name} ---\")\n    df = pd.DataFrame(data)\n    \n    # Dimensioni\n    print(f\"Numero di esempi nel {name}: {len(df)}\\n\")\n    \n    # Prime righe\n    print(\"Prime 5 righe:\")\n    print(df.head(), \"\\n\")\n    \n    # Dati mancanti\n    print(\"Dati mancanti per colonna:\")\n    print(df.isnull().sum(), \"\\n\")\n    \n    # Distribuzione delle classi\n    print(\"Distribuzione delle classi (colonne binarie):\")\n    distribution_table = []\n    \n    for col in class_columns:\n        total_positive = df[col].sum()\n        percentage_positive = (total_positive / len(df)) * 100\n        distribution_table.append({\n            'Colonna': col,\n            'Positivi': total_positive,\n            'Percentuale': percentage_positive\n        })\n    \n    distribution_df = pd.DataFrame(distribution_table)\n    print(distribution_df, \"\\n\\n\")\n    \n    return df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:47:31.444388Z","iopub.execute_input":"2025-01-22T16:47:31.444702Z","iopub.status.idle":"2025-01-22T16:47:31.450362Z","shell.execute_reply.started":"2025-01-22T16:47:31.444677Z","shell.execute_reply":"2025-01-22T16:47:31.449392Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_data, temp_data = train_test_split(toxic_dataset, test_size=0.2, random_state=42)\n\nval_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n\nprint(\"--- Dimensioni del dataset ---\")\nprint(f\"Train set: {len(train_data)} esempi\")\nprint(f\"Validation set: {len(val_data)} esempi\")\nprint(f\"Test set: {len(test_data)} esempi\")\nprint(f\"Totale: {len(train_data) + len(val_data) + len(test_data)} esempi\\n\")\n    \n# Analisi dei tre split del dataset\nclass_columns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\nanalyze_data_toxic(\"Train\", train_data, class_columns)\nanalyze_data_toxic(\"Validation\", val_data, class_columns)\nanalyze_data_toxic(\"Test\", test_data, class_columns)\nprint('')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:47:31.451277Z","iopub.execute_input":"2025-01-22T16:47:31.451575Z","iopub.status.idle":"2025-01-22T16:47:31.558773Z","shell.execute_reply.started":"2025-01-22T16:47:31.451544Z","shell.execute_reply":"2025-01-22T16:47:31.557804Z"}},"outputs":[{"name":"stdout","text":"--- Dimensioni del dataset ---\nTrain set: 127656 esempi\nValidation set: 15957 esempi\nTest set: 15958 esempi\nTotale: 159571 esempi\n\n--- Analisi Train ---\nNumero di esempi nel Train: 127656\n\nPrime 5 righe:\n                      id                                       comment_text  \\\n140030  ed56f082116dcbd0  Grandma Terri Should Burn in Trash \\nGrandma T...   \n159124  f8e3cd98b63bf401  , 9 May 2009 (UTC)\\nIt would be easiest if you...   \n60006   a09e1bcf10631f9a  \"\\n\\nThe Objectivity of this Discussion is dou...   \n65432   af0ee0066c607eb8              Shelly Shock\\nShelly Shock is. . .( )   \n154979  b734772b1a807e09  I do not care. Refer to Ong Teng Cheong talk p...   \n\n        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n140030      1             0        0       0       0              0  \n159124      0             0        0       0       0              0  \n60006       0             0        0       0       0              0  \n65432       0             0        0       0       0              0  \n154979      0             0        0       0       0              0   \n\nDati mancanti per colonna:\nid               0\ncomment_text     0\ntoxic            0\nsevere_toxic     0\nobscene          0\nthreat           0\ninsult           0\nidentity_hate    0\ndtype: int64 \n\nDistribuzione delle classi (colonne binarie):\n         Colonna  Positivi  Percentuale\n0          toxic     12238     9.586702\n1   severe_toxic      1274     0.997995\n2        obscene      6734     5.275114\n3         threat       404     0.316476\n4         insult      6263     4.906154\n5  identity_hate      1111     0.870308 \n\n\n--- Analisi Validation ---\nNumero di esempi nel Validation: 15957\n\nPrime 5 righe:\n                      id                                       comment_text  \\\n66232   b12aef02af976d9c  yo  \\n\\nyou could at least reply to my message...   \n123586  950b9d303b8200f0  \"A presentation at a major NASA conference is ...   \n20949   374823faa603ba0e  \"\\nYes, It's a Wonderful Life is an example of...   \n97754   0af7a0c2ef4ec980  \"\\nNo, that had nothing to do with it.\\n\\nName...   \n50166   861361ae4b1e6369        Albert Lewis now looks more like it should!   \n\n        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n66232       0             0        0       0       0              0  \n123586      0             0        0       0       0              0  \n20949       0             0        0       0       0              0  \n97754       0             0        0       0       0              0  \n50166       0             0        0       0       0              0   \n\nDati mancanti per colonna:\nid               0\ncomment_text     0\ntoxic            0\nsevere_toxic     0\nobscene          0\nthreat           0\ninsult           0\nidentity_hate    0\ndtype: int64 \n\nDistribuzione delle classi (colonne binarie):\n         Colonna  Positivi  Percentuale\n0          toxic      1536     9.625870\n1   severe_toxic       159     0.996428\n2        obscene       859     5.383217\n3         threat        37     0.231873\n4         insult       806     5.051075\n5  identity_hate       156     0.977627 \n\n\n--- Analisi Test ---\nNumero di esempi nel Test: 15958\n\nPrime 5 righe:\n                      id                                       comment_text  \\\n116051  6c87cef0213e9af7  \"\\nOf course. I feel like the Maxie page could...   \n147354  3b1bbb47929c3354  \"\\n\\nI'll give you time. BTW, \"\"vandalism\"\" is...   \n144159  08ad981dc1154f38  you can't keep me down nigger \\nyou can't keep...   \n28406   4b36136db08a6e32  \"\\n\\nI added them to the page.  Hopefully they...   \n37278   6388a502e378e2b4  Reasons to KEEP my FrontPoint system==\\nCurren...   \n\n        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n116051      0             0        0       0       0              0  \n147354      0             0        0       0       0              0  \n144159      1             1        0       0       1              1  \n28406       0             0        0       0       0              0  \n37278       0             0        0       0       0              0   \n\nDati mancanti per colonna:\nid               0\ncomment_text     0\ntoxic            0\nsevere_toxic     0\nobscene          0\nthreat           0\ninsult           0\nidentity_hate    0\ndtype: int64 \n\nDistribuzione delle classi (colonne binarie):\n         Colonna  Positivi  Percentuale\n0          toxic      1520     9.525003\n1   severe_toxic       162     1.015165\n2        obscene       856     5.364081\n3         threat        37     0.231859\n4         insult       808     5.063291\n5  identity_hate       138     0.864770 \n\n\n\n","output_type":"stream"}],"execution_count":49},{"cell_type":"markdown","source":"### 5. DBpedia 14\n\nIl dataset **DBpedia 14** è una raccolta di documenti Wikipedia classificati in 14 categorie, progettata per valutare i modelli NLP sul task di classificazione di testi in categorie tematiche.  \nMaggiori informazioni: [DBpedia 14 Dataset](https://huggingface.co/datasets/fancyzhx/dbpedia_14).\n\n\n**Caratteristiche del dataset**\n\n- **Task**: Classificazione.  \n  Assegnare ogni articolo a una delle 14 categorie tematiche predefinite.\n  \n- **Tipo di task**: **Classificazione multiclasse**. Ogni articolo è associato a una sola categoria tra le seguenti:\n    - **Company** (0): Aziende e organizzazioni commerciali.\n    - **EducationalInstitution** (1): Istituzioni educative come scuole, università, ecc.\n    - **Artist** (2): Artisti, incluse figure come pittori, musicisti, scrittori, ecc.\n    - **Athlete** (3): Atleti di vari sport.\n    - **OfficeHolder** (4): Persone che occupano posizioni politiche o amministrative.\n    - **MeanOfTransportation** (5): Mezzi di trasporto come automobili, treni, aerei, ecc.\n    - **Building** (6): Edifici, strutture architettoniche.\n    - **NaturalPlace** (7): Luoghi naturali come montagne, fiumi, laghi, ecc.\n    - **Village** (8): Villaggi e piccole comunità.\n    - **Animal** (9): Animali di tutte le specie.\n    - **Plant** (10): Piante e organismi vegetali.\n    - **Album** (11): Album musicali e raccolte di brani.\n    - **Film** (12): Film, opere cinematografiche.\n    - **WrittenWork** (13): Opere scritte come libri, articoli, saggi, ecc.\n\n- **Dominio**: I testi provengono da Wikipedia.\n\n- **Struttura del dataset**:  \n  Ogni esempio contiene:\n  - **title**: Il titolo del documento Wikipedia.\n  - **content**: Il contenuto del documento.\n  - **label**: La categoria tematica assegnata all'articolo.\n  \n**Nota bene**  \n- I dati sono divisi intrain set e test set.","metadata":{}},{"cell_type":"code","source":"#ottenimento del dataset\ntrain_data = pd.read_csv('/kaggle/input/dbpedia-ontology-dataset/train.csv')\ntest_data = pd.read_csv('/kaggle/input/dbpedia-ontology-dataset/test.csv')\nprint(train_data)\n\nprint(\"--- Dimensioni del dataset ---\")\nprint(f\"Train set: {len(train_data)} esempi\")\nprint(f\"Test set: {len(test_data)} esempi\")\nprint(f\"Totale: {len(train_data)  + len(test_data)} esempi\\n\")\n\n# Analisi dei tre split del dataset\nanalyze_data(\"Train\", train_data, \"label\")\nanalyze_data(\"Test\", test_data, \"label\")\nprint('')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:47:31.559833Z","iopub.execute_input":"2025-01-22T16:47:31.560211Z","iopub.status.idle":"2025-01-22T16:47:36.962822Z","shell.execute_reply.started":"2025-01-22T16:47:31.560172Z","shell.execute_reply":"2025-01-22T16:47:36.961999Z"}},"outputs":[{"name":"stdout","text":"        label                              title  \\\n0           0                   E. D. Abbott Ltd   \n1           0                     Schwan-Stabilo   \n2           0                         Q-workshop   \n3           0  Marvell Software Solutions Israel   \n4           0        Bergan Mercy Medical Center   \n...       ...                                ...   \n559995     13                   Barking in Essex   \n559996     13                   Science & Spirit   \n559997     13             The Blithedale Romance   \n559998     13                Razadarit Ayedawbon   \n559999     13           The Vinyl Cafe Notebooks   \n\n                                                  content  \n0        Abbott of Farnham E D Abbott Limited was a Br...  \n1        Schwan-STABILO is a German maker of pens for ...  \n2        Q-workshop is a Polish company located in Poz...  \n3        Marvell Software Solutions Israel known as RA...  \n4        Bergan Mercy Medical Center is a hospital loc...  \n...                                                   ...  \n559995   Barking in Essex is a Black comedy play direc...  \n559996   Science & Spirit is a discontinued American b...  \n559997   The Blithedale Romance (1852) is Nathaniel Ha...  \n559998   Razadarit Ayedawbon (Burmese: ရာဇာဓိရာဇ် အရေး...  \n559999   Vinyl Cafe Notebooks: a collection of essays ...  \n\n[560000 rows x 3 columns]\n--- Dimensioni del dataset ---\nTrain set: 560000 esempi\nTest set: 70000 esempi\nTotale: 630000 esempi\n\n--- Analisi Train ---\nNumero di esempi nel Train: 560000\n\nPrime 5 righe:\n   label                              title  \\\n0      0                   E. D. Abbott Ltd   \n1      0                     Schwan-Stabilo   \n2      0                         Q-workshop   \n3      0  Marvell Software Solutions Israel   \n4      0        Bergan Mercy Medical Center   \n\n                                             content  \n0   Abbott of Farnham E D Abbott Limited was a Br...  \n1   Schwan-STABILO is a German maker of pens for ...  \n2   Q-workshop is a Polish company located in Poz...  \n3   Marvell Software Solutions Israel known as RA...  \n4   Bergan Mercy Medical Center is a hospital loc...   \n\nDati mancanti per colonna:\nlabel      0\ntitle      0\ncontent    0\ndtype: int64 \n\nDistribuzione delle classi:\n    Classe  Conteggio  Percentuale\n0        0      40000     7.142857\n1        1      40000     7.142857\n2        2      40000     7.142857\n3        3      40000     7.142857\n4        4      40000     7.142857\n5        5      40000     7.142857\n6        6      40000     7.142857\n7        7      40000     7.142857\n8        8      40000     7.142857\n9        9      40000     7.142857\n10      10      40000     7.142857\n11      11      40000     7.142857\n12      12      40000     7.142857\n13      13      40000     7.142857 \n\n\n--- Analisi Test ---\nNumero di esempi nel Test: 70000\n\nPrime 5 righe:\n   label                     title  \\\n0      0                     TY KU   \n1      0     Odd Lot Entertainment   \n2      0                    Henkel   \n3      0                GOAT Store   \n4      0  RagWing Aircraft Designs   \n\n                                             content  \n0   TY KU /taɪkuː/ is an American alcoholic bever...  \n1   OddLot Entertainment founded in 2001 by longt...  \n2   Henkel AG & Company KGaA operates worldwide w...  \n3   The GOAT Store (Games Of All Type Store) LLC ...  \n4   RagWing Aircraft Designs (also called the Rag...   \n\nDati mancanti per colonna:\nlabel      0\ntitle      0\ncontent    0\ndtype: int64 \n\nDistribuzione delle classi:\n    Classe  Conteggio  Percentuale\n0        0       5000     7.142857\n1        1       5000     7.142857\n2        2       5000     7.142857\n3        3       5000     7.142857\n4        4       5000     7.142857\n5        5       5000     7.142857\n6        6       5000     7.142857\n7        7       5000     7.142857\n8        8       5000     7.142857\n9        9       5000     7.142857\n10      10       5000     7.142857\n11      11       5000     7.142857\n12      12       5000     7.142857\n13      13       5000     7.142857 \n\n\n\n","output_type":"stream"}],"execution_count":50},{"cell_type":"markdown","source":"### 6. SMS Spam Collection\n\nIl dataset **SMS Spam Collection** è una raccolta di messaggi SMS etichettati, progettata per valutare i modelli NLP nel task di classificazione binaria per identificare i messaggi spam.  \nMaggiori informazioni: [SMS Spam Collection Dataset](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection).\n\n\n**Caratteristiche del dataset**\n\n- **Task**: Classificazione binaria.  \n  Determinare se un messaggio SMS è **spam** (indesiderato) o **ham** (non spam, ossia un messaggio legittimo).\n\n- **Tipo di task**: **Classificazione binaria**. Ogni messaggio è etichettato come spam/ham.\n\n- **Dominio**: I messaggi provengono da una varietà di contesti, inclusi spam pubblicitari, notifiche di servizio e messaggi personali.\n\n- **Struttura del dataset**:  \n  Ogni esempio contiene:\n  - **label**: L'etichetta associata al messaggio, che può essere **spam** o **ham**.\n  - **message**: Il testo del messaggio SMS.\n\n**Nota bene**  \n- I dati sono organizzati in un unico file, non suddivisi in training, validation e test set.\n- Il dataset è sbilanciato, con una maggiore quantità di messaggi legittimi (ham) rispetto ai messaggi spam.","metadata":{}},{"cell_type":"code","source":"# Ottenimento del dataset\n\nsms_dataset = load_dataset(\"ucirvine/sms_spam\")\n\nprint(sms_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:47:36.963748Z","iopub.execute_input":"2025-01-22T16:47:36.964046Z","iopub.status.idle":"2025-01-22T16:47:37.859713Z","shell.execute_reply.started":"2025-01-22T16:47:36.964019Z","shell.execute_reply":"2025-01-22T16:47:37.858817Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/4.98k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c0a57d7d15c48999a3da6420d8062b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/359k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42a72cfd1a2c4328a4d811ae8bf39f98"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/5574 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e7847605b204a7680dfde4a009090a3"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['sms', 'label'],\n        num_rows: 5574\n    })\n})\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"train_data = sms_dataset[\"train\"]\n\nprint(\"--- Dimensioni del dataset ---\")\nprint(f\"Train set: {len(train_data)} esempi\")\nprint(f\"Totale: {len(train_data)} esempi\\n\")\n\n# Analisi dei tre split del dataset\nanalyze_data(\"Train\", train_data,\"label\")\nprint('')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:47:37.862216Z","iopub.execute_input":"2025-01-22T16:47:37.862466Z","iopub.status.idle":"2025-01-22T16:47:38.077357Z","shell.execute_reply.started":"2025-01-22T16:47:37.862440Z","shell.execute_reply":"2025-01-22T16:47:38.076570Z"}},"outputs":[{"name":"stdout","text":"--- Dimensioni del dataset ---\nTrain set: 5574 esempi\nTotale: 5574 esempi\n\n--- Analisi Train ---\nNumero di esempi nel Train: 5574\n\nPrime 5 righe:\n                                                 sms  label\n0  Go until jurong point, crazy.. Available only ...      0\n1                    Ok lar... Joking wif u oni...\\n      0\n2  Free entry in 2 a wkly comp to win FA Cup fina...      1\n3  U dun say so early hor... U c already then say...      0\n4  Nah I don't think he goes to usf, he lives aro...      0 \n\nDati mancanti per colonna:\nsms      0\nlabel    0\ndtype: int64 \n\nDistribuzione delle classi:\n   Classe  Conteggio  Percentuale\n0       0       4827    86.598493\n1       1        747    13.401507 \n\n\n\n","output_type":"stream"}],"execution_count":52},{"cell_type":"markdown","source":"### 7. GoEmotions\n\nIl dataset **GoEmotions** è una raccolta di commenti da Reddit, progettata per valutare i modelli NLP nel task di classificazione delle emozioni. \n\n**Caratteristiche del dataset**\n\n- **Task**: Classificazione.\n  Assegnare a ciascun commento una o più tra 27 emozioni.\n\n- **Tipo di task**: **Classificazione multilabel**. Ogni commento può appartenere a una o più delle seguenti categorie:\n  - **0**: Ammirazione\n  - **1**: Divertimento\n  - **2**: Rabbia\n  - **3**: Fastidio\n  - **4**: Approvazione\n  - **5**: Cura\n  - **6**: Confusione\n  - **7**: Delusione\n  - **8**: Disgusto\n  - **9**: Paura\n  - **10**: Felicità\n  - **11**: Tristezza\n  - **12**: Sorpresa\n  - **13**: Invidia\n  - **14**: Gratitudine\n  - **15**: Speranza\n  - **16**: Orgoglio\n  - **17**: Colpa\n  - **18**: Vergogna\n  - **19**: Solitudine\n  - **20**: Ansia\n  - **21**: Nostalgia\n  - **22**: Imbarazzo\n  - **23**: Frustrazione\n  - **24**: Sollevamento\n  - **25**: Trionfo\n  - **26**: Amore\n  - **27**: Neutrale\n\n- **Dominio**: I commenti provengono da Reddit.\n\n- **Struttura del dataset**:\n  Ogni esempio contiene:\n\n  - **id**: Identificatore dell'esempio.\n  - **text**: Il testo del commento.\n  - **labels**: Una lista di etichette numeriche che rappresentano le emozioni associate al commento.\n\n**Nota bene**\n- **Classi sbilanciate**. ","metadata":{}},{"cell_type":"code","source":"# Ottenimento del dataset\n\ngoe_dataset = load_dataset(\"google-research-datasets/go_emotions\")\n\nprint(goe_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:47:38.078640Z","iopub.execute_input":"2025-01-22T16:47:38.078885Z","iopub.status.idle":"2025-01-22T16:47:39.583349Z","shell.execute_reply.started":"2025-01-22T16:47:38.078863Z","shell.execute_reply":"2025-01-22T16:47:39.582505Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/9.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"757cb4d3195d461991d6c7dcf42c66c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/2.77M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44f532e72f484bf4ae74ff9ac137481d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/350k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"302a534f62034e13873f335ac0237e63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/347k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c47fa3a857545efbba1889a36bf1b98"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/43410 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f41960d5cb58411680f42ea8f8f939f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/5426 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5312ab09dbc6496fb23e6cd6004da5f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/5427 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bdf8e25bd4440bbb70e6febf041a8cf"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'labels', 'id'],\n        num_rows: 43410\n    })\n    validation: Dataset({\n        features: ['text', 'labels', 'id'],\n        num_rows: 5426\n    })\n    test: Dataset({\n        features: ['text', 'labels', 'id'],\n        num_rows: 5427\n    })\n})\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"train_data = goe_dataset[\"train\"]\nval_data = goe_dataset[\"validation\"]\ntest_data = goe_dataset[\"test\"]\n\nprint(\"--- Dimensioni del dataset ---\")\nprint(f\"Train set: {len(train_data)} esempi\")\nprint(f\"Validation set: {len(val_data)} esempi\")\nprint(f\"Test set: {len(test_data)} esempi\")\nprint(f\"Totale: {len(train_data) + len(val_data) + len(test_data)} esempi\\n\")\n\n# Analisi dei tre split del dataset\nanalyze_data(\"Train\", train_data,\"labels\")\nanalyze_data(\"Validation\", val_data, \"labels\")\nanalyze_data(\"Test\", test_data, \"labels\")\nprint('')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:48:47.716699Z","iopub.execute_input":"2025-01-22T16:48:47.717062Z","iopub.status.idle":"2025-01-22T16:48:49.776663Z","shell.execute_reply.started":"2025-01-22T16:48:47.717036Z","shell.execute_reply":"2025-01-22T16:48:49.775452Z"}},"outputs":[{"name":"stdout","text":"--- Dimensioni del dataset ---\nTrain set: 43410 esempi\nValidation set: 5426 esempi\nTest set: 5427 esempi\nTotale: 54263 esempi\n\n--- Analisi Train ---\nNumero di esempi nel Train: 43410\n\nPrime 5 righe:\n                                                text labels       id\n0  My favourite food is anything I didn't have to...   [27]  eebbqej\n1  Now if he does off himself, everyone will thin...   [27]  ed00q6i\n2                     WHY THE FUCK IS BAYLESS ISOING    [2]  eezlygj\n3                        To make her feel threatened   [14]  ed7ypvh\n4                             Dirty Southern Wankers    [3]  ed0bdzj \n\nDati mancanti per colonna:\ntext      0\nlabels    0\nid        0\ndtype: int64 \n\nDistribuzione delle classi:\n           Classe  Conteggio  Percentuale\n0            [27]      12823    29.539277\n1             [0]       2710     6.242801\n2             [4]       1873     4.314674\n3            [15]       1857     4.277816\n4             [1]       1652     3.805575\n..            ...        ...          ...\n706      [11, 13]          1     0.002304\n707    [0, 5, 20]          1     0.002304\n708   [9, 20, 25]          1     0.002304\n709  [13, 17, 21]          1     0.002304\n710   [8, 11, 18]          1     0.002304\n\n[711 rows x 3 columns] \n\n\n--- Analisi Validation ---\nNumero di esempi nel Validation: 5426\n\nPrime 5 righe:\n                                                text   labels       id\n0  Is this in New Orleans?? I really feel like th...     [27]  edgurhb\n1  You know the answer man, you are programmed to...  [4, 27]  ee84bjg\n2               I've never been this sad in my life!     [25]  edcu99z\n3  The economy is heavily controlled and subsidiz...  [4, 27]  edc32e2\n4  He could have easily taken a real camera from ...     [20]  eepig6r \n\nDati mancanti per colonna:\ntext      0\nlabels    0\nid        0\ndtype: int64 \n\nDistribuzione delle classi:\n              Classe  Conteggio  Percentuale\n0               [27]       1592    29.340214\n1                [0]        326     6.008109\n2               [15]        261     4.810173\n3                [4]        258     4.754884\n4               [10]        212     3.907114\n..               ...        ...          ...\n291       [0, 2, 18]          1     0.018430\n292  [4, 17, 22, 23]          1     0.018430\n293          [0, 11]          1     0.018430\n294          [9, 18]          1     0.018430\n295         [10, 25]          1     0.018430\n\n[296 rows x 3 columns] \n\n\n--- Analisi Test ---\nNumero di esempi nel Test: 5427\n\nPrime 5 righe:\n                                                text labels       id\n0  I’m really sorry about your situation :( Altho...   [25]  eecwqtt\n1    It's wonderful because it's awful. At not with.    [0]  ed5f85d\n2  Kings fan here, good luck to you guys! Will be...   [13]  een27c3\n3  I didn't know that, thank you for teaching me ...   [15]  eelgwd1\n4  They got bored from haunting earth for thousan...   [27]  eem5uti \n\nDati mancanti per colonna:\ntext      0\nlabels    0\nid        0\ndtype: int64 \n\nDistribuzione delle classi:\n          Classe  Conteggio  Percentuale\n0           [27]       1606    29.592777\n1            [0]        348     6.412383\n2           [15]        260     4.790861\n3            [4]        236     4.348627\n4           [10]        195     3.593145\n..           ...        ...          ...\n270      [7, 11]          1     0.018426\n271   [3, 6, 27]          1     0.018426\n272  [2, 10, 11]          1     0.018426\n273     [14, 26]          1     0.018426\n274      [1, 24]          1     0.018426\n\n[275 rows x 3 columns] \n\n\n\n","output_type":"stream"}],"execution_count":55},{"cell_type":"markdown","source":"### 8. Fake News\n\nIl dataset **Fake News** è una raccolta di articoli di notizie progettata per addestrare e valutare modelli NLP nel compito di classificazione della veridicità delle notizie.  \nMaggiori informazioni: [Fake News Dataset](https://www.kaggle.com/datasets/unarinemukwevho/fake-news).\n\n\n\n**Caratteristiche del dataset**\n\n- **Task**: Classificazione.  \n  Determinare se una notizia è autentica o falsa.\n\n- **Tipo di task**: **Classificazione binaria**. Ogni notizia appartiene a una delle seguenti categorie: **0** Fake, **1** Real.\n\n- **Dominio**: Le notizie coprono vari argomenti, tra cui politica, società, economia e altri temi rilevanti.\n\n- **Struttura del dataset**:  \n  Ogni esempio contiene:  \n  - **id**: Identificatore univoco dell'articolo.  \n  - **title**: Il titolo della notizia.  \n  - **author**: L'autore della notizia (se disponibile).  \n  - **text**: Il corpo del testo dell'articolo.  \n  - **label**: Etichetta binaria che indica se l'articolo è falso (0) o vero (1).\n\n\n**Nota bene**  \n- Non è fornito un validation set predefinito.  \n- Il test set non ha le labels.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ntrain_file = \"/kaggle/input/fake-news/train.csv\"\ntest_file = \"/kaggle/input/fake-news/test.csv\"\n\ntrain_data = pd.read_csv(train_file, encoding='utf-8')\ntest_data = pd.read_csv(test_file,  encoding='utf-8')\n\nprint(\"--- Dimensioni del dataset ---\")\nprint(f\"Train set: {len(train_data)} esempi\")\nprint(f\"Test set: {len(test_data)} esempi\")\nprint(f\"Totale: {len(train_data) +  + len(test_data)} esempi\\n\")\n\n# Analisi dei tre split del dataset\nanalyze_data(\"Train\", train_data, \"label\")\nprint('')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:48:55.359035Z","iopub.execute_input":"2025-01-22T16:48:55.359446Z","iopub.status.idle":"2025-01-22T16:48:58.637326Z","shell.execute_reply.started":"2025-01-22T16:48:55.359416Z","shell.execute_reply":"2025-01-22T16:48:58.636311Z"}},"outputs":[{"name":"stdout","text":"--- Dimensioni del dataset ---\nTrain set: 20800 esempi\nTest set: 5200 esempi\nTotale: 26000 esempi\n\n--- Analisi Train ---\nNumero di esempi nel Train: 20800\n\nPrime 5 righe:\n   id                                              title              author  \\\n0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n\n                                                text  label  \n0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n1  Ever get the feeling your life circles the rou...      0  \n2  Why the Truth Might Get You Fired October 29, ...      1  \n3  Videos 15 Civilians Killed In Single US Airstr...      1  \n4  Print \\nAn Iranian woman has been sentenced to...      1   \n\nDati mancanti per colonna:\nid           0\ntitle      558\nauthor    1957\ntext        39\nlabel        0\ndtype: int64 \n\nDistribuzione delle classi:\n   Classe  Conteggio  Percentuale\n0       1      10413      50.0625\n1       0      10387      49.9375 \n\n\n\n","output_type":"stream"}],"execution_count":56},{"cell_type":"markdown","source":"## Dataset per la name entity recognition","metadata":{}},{"cell_type":"markdown","source":"### 1. CoNLL-2003\n\nIl dataset **CoNLL-2003** è una raccolta annotata per il task di Named Entity Recognition, progettata per identificare entità nominate all'interno di testi.  \nMaggiori informazioni: [CoNLL-2003 Dataset](https://github.com/asahi417/tner).\n  \n  \n**Caratteristiche del dataset**\n\n- **Task**: Named Entity Recognition.  \n  Assegnare un'etichetta a ciascun token per identificare se fa parte di un'entità nominata e, in caso affermativo, il tipo di entità.\n\n- **Tipo di task**: **Classificazione token-level**. Ogni token del testo è classificato in base alla sua appartenenza a una delle seguenti etichette:\n  - **O**: Non appartenente a un'entità.\n  - **B-ORG**: Inizio di un'entità organizzativa (es. \"Google\").\n  - **I-ORG**: Continuazione di un'entità organizzativa. (es. \"headquarters\")\n  - **B-MISC**: Inizio di un'entità di tipo misto (es. eventi o nazionalità, \"Olympic\").\n  - **I-MISC**: Continuazione di un'entità di tipo misto. (es. \"Games\")\n  - **B-PER**: Inizio di un'entità personale (es. \"Barak\").\n  - **I-PER**: Continuazione di un'entità personale. (es. Obama)\n  - **B-LOC**: Inizio di un'entità geografica o località (es. \"Eiffel\").\n  - **I-LOC**: Continuazione di un'entità geografica. (es. Tower)\n\n- **Dominio**: I testi provengono da articoli di notizie.\n\n- **Struttura del dataset**:  \n  Ogni esempio contiene:\n  - **token**: Parole estratte dal testo.\n  - **label**: L'etichetta associata a ciascun token.\n\n\n**Nota bene**  \n- **Token sbilanciati**.\n- Il dataset segue lo schema **IOB2**, in cui ogni entità inizia con un'etichetta \"B\" e continua con un'etichetta \"I\".","metadata":{}},{"cell_type":"code","source":"# Ottenimento del dataset\n\nconll_dataset = load_dataset(\"tner/conll2003\")\n\nprint(conll_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:48:59.399963Z","iopub.execute_input":"2025-01-22T16:48:59.400324Z","iopub.status.idle":"2025-01-22T16:49:00.755010Z","shell.execute_reply.started":"2025-01-22T16:48:59.400295Z","shell.execute_reply":"2025-01-22T16:49:00.754154Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/2.97k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"805eb681dac44733833a38e42a473d2e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"conll2003.py:   0%|          | 0.00/2.74k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"069627d07f3e4776a8262cf49bfafcd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"conll2003/train/0000.parquet:   0%|          | 0.00/841k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e931fe671d4d418e9c7016009c257262"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"conll2003/validation/0000.parquet:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f42a694a65df4c01a93f1edc1016f357"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"conll2003/test/0000.parquet:   0%|          | 0.00/192k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94d3653b25da48fc8345fff0e07e7e15"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/14041 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d54f45c43ea42998eb71b6d35a52b21"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/3250 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dea0a0a3058d4a10b561d7d9caef68a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/3453 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b30b63f02b354382840ac50753eef4ca"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['tokens', 'tags'],\n        num_rows: 14041\n    })\n    validation: Dataset({\n        features: ['tokens', 'tags'],\n        num_rows: 3250\n    })\n    test: Dataset({\n        features: ['tokens', 'tags'],\n        num_rows: 3453\n    })\n})\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"import pandas as pd\nfrom collections import Counter\n\ndef analyze_data_ner(name, data, target):\n    print(f\"--- Analisi {name} ---\")\n    \n    # Converto i dati in un DataFrame\n    df = pd.DataFrame(data)\n    \n    # Dimensioni\n    print(f\"Numero di esempi nel {name}: {len(df)}\\n\")\n    \n    # Prime righe\n    print(\"Prime 5 righe:\")\n    print(df.head(), \"\\n\")\n    \n    # Dati mancanti\n    print(\"Dati mancanti per colonna:\")\n    print(df.isnull().sum(), \"\\n\")\n    \n    # Distribuzione dei token e dei tag\n    print(\"Distribuzione dei tag:\")\n    all_tags = [tag for tags_list in df[target] for tag in tags_list]\n    tag_counts = Counter(all_tags)\n    total_tags = sum(tag_counts.values())\n    tag_distribution = pd.DataFrame({\n        'Tag': list(tag_counts.keys()),\n        'Conteggio': list(tag_counts.values()),\n        'Percentuale': [count / total_tags * 100 for count in tag_counts.values()]\n    }).sort_values(by='Conteggio', ascending=False)\n    print(tag_distribution, \"\\n\")\n    \n    return df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:49:06.970031Z","iopub.execute_input":"2025-01-22T16:49:06.970388Z","iopub.status.idle":"2025-01-22T16:49:06.976852Z","shell.execute_reply.started":"2025-01-22T16:49:06.970360Z","shell.execute_reply":"2025-01-22T16:49:06.975743Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"train_data = conll_dataset[\"train\"]\nval_data = conll_dataset[\"validation\"]\ntest_data = conll_dataset[\"test\"]\n\nprint(\"--- Dimensioni del dataset ---\")\nprint(f\"Train set: {len(train_data)} esempi\")\nprint(f\"Validation set: {len(val_data)} esempi\")\nprint(f\"Test set: {len(test_data)} esempi\")\nprint(f\"Totale: {len(train_data) + len(val_data) + len(test_data)} esempi\\n\")\n\n# Analisi dei tre split del dataset\nanalyze_data_ner(\"Train\", train_data,\"tags\")\nanalyze_data_ner(\"Validation\", val_data, \"tags\")\nanalyze_data_ner(\"Test\", test_data, \"tags\")\nprint('')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:49:09.036268Z","iopub.execute_input":"2025-01-22T16:49:09.036612Z","iopub.status.idle":"2025-01-22T16:49:10.274629Z","shell.execute_reply.started":"2025-01-22T16:49:09.036584Z","shell.execute_reply":"2025-01-22T16:49:10.273749Z"}},"outputs":[{"name":"stdout","text":"--- Dimensioni del dataset ---\nTrain set: 14041 esempi\nValidation set: 3250 esempi\nTest set: 3453 esempi\nTotale: 20744 esempi\n\n--- Analisi Train ---\nNumero di esempi nel Train: 14041\n\nPrime 5 righe:\n                                              tokens  \\\n0  [EU, rejects, German, call, to, boycott, Briti...   \n1                                 [Peter, Blackburn]   \n2                             [BRUSSELS, 1996-08-22]   \n3  [The, European, Commission, said, on, Thursday...   \n4  [Germany, 's, representative, to, the, Europea...   \n\n                                                tags  \n0                        [1, 0, 2, 0, 0, 0, 2, 0, 0]  \n1                                             [3, 4]  \n2                                             [5, 0]  \n3  [0, 1, 6, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, ...  \n4  [5, 0, 0, 0, 0, 1, 6, 0, 0, 0, 3, 4, 0, 0, 0, ...   \n\nDati mancanti per colonna:\ntokens    0\ntags      0\ndtype: int64 \n\nDistribuzione dei tag:\n   Tag  Conteggio  Percentuale\n1    0     169575    83.280948\n5    5       7140     3.506566\n3    3       6600     3.241364\n0    1       6321     3.104342\n4    4       4528     2.223772\n6    6       3704     1.819093\n2    2       3438     1.688456\n8    8       1157     0.568221\n7    7       1155     0.567239 \n\n--- Analisi Validation ---\nNumero di esempi nel Validation: 3250\n\nPrime 5 righe:\n                                              tokens  \\\n0  [CRICKET, -, LEICESTERSHIRE, TAKE, OVER, AT, T...   \n1                               [LONDON, 1996-08-30]   \n2  [West, Indian, all-rounder, Phil, Simmons, too...   \n3  [Their, stay, on, top, ,, though, ,, may, be, ...   \n4  [After, bowling, Somerset, out, for, 83, on, t...   \n\n                                                tags  \n0                  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]  \n1                                             [5, 0]  \n2  [2, 7, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, ...  \n3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...  \n4  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 5, 8, 0, 1, ...   \n\nDati mancanti per colonna:\ntokens    0\ntags      0\ndtype: int64 \n\nDistribuzione dei tag:\n   Tag  Conteggio  Percentuale\n0    0      42757    83.249611\n5    3       1842     3.586449\n2    5       1837     3.576713\n1    1       1341     2.610981\n6    4       1307     2.544782\n3    2        922     1.795171\n8    6        751     1.462227\n4    7        346     0.673676\n7    8        257     0.500389 \n\n--- Analisi Test ---\nNumero di esempi nel Test: 3453\n\nPrime 5 righe:\n                                              tokens  \\\n0  [SOCCER, -, JAPAN, GET, LUCKY, WIN, ,, CHINA, ...   \n1                                     [Nadim, Ladki]   \n2    [AL-AIN, ,, United, Arab, Emirates, 1996-12-06]   \n3  [Japan, began, the, defence, of, their, Asian,...   \n4  [But, China, saw, their, luck, desert, them, i...   \n\n                                                tags  \n0               [0, 0, 5, 0, 0, 0, 0, 3, 0, 0, 0, 0]  \n1                                             [3, 4]  \n2                                 [5, 0, 5, 8, 8, 0]  \n3  [5, 0, 0, 0, 0, 0, 2, 7, 0, 0, 0, 0, 0, 0, 0, ...  \n4  [0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n\nDati mancanti per colonna:\ntokens    0\ntags      0\ndtype: int64 \n\nDistribuzione dei tag:\n   Tag  Conteggio  Percentuale\n0    0      38315    82.527409\n1    5       1668     3.592737\n7    1       1661     3.577660\n2    3       1617     3.482887\n3    4       1156     2.489930\n8    6        835     1.798522\n5    2        702     1.512051\n4    8        257     0.553557\n6    7        216     0.465247 \n\n\n","output_type":"stream"}],"execution_count":59},{"cell_type":"markdown","source":"### 2. WNUT 2017  \n\nIl dataset **WNUT 2017** è una raccolta annotata per il task di Named Entity Recognition (NER), progettata per identificare entità nominate con un focus su entità rare ed emergenti in testi provenienti da social media.  \nMaggiori informazioni: [WNUT 2017 Dataset](https://huggingface.co/datasets/leondz/wnut_17).  \n  \n  \n**Caratteristiche del dataset**\n\n- **Task**: Named Entity Recognition.  \n  Assegnare un'etichetta a ciascun token per identificare se appartiene a un'entità nominata e, in caso affermativo, il tipo di entità.  \n\n- **Tipo di task**: **Classificazione token-level**. Ogni token è classificato secondo lo schema **IOB2** in una delle seguenti categorie:  \n  - **O**: Non appartenente a un'entità.  \n  - **B-corporation**: Inizio di un'entità aziendale (es. \"Microsoft\").  \n  - **I-corporation**: Continuazione di un'entità aziendale (es. \"Corporation\").  \n  - **B-creative-work**: Inizio di un'entità relativa a opere creative (es. \"The Matrix\").  \n  - **I-creative-work**: Continuazione di un'entità relativa a opere creative.  \n  - **B-group**: Inizio di un'entità riferita a gruppi di persone (es. \"The Beatles\").  \n  - **I-group**: Continuazione di un'entità riferita a gruppi di persone.  \n  - **B-location**: Inizio di un'entità geografica o località (es. \"Paris\").  \n  - **I-location**: Continuazione di un'entità geografica.  \n  - **B-person**: Inizio di un'entità personale (es. \"Elon\").  \n  - **I-person**: Continuazione di un'entità personale (es. \"Musk\").  \n  - **B-product**: Inizio di un'entità riferita a prodotti (es. \"iPhone\").  \n  - **I-product**: Continuazione di un'entità riferita a prodotti.  \n\n- **Dominio**: I testi provengono da piattaforme di social media e contengono frasi brevi e informali.\n\n- **Struttura del dataset**:  \n  Ogni esempio contiene:\n  - **id**: identificativo dell'esempio. \n  - **tokens**: parole dal testo.  \n  - **ner:tags**: etichetta associata a ciascun token*.  \n\n\n**Nota bene**  \n- **Token sbilanciati**.","metadata":{}},{"cell_type":"code","source":"# Ottenimento del dataset\n\nwnut_dataset = load_dataset(\"leondz/wnut_17\")\n\nprint(wnut_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:49:15.860395Z","iopub.execute_input":"2025-01-22T16:49:15.860771Z","iopub.status.idle":"2025-01-22T16:49:25.516488Z","shell.execute_reply.started":"2025-01-22T16:49:15.860733Z","shell.execute_reply":"2025-01-22T16:49:25.515682Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/9.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cce734b0a8174aee9c31217d469c57fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"wnut_17.py:   0%|          | 0.00/7.46k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09d3d8225a804503986ec2e7eab40c80"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository for leondz/wnut_17 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/leondz/wnut_17.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/494k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9394c12eaef40958031cf68accd7678"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/115k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6dadf02db0eb4751a286a973b79eeb37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/192k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1b784aef8964ba19a73cdee305d224a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/3394 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"358fbbb8aefc4b55bd15251b7ca588dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1009 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94ba2f416a264cf797787783c55b2a69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1287 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"357159c85d2a452a852e0d8298eb0218"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'tokens', 'ner_tags'],\n        num_rows: 3394\n    })\n    validation: Dataset({\n        features: ['id', 'tokens', 'ner_tags'],\n        num_rows: 1009\n    })\n    test: Dataset({\n        features: ['id', 'tokens', 'ner_tags'],\n        num_rows: 1287\n    })\n})\n","output_type":"stream"}],"execution_count":60},{"cell_type":"code","source":"train_data = wnut_dataset[\"train\"]\nval_data = wnut_dataset[\"validation\"]\ntest_data = wnut_dataset[\"test\"]\n\nprint(\"--- Dimensioni del dataset ---\")\nprint(f\"Train set: {len(train_data)} esempi\")\nprint(f\"Validation set: {len(val_data)} esempi\")\nprint(f\"Test set: {len(test_data)} esempi\")\nprint(f\"Totale: {len(train_data) + len(val_data) + len(test_data)} esempi\\n\")\n\n# Analisi dei tre split del dataset\nanalyze_data_ner(\"Train\", train_data,\"ner_tags\")\nanalyze_data_ner(\"Validation\", val_data, \"ner_tags\")\nanalyze_data_ner(\"Test\", test_data, \"ner_tags\")\nprint('')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:49:28.096149Z","iopub.execute_input":"2025-01-22T16:49:28.096506Z","iopub.status.idle":"2025-01-22T16:49:28.520557Z","shell.execute_reply.started":"2025-01-22T16:49:28.096475Z","shell.execute_reply":"2025-01-22T16:49:28.519539Z"}},"outputs":[{"name":"stdout","text":"--- Dimensioni del dataset ---\nTrain set: 3394 esempi\nValidation set: 1009 esempi\nTest set: 1287 esempi\nTotale: 5690 esempi\n\n--- Analisi Train ---\nNumero di esempi nel Train: 3394\n\nPrime 5 righe:\n  id                                             tokens  \\\n0  0  [@paulwalk, It, 's, the, view, from, where, I,...   \n1  1  [From, Green, Newsfeed, :, AHFA, extends, dead...   \n2  2  [Pxleyes, Top, 50, Photography, Contest, Pictu...   \n3  3     [today, is, my, last, day, at, the, office, .]   \n4  4  [4Dbling, 's, place, til, monday, ,, party, pa...   \n\n                                            ner_tags  \n0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, ...  \n1      [0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n2               [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n3                        [0, 0, 0, 0, 0, 0, 0, 0, 0]  \n4               [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n\nDati mancanti per colonna:\nid          0\ntokens      0\nner_tags    0\ndtype: int64 \n\nDistribuzione dei tag:\n    Tag  Conteggio  Percentuale\n0     0      59570    94.962538\n5     9        660     1.052128\n1     7        548     0.873585\n8    10        335     0.534035\n3     5        264     0.420851\n2     8        245     0.390563\n4     1        221     0.352304\n9     4        206     0.328392\n12   12        203     0.323609\n11    6        150     0.239120\n7    11        142     0.226367\n6     3        140     0.223179\n10    2         46     0.073330 \n\n--- Analisi Validation ---\nNumero di esempi nel Validation: 1009\n\nPrime 5 righe:\n  id                                             tokens  \\\n0  0  [Stabilized, approach, or, not, ?, That, ´, s,...   \n1  1  [You, should, ', ve, stayed, on, Redondo, Beac...   \n2  2  [All, I, ', ve, been, doing, is, BINGE, watchi...   \n3  3  [wow, emma, and, kaite, is, so, very, cute, an...   \n4  4                               [THIS, IS, SO, GOOD]   \n\n                                            ner_tags  \n0               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n1  [0, 0, 0, 0, 0, 0, 7, 8, 8, 0, 0, 0, 0, 0, 0, ...  \n2            [0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0]  \n3  [0, 9, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n4                                       [0, 0, 0, 0]   \n\nDati mancanti per colonna:\nid          0\ntokens      0\nner_tags    0\ndtype: int64 \n\nDistribuzione dei tag:\n    Tag  Conteggio  Percentuale\n0     0      14483    92.054916\n5     9        470     2.987351\n4     4        133     0.845357\n6    10        117     0.743660\n7    11        114     0.724592\n3     3        105     0.667387\n8    12         94     0.597470\n1     7         74     0.470349\n9     5         39     0.247887\n11    1         34     0.216106\n2     8         33     0.209750\n10    6         25     0.158902\n12    2         12     0.076273 \n\n--- Analisi Test ---\nNumero di esempi nel Test: 1287\n\nPrime 5 righe:\n  id                                             tokens  \\\n0  0  [&, gt, ;, *, The, soldier, was, killed, when,...   \n1  1  [&, gt, ;, *, Police, last, week, evacuated, 8...   \n2  2  [&, gt, ;, *, The, army, on, Thursday, recover...   \n3  3  [&, gt, ;, *, The, four, civilians, killed, in...   \n4  4  [The, bodies, of, the, soldiers, were, recover...   \n\n                                            ner_tags  \n0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 8, 0, 0, ...  \n2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, ...   \n\nDati mancanti per colonna:\nid          0\ntokens      0\nner_tags    0\ndtype: int64 \n\nDistribuzione dei tag:\n    Tag  Conteggio  Percentuale\n0     0      21654    92.562195\n5     9        429     1.833804\n8     4        218     0.931863\n3     5        165     0.705309\n1     7        150     0.641190\n7     3        142     0.606993\n6    10        131     0.559973\n10   11        127     0.542874\n12   12        126     0.538600\n2     8         94     0.401812\n4     6         70     0.299222\n9     1         66     0.282124\n11    2         22     0.094041 \n\n\n","output_type":"stream"}],"execution_count":61},{"cell_type":"markdown","source":"## Dataset per il Question Answering\n\n### 1. BoolQ\n\nIl dataset **BoolQ** è una raccolta di domande basate su contenuti di testo, progettata per valutare i modelli NLP sul task di risposta a domande con risposta booleana (vero o falso).  \nMaggiori informazioni: [BoolQ Dataset](https://huggingface.co/datasets/google/boolq).\n\n**Caratteristiche del dataset**\n\n- **Task**: Question Answering.  \n  Determinare se una domanda posta su un passaggio di testo ha una risposta positiva (vero) o negativa (falso).\n\n- **Tipo di task**: **Classificazione binaria**. Ogni domanda ha una risposta che può essere True o False.\n\n- \n- **Dominio**: Le domande vengono raccolte da query anonime e aggregate nel motore di ricerca Google.\n\n- **Struttura del dataset**:  \n  Ogni esempio contiene:\n  - **passage**: Il passaggio di testo che fornisce il contesto per rispondere alla domanda.\n  - **question**: La domanda a cui rispondere, formulata in relazione al passaggio.\n  - **answer**: La risposta booleana alla domanda, indicata come **True** o **False**.\n\n**Nota bene**  \n- **Classi sbilanciate**.","metadata":{}},{"cell_type":"code","source":"# Ottenimento del dataset\n\nboolq_dataset = load_dataset(\"google/boolq\")\n\nprint(boolq_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:49:33.777217Z","iopub.execute_input":"2025-01-22T16:49:33.777541Z","iopub.status.idle":"2025-01-22T16:49:35.144911Z","shell.execute_reply.started":"2025-01-22T16:49:33.777516Z","shell.execute_reply":"2025-01-22T16:49:35.143992Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/6.57k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cae896f49c7c41a3b7f567b89590ac48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/3.69M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a141cfdc478241e4bd89efa0ad647f36"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/1.26M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f56332a5eb4417c95bc9d9cf2832a02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/9427 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d591ede1df14ba496032c8a596445ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/3270 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fe783392dc54e1eb7834482a21c6c15"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['question', 'answer', 'passage'],\n        num_rows: 9427\n    })\n    validation: Dataset({\n        features: ['question', 'answer', 'passage'],\n        num_rows: 3270\n    })\n})\n","output_type":"stream"}],"execution_count":62},{"cell_type":"code","source":"train_data = boolq_dataset[\"train\"]\nval_data = boolq_dataset[\"validation\"]\n\nprint(\"--- Dimensioni del dataset ---\")\nprint(f\"Train set: {len(train_data)} esempi\")\nprint(f\"Validation set: {len(val_data)} esempi\")\nprint(f\"Totale: {len(train_data) + len(val_data) } esempi\\n\")\n\n# Analisi dei tre split del dataset\nanalyze_data(\"Train\", train_data,\"answer\")\nanalyze_data(\"Validation\", val_data, \"answer\")\nprint('')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:49:37.059712Z","iopub.execute_input":"2025-01-22T16:49:37.060261Z","iopub.status.idle":"2025-01-22T16:49:37.481182Z","shell.execute_reply.started":"2025-01-22T16:49:37.060212Z","shell.execute_reply":"2025-01-22T16:49:37.480041Z"}},"outputs":[{"name":"stdout","text":"--- Dimensioni del dataset ---\nTrain set: 9427 esempi\nValidation set: 3270 esempi\nTotale: 12697 esempi\n\n--- Analisi Train ---\nNumero di esempi nel Train: 9427\n\nPrime 5 righe:\n                                            question  answer  \\\n0    do iran and afghanistan speak the same language    True   \n1  do good samaritan laws protect those who help ...    True   \n2  is windows movie maker part of windows essentials    True   \n3  is confectionary sugar the same as powdered sugar    True   \n4         is elder scrolls online the same as skyrim   False   \n\n                                             passage  \n0  Persian (/ˈpɜːrʒən, -ʃən/), also known by its ...  \n1  Good Samaritan laws offer legal protection to ...  \n2  Windows Movie Maker (formerly known as Windows...  \n3  Powdered sugar, also called confectioners' sug...  \n4  As with other games in The Elder Scrolls serie...   \n\nDati mancanti per colonna:\nquestion    0\nanswer      0\npassage     0\ndtype: int64 \n\nDistribuzione delle classi:\n   Classe  Conteggio  Percentuale\n0    True       5874    62.310385\n1   False       3553    37.689615 \n\n\n--- Analisi Validation ---\nNumero di esempi nel Validation: 3270\n\nPrime 5 righe:\n                                            question  answer  \\\n0   does ethanol take more energy make that produces   False   \n1             is house tax and property tax are same    True   \n2  is pain experienced in a missing body part or ...    True   \n3  is harry potter and the escape from gringotts ...    True   \n4  is there a difference between hydroxyzine hcl ...    True   \n\n                                             passage  \n0  All biomass goes through at least some of thes...  \n1  Property tax or 'house tax' is a local tax on ...  \n2  Phantom pain sensations are described as perce...  \n3  Harry Potter and the Escape from Gringotts is ...  \n4  Hydroxyzine preparations require a doctor's pr...   \n\nDati mancanti per colonna:\nquestion    0\nanswer      0\npassage     0\ndtype: int64 \n\nDistribuzione delle classi:\n   Classe  Conteggio  Percentuale\n0    True       2033    62.171254\n1   False       1237    37.828746 \n\n\n\n","output_type":"stream"}],"execution_count":63},{"cell_type":"markdown","source":"### 7. RACE\n\nIl dataset **RACE** (ReAding Comprehension from Examinations) è una raccolta di domande di comprensione del testo tratte da esami scolastici cinesi, progettata per valutare i modelli NLP sul task di risposta a domande di comprensione del testo.  \nMaggiori informazioni: [RACE Dataset](https://huggingface.co/datasets/ehovy/race).\n\n**Caratteristiche del dataset**\n\n- **Task**: Question Answering / Reading Comprehension.  \n  Determinare la risposta corretta tra un set di opzioni date, in base al passaggio di testo fornito.\n\n- **Tipo di task**: **Classificazione multiclasse**. Ogni domanda ha un set di risposte possibili e il modello deve selezionare quella corretta.\n\n- **Dominio**: Le domande sono tratte esami scolasticii, incentrati su vari argomenti.\n\n- **Struttura del dataset**:  \n  Ogni esempio contiene:\n  - **example_id**: identificatore univoco dell'esempio nel dataset.\n  - **article**: iIl passaggio di testo che fornisce il contesto per rispondere alla domanda.\n  - **question**: la domanda che viene posta in relazione al passaggio di testo.\n  - **answer**: la risposta corretta alla domanda.\n  - **options**: le opzioni di risposta tra cui il modello deve selezionare quella corretta.\n\n**Nota bene**  \n","metadata":{}},{"cell_type":"code","source":"# Ottenimento del dataset\n\nrace_dataset = load_dataset(\"ehovy/race\", 'all')\n\nprint(race_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:49:42.578294Z","iopub.execute_input":"2025-01-22T16:49:42.578610Z","iopub.status.idle":"2025-01-22T16:49:44.611139Z","shell.execute_reply.started":"2025-01-22T16:49:42.578585Z","shell.execute_reply":"2025-01-22T16:49:44.610322Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/11.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"728c102f16cb412e85ff9702b51ee8dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/2.08M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d8b5440e6c345da8e87d608beddd98b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/37.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fe6aa906ac54bd08d27f77606532f78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/2.05M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bd655944fae4a78b1827de508997c36"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/4934 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9de4ebb7d80543f8bf6188da38c5a322"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/87866 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5fb2c6152ca4e9b855ba07f432ae82b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/4887 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"573ca4bf34bf47cca9effeae183f4af4"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    test: Dataset({\n        features: ['example_id', 'article', 'answer', 'question', 'options'],\n        num_rows: 4934\n    })\n    train: Dataset({\n        features: ['example_id', 'article', 'answer', 'question', 'options'],\n        num_rows: 87866\n    })\n    validation: Dataset({\n        features: ['example_id', 'article', 'answer', 'question', 'options'],\n        num_rows: 4887\n    })\n})\n","output_type":"stream"}],"execution_count":64},{"cell_type":"code","source":"train_data = race_dataset[\"train\"]\nval_data = race_dataset[\"validation\"]\ntest_data = race_dataset[\"test\"]\n\nprint(\"--- Dimensioni del dataset ---\")\nprint(f\"Train set: {len(train_data)} esempi\")\nprint(f\"Validation set: {len(val_data)} esempi\")\nprint(f\"Validation set: {len(test_data)} esempi\")\nprint(f\"Totale: {len(train_data) + len(val_data)  + len(test_data) } esempi\\n\")\n\n# Analisi dei tre split del dataset\nanalyze_data(\"Train\", train_data,\"answer\")\nanalyze_data(\"Validation\", val_data, \"answer\")\nanalyze_data(\"Test\", test_data, \"answer\")\nprint('')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T16:49:47.446417Z","iopub.execute_input":"2025-01-22T16:49:47.446770Z","iopub.status.idle":"2025-01-22T16:49:53.108131Z","shell.execute_reply.started":"2025-01-22T16:49:47.446744Z","shell.execute_reply":"2025-01-22T16:49:53.107010Z"}},"outputs":[{"name":"stdout","text":"--- Dimensioni del dataset ---\nTrain set: 87866 esempi\nValidation set: 4887 esempi\nValidation set: 4934 esempi\nTotale: 97687 esempi\n\n--- Analisi Train ---\nNumero di esempi nel Train: 87866\n\nPrime 5 righe:\n      example_id                                            article answer  \\\n0  high19088.txt  Last week I talked with some of my students ab...      C   \n1  high19088.txt  Last week I talked with some of my students ab...      C   \n2  high19088.txt  Last week I talked with some of my students ab...      D   \n3  high19088.txt  Last week I talked with some of my students ab...      B   \n4  high15596.txt  YUZHOU, HENAN -An accident in a central China ...      B   \n\n                                            question  \\\n0  We can know from the passage that the author w...   \n1  Many graduates today turn to cosmetic surgery ...   \n2  According to the passage, the author believes ...   \n3          Which' s the best title for the passage?.   \n4     What could be the best title for this passage?   \n\n                                             options  \n0                 [doctor, model, teacher, reporter]  \n1  [marry a better man/woman, become a model, get...  \n2  [everyone should purchase perfection, whatever...  \n3  [Young Graduates Have Higher Expectations, You...  \n4  [Death Toll Rises in an Accident in China, A C...   \n\nDati mancanti per colonna:\nexample_id    0\narticle       0\nanswer        0\nquestion      0\noptions       0\ndtype: int64 \n\nDistribuzione delle classi:\n  Classe  Conteggio  Percentuale\n0      C      23891    27.190267\n1      B      22726    25.864384\n2      D      22103    25.155350\n3      A      19146    21.789998 \n\n\n--- Analisi Validation ---\nNumero di esempi nel Validation: 4887\n\nPrime 5 righe:\n      example_id                                            article answer  \\\n0   high5060.txt  I am a psychologist. I first met Timothy, a qu...      C   \n1   high5060.txt  I am a psychologist. I first met Timothy, a qu...      A   \n2   high5060.txt  I am a psychologist. I first met Timothy, a qu...      C   \n3  high14410.txt  From self-driving cars to carebots (care+robot...      A   \n4  high14410.txt  From self-driving cars to carebots (care+robot...      B   \n\n                                            question  \\\n0  What did the writer think of Timothy after lea...   \n1  Which of the following statements best describ...   \n2  According to the passage, how long should a th...   \n3                    According to the report,   _  .   \n4  We can infer from the text that in the future ...   \n\n                                             options  \n0  [Timothy was very hardworking., Timothy was be...  \n1  [Children should be allowed enough time to pla...  \n2  [About ten minutes., No more than twenty minut...  \n3  [people won't necessarily lose jobs, big compa...  \n4  [people will face many difficulties, people wi...   \n\nDati mancanti per colonna:\nexample_id    0\narticle       0\nanswer        0\nquestion      0\noptions       0\ndtype: int64 \n\nDistribuzione delle classi:\n  Classe  Conteggio  Percentuale\n0      C       1303    26.662574\n1      B       1291    26.417025\n2      D       1226    25.086965\n3      A       1067    21.833436 \n\n\n--- Analisi Test ---\nNumero di esempi nel Test: 4934\n\nPrime 5 righe:\n      example_id                                            article answer  \\\n0  high19432.txt  The rain had continued for a week and the floo...      C   \n1  high19432.txt  The rain had continued for a week and the floo...      D   \n2  high19432.txt  The rain had continued for a week and the floo...      A   \n3   high6268.txt  There is probably no field of human activity i...      B   \n4   high6268.txt  There is probably no field of human activity i...      B   \n\n                                            question  \\\n0     What did Nancy try to do before she fell over?   \n1  The following are true according to the passag...   \n2  What did the local people do to help those in ...   \n3                   The passage tells us that   _  .   \n4   Traditionally,people usually thought that   _  .   \n\n                                             options  \n0  [Measure the depth of the river, Look for a fa...  \n1  [It took Lizzie and Nancy about 20 minutes to ...  \n2  [They put up shelter for them in a school., Th...  \n3  [our values and lifestyles are in no field of ...  \n4  [men cared very much for clothes, women were c...   \n\nDati mancanti per colonna:\nexample_id    0\narticle       0\nanswer        0\nquestion      0\noptions       0\ndtype: int64 \n\nDistribuzione delle classi:\n  Classe  Conteggio  Percentuale\n0      C       1324    26.834212\n1      B       1323    26.813944\n2      D       1224    24.807458\n3      A       1063    21.544386 \n\n\n\n","output_type":"stream"}],"execution_count":65},{"cell_type":"markdown","source":"## Altri dataset \n\n### Classificazione multilabel\n\n- **Reuters-21578**: 21.578 articoli di notizie pubblicati da Reuters nel 1987 ed etichettati con 135 categorie tematiche, tra cui economia, sport, politica e tecnologia.\n- **RCV1** : 800.000 articoli di notizie in inglese pubblicati da Reuters tra il 1996 e il 1997 ed etichettati con 103 categorie suddivise in gerarchie tematiche come economia, scienza, sport e tecnologia.\n- **Emotion**: Frasi o brevi testi etichettati con emozioni multiple. Utilizzato per analisi emotive su contenuti testuali.\nEtichette: Emozioni come gioia, tristezza, paura, rabbia, disgusto, sorpresa e confusione.\n- **RCV1 (Reuters Corpus Volume 1)**\nContenuto: Corpus di oltre 800.000 articoli di notizie in inglese pubblicati da Reuters tra il 1996 e il 1997.\nEtichette: 103 categorie suddivise in gerarchie tematiche come economia, scienza, sport e tecnologia.\n- **Emotion Dataset**\nContenuto: Frasi o brevi testi etichettati con emozioni multiple. Utilizzato per analisi emotive su contenuti testuali.\nEtichette: Emozioni come gioia, tristezza, paura, rabbia, disgusto, sorpresa e confusione.\n- **Altri**: disponibili nelle librerie Mulan o scikit-multilearn\n","metadata":{}},{"cell_type":"markdown","source":"\n| Nome del dataset | Descrizione | Features e Label | Task | Tipo di task| Note |\n| ---------------- | ----------- | ---------------- | ---- | ----------- | ---- |\n| **Amazon Product Reviews**  | Recensioni di prodotti Amazon con punteggi da 1 a 5. | `text`: contenuto della recensione<br> `rating`: valutazione del prodotto da 1 a 5  | Sentiment Analysis | Classificazione multiclasse |  Specie di rating|\n| **SST-2**            | Dataset di recensioni cinematografiche annotate con sentiment positivo o negativo. | `sentence`: recensione<br> `label`: sentimento binario| Sentiment Analysis | Classificazione binaria |  |\n| **SemEval 2017**  | Dataset per sentiment analysis su tweet  | `text`: contenuto del tweet<br>`sentiment`: positivo, negativo, neutro | Sentiment Analysis | Classificazione multiclasse | Testi brevi (Tweet) |\n| **Sentiment140** | Dataset di tweet con sentiment |  `text`: contenuto del tweet<br>`sentiment`: positivo o negativo | Sentiment Analysis | Classificazione binaria | Testi brevi |\n| **SMS Spam Collection** | Messaggi SMS etichettati come spam o legittimi (ham).   | `message`: contenuto del messaggio SMS<br>`label`: spam o ham | Spam detection   | Classificazione binaria    |    |\n| **Fake News** | Articoli di notizie etichettati come reali o falsi.   | `title`: titolo dell'articolo, `text`: contenuto dell'articolo<br>`label`: vero o falso | Fake news detection   | Classificazione binaria  |    |\n| **AG News** | Articoli di notizie classificati in quattro categorie tematiche. | `text`: contenuto dell'articolo<br>`label`: categoria della notizia. | Classificazione  | Classificazione multiclasse | Notizie |\n| **DBpedia 14**| Documenti Wikipedia classificati in 14 categorie.   |  `title`: titolo del documento, `content`: contenuto del documento<br>`label`: categoria del documento | Classificazione    | Classificazione multiclasse | Testi ontologici |\n| **Yahoo Answers Topics** | Domande e risposte di Yahoo Answers, classificate in 10 categorie.| `question_title`: titolo della domanda, `question_content`: testo della domanda, `best_answer`: risposta migliore selezionata<br> `topic`: categoria della domanda | Classificazione | Classificazione multiclasse | Domande |\n| **Emotion Dataset**  | Tweet classificati in base a sei emozioni.   | `text`: contenuto del tweet<br>`label`:emozione associata | Emotion Analysis  | Classificazione multiclasse | Testi brevi (Tweet) |\n| **Toxic Comment Classification** | Commenti tossici da Wikipedia, classificati in più categorie di tossicità. | `comment_text`: contenuto del commento<br>  `toxic`, `severe_toxic`, `obscene`, `threat`, `insult`, `identity_hate`: etichette binarie per ogni tipo di tossicità. | Classificazione   | Classificazione multilabel | Multilabel |\n| **GoEmotions**  | Commenti Reddit classificati in 27 emozioni.                           |`text`: contenuto del commento<br>`labels`: una o più emozioni associate al commento     | Emotion Analysis   | Classificazione multilabel | Multilabel  |\n| **MNLI**             | Dataset per inferenza logica tra coppie di frasi (premessa e ipotesi). | `premise`: premessa<br>`hypothesis`: ipotesi<br>`label`: relazione logica (0 = Entailment, 1 = Neutral, 2 = Contradiction) | Inferenza logica  | Classificazione multi-classe |    |\n| **QNLI**             | Dataset per valutare se una frase contestuale risponde a una domanda specifica. | `question`: domanda<br>`sentence`: frase contestuale<br>`label`: risposta binaria (1 = sì, 0 = no) | Inferenza logica | Classificazione binaria | Domande |\n| **RTE**              | Dataset per valutare se una premessa implica logicamente un'ipotesi.  | `sentence1`: premessa<br>`sentence2`: ipotesi<br>- `label`: implicazione logica (1 = sì, 0 = no)| Inferenza logica | Classificazione binaria |  |\n| **WNLI**             | Dataset per risolvere ambiguità pronominali basate sul contesto. | `sentence1`: frase originale<br>`sentence2`: frase ipotesi<br>`label`: implicazione logica (1 = sì, 0 = no) | Risoluzione di ambiguità pronominali   | Classificazione binaria | Pronomi |\n| **MRPC**            | Dataset per valutare la capacità di identificare parafrasi tra coppie di frasi.| `sentence1`: prima frase<br>`sentence2`: seconda frase<br>`label`: parafrasi o non parafrasi | Identificazione Parafrasi | Classificazione binaria |   |\n| **QQP**              | Dataset per identificare se due domande hanno lo stesso significato |`question1`: prima domanda<br>`question2`: seconda domanda<br>`label`: duplicate o non duplicate | Identificazione Parafrasi  | Classificazione binaria | Domande  |\n| **STS-B**            | Dataset per valutare il grado di similarità semantica tra due frasi.  | `sentence1`: prima frase<br>`sentence2`: seconda frase<br>`label`: punteggio di similarità (0-5)| Similarità Semantica | Regressione | Speciie di rating |\n| **CoLA**             | Dataset per valutare l'accettabilità linguistica di frasi in inglese. |`sentence`: frase in inglese<br>`label`: etichetta binaria | Accettabilità linguistica | Classificazione binaria |   |\n| **CoNLL-2003**  | Frasi annotate con 8 label per Named Entity Recognition. | `token`: parole della frase<br> `label`: entità associata al token  | Named Entity Recognition     | Classificazione token-level | Testi medi  |\n| **WNUT 2017**  | Annotazioni per Named Entity Recognition su testi di social media.   | `tokens`: sequenza di parole della frase<br>`ner_tags`: entità associate ai token  | Named Entity Recognition  | Classificazione token-level | Testi brevi e informali |\n| **BoolQ**  | Domande con risposte booleane basate su passaggi di testo.  | `passage`: testo di riferimento, `question`: domanda<br> `answer`: vero o falso  | Question Answering           | Classificazione binaria   |   |\n| **RACE**  | Domande di comprensione del testo tratte da esami scolastici.  | `article`:  testo dell'articolo, `question`: domanda, `options`: possibili risposte<br> `answer`: risposta corretta | Reading Comprehension | Classificazione multiclasse | |","metadata":{}},{"cell_type":"markdown","source":"Collezione di dataset e task","metadata":{}},{"cell_type":"markdown","source":"\n| Nome del dataset | Descrizione | Features e Label | Task | Tipo di task| Note |\n| ---------------- | ----------- | ---------------- | ---- | ----------- | ---- |\n| **Amazon Product Reviews**  | Recensioni di prodotti Amazon con punteggi da 1 a 5. | `text`: contenuto della recensione<br> `rating`: valutazione del prodotto da 1 a 5  | Sentiment Analysis | Classificazione multiclasse |  Specie di rating|\n| **SST-2**            | Dataset di recensioni cinematografiche annotate con sentiment positivo o negativo. | `sentence`: recensione<br> `label`: sentimento binario| Sentiment Analysis | Classificazione binaria |  |\n| **Sentiment140** | Dataset di tweet con sentiment |  `text`: contenuto del tweet<br>`sentiment`: positivo o negativo | Sentiment Analysis | Classificazione binaria | Testi brevi (Tweet) |\n| **AG News** | Articoli di notizie classificati in quattro categorie tematiche. | `text`: contenuto dell'articolo<br>`label`: categoria della notizia. | Classificazione  | Classificazione multiclasse | Notizie |\n| **Yahoo Answers Topics** | Domande e risposte di Yahoo Answers, classificate in 10 categorie.| `question_title`: titolo della domanda, `question_content`: testo della domanda, `best_answer`: risposta migliore selezionata<br> `topic`: categoria della domanda | Classificazione | Classificazione multiclasse | Domande |\n| **Emotion Dataset**  | Tweet classificati in base a sei emozioni.   | `text`: contenuto del tweet<br>`label`:emozione associata | Emotion Analysis  | Classificazione multiclasse | Testi brevi (Tweet) |\n| **Toxic Comment Classification** | Commenti tossici da Wikipedia, classificati in più categorie di tossicità. | `comment_text`: contenuto del commento<br>  `toxic`, `severe_toxic`, `obscene`, `threat`, `insult`, `identity_hate`: etichette binarie per ogni tipo di tossicità. | Classificazione   | Classificazione multilabel | Multilabel |\n| **MNLI**             | Dataset per inferenza logica tra coppie di frasi (premessa e ipotesi). | `premise`: premessa<br>`hypothesis`: ipotesi<br>`label`: relazione logica (0 = Entailment, 1 = Neutral, 2 = Contradiction) | Inferenza logica  | Classificazione multi-classe |    |\n| **QNLI**             | Dataset per valutare se una frase contestuale risponde a una domanda specifica. | `question`: domanda<br>`sentence`: frase contestuale<br>`label`: risposta binaria (1 = sì, 0 = no) | Inferenza logica | Classificazione binaria | Domande |\n| **WNLI**             | Dataset per risolvere ambiguità pronominali basate sul contesto. | `sentence1`: frase originale<br>`sentence2`: frase ipotesi<br>`label`: implicazione logica (1 = sì, 0 = no) | Risoluzione di ambiguità pronominali   | Classificazione binaria | Pronomi |\n| **MRPC**            | Dataset per valutare la capacità di identificare parafrasi tra coppie di frasi.| `sentence1`: prima frase<br>`sentence2`: seconda frase<br>`label`: parafrasi o non parafrasi | Identificazione Parafrasi | Classificazione binaria |   |\n| **QQP**              | Dataset per identificare se due domande hanno lo stesso significato |`question1`: prima domanda<br>`question2`: seconda domanda<br>`label`: duplicate o non duplicate | Identificazione Parafrasi  | Classificazione binaria | Domande  |\n| **STS-B**            | Dataset per valutare il grado di similarità semantica tra due frasi.  | `sentence1`: prima frase<br>`sentence2`: seconda frase<br>`label`: punteggio di similarità (0-5)| Similarità Semantica | Regressione | Speciie di rating |\n| **CoLA**             | Dataset per valutare l'accettabilità linguistica di frasi in inglese. |`sentence`: frase in inglese<br>`label`: etichetta binaria | Accettabilità linguistica | Classificazione binaria |   |\n| **CoNLL-2003**  | Frasi annotate con 8 label per Named Entity Recognition. | `token`: parole della frase<br> `label`: entità associata al token  | Named Entity Recognition     | Classificazione token-level | Testi medi  |\n| **WNUT 2017**  | Annotazioni per Named Entity Recognition su testi di social media.   | `tokens`: sequenza di parole della frase<br>`ner_tags`: entità associate ai token  | Named Entity Recognition  | Classificazione token-level | Testi brevi e informali |\n| **BoolQ**  | Domande con risposte booleane basate su passaggi di testo.  | `passage`: testo di riferimento, `question`: domanda<br> `answer`: vero o falso  | Question Answering           | Classificazione binaria   |   |\n| **RACE**  | Domande di comprensione del testo tratte da esami scolastici.  | `article`:  testo dell'articolo, `question`: domanda, `options`: possibili risposte<br> `answer`: risposta corretta | Reading Comprehension | Classificazione multiclasse | |","metadata":{}}]}