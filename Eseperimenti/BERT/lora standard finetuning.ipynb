{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# Fine-Tuning standard con LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configurazioni generali"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T08:24:16.998582Z",
     "iopub.status.busy": "2025-02-16T08:24:16.998293Z",
     "iopub.status.idle": "2025-02-16T08:24:17.003779Z",
     "shell.execute_reply": "2025-02-16T08:24:17.002668Z",
     "shell.execute_reply.started": "2025-02-16T08:24:16.998561Z"
    }
   },
   "source": [
    "Installazione delle librerie necessarie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importo i moduli necessari."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 09:25:32.761608: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-26 09:25:32.775393: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742981132.793028  349448 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742981132.798623  349448 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1742981132.811637  349448 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742981132.811650  349448 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742981132.811652  349448 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742981132.811653  349448 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-26 09:25:32.816560: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from transformers import BertTokenizer\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import BertForSequenceClassification, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impostazione del seme casuale per la riproducibilità."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 42\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "torch.manual_seed(seed_value)\n",
    "\n",
    "# Imposto il seme casuale anche per i calcoli CUDA\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)  \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T14:40:13.528575Z",
     "iopub.status.busy": "2025-03-13T14:40:13.528260Z",
     "iopub.status.idle": "2025-03-13T14:41:26.429773Z",
     "shell.execute_reply": "2025-03-13T14:41:26.429098Z",
     "shell.execute_reply.started": "2025-03-13T14:40:13.528544Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f20e795256404bb78c2295c65a76db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/6.84k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc914d394fc41b6aead578b3841e23b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentiment140.py:   0%|          | 0.00/4.03k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9da571f6915a4a5f983c9dd5fef6647b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/81.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fdf47eac62648ec92dcb4316b3ddc31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1600000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c029b52541c41c2943a5e34bc02b010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/498 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'date', 'user', 'sentiment', 'query'],\n",
      "        num_rows: 1600000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'date', 'user', 'sentiment', 'query'],\n",
      "        num_rows: 498\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Ottenimento del dataset\n",
    "sent140_dataset = load_dataset(\"stanfordnlp/sentiment140\",trust_remote_code=True)\n",
    "print(sent140_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T14:41:26.430804Z",
     "iopub.status.busy": "2025-03-13T14:41:26.430503Z",
     "iopub.status.idle": "2025-03-13T14:41:55.400769Z",
     "shell.execute_reply": "2025-03-13T14:41:55.400071Z",
     "shell.execute_reply.started": "2025-03-13T14:41:26.430771Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensioni dei set:\n",
      "Train: 20000\n",
      "Validation: 1000\n",
      "Test: 1024\n",
      "\n",
      "Distribuzione delle etichette:\n",
      "Train: Counter({0: 10000, 1: 10000})\n",
      "Validation: Counter({1: 500, 0: 500})\n",
      "Test: Counter({1: 512, 0: 512})\n"
     ]
    }
   ],
   "source": [
    "# Divido i dati in training, validation e test set\n",
    "sent140_data = sent140_dataset[\"train\"].shuffle(seed=42)\n",
    "\n",
    "sent140_temp_sentences, sent140_test_sentences, sent140_temp_labels, sent140_test_labels = train_test_split(\n",
    "                                                sent140_data['text'], \n",
    "                                                sent140_data['sentiment'], \n",
    "                                                test_size=1024, \n",
    "                                                random_state=42,\n",
    "                                                stratify=sent140_data['sentiment'])\n",
    "\n",
    "sent140_train_sentences, sent140_val_sentences, sent140_train_labels, sent140_val_labels = train_test_split(\n",
    "                                                sent140_temp_sentences, \n",
    "                                                sent140_temp_labels, \n",
    "                                                train_size=20000,\n",
    "                                                test_size=1000,\n",
    "                                                random_state=42,\n",
    "                                                stratify=sent140_temp_labels)\n",
    "\n",
    "# Trasformazione delle etichette 0 -> 0 e 4->1\n",
    "sent140_train_labels = [1 if label == 4 else 0 for label in sent140_train_labels]\n",
    "sent140_val_labels = [1 if label == 4 else 0 for label in sent140_val_labels]\n",
    "sent140_test_labels = [1 if label == 4 else 0 for label in sent140_test_labels]\n",
    "\n",
    "\n",
    "print(\"Dimensioni dei set:\")\n",
    "print(f\"Train: {len(sent140_train_sentences)}\")\n",
    "print(f\"Validation: {len(sent140_val_sentences)}\")\n",
    "print(f\"Test: {len(sent140_test_sentences)}\")\n",
    "\n",
    "# Verifica distribuzione delle etichette\n",
    "print(\"\\nDistribuzione delle etichette:\")\n",
    "print(f\"Train: {Counter(sent140_train_labels)}\")\n",
    "print(f\"Validation: {Counter(sent140_val_labels)}\")\n",
    "print(f\"Test: {Counter(sent140_test_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationDataset(Dataset):\n",
    "\n",
    "    def __init__(self, sentences, labels, tokenizer, max_len):\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        sentence = self.sentences[index]\n",
    "        label = self.labels[index]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            sentence,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True,\n",
    "            padding=\"max_length\",\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt')\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'token_type_ids': encoding[\"token_type_ids\"].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 128\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Inizializzo il Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Ottiengo i dataset\n",
    "sent140_training_data = ClassificationDataset(\n",
    "                           sentences = sent140_train_sentences,\n",
    "                           labels = sent140_train_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)\n",
    "\n",
    "sent140_validation_data = ClassificationDataset(\n",
    "                           sentences = sent140_val_sentences,\n",
    "                           labels = sent140_val_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)\n",
    "\n",
    "sent140_test_data = ClassificationDataset(\n",
    "                           sentences = sent140_test_sentences,\n",
    "                           labels = sent140_test_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch.nn as nn\n",
    "from codecarbon import EmissionsTracker\n",
    "\n",
    "\n",
    "# Funzione di training e valutazione\n",
    "def train_and_evaluate_model(model, dataset, train_loader, val_loader, optimizer, scheduler, device, epochs=10, patience=3):\n",
    "\n",
    "    os.makedirs(\"carbon_emissions\", exist_ok=True)\n",
    "    tracker = EmissionsTracker(output_dir=\"carbon_emissions\", output_file=\"emissions.csv\")  \n",
    "    tracker.start()  \n",
    "\n",
    "    history = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "    best_accuracy = 0\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0  \n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "        # Training\n",
    "        train_loss, train_acc = train_model(model, train_loader, optimizer, scheduler, device)\n",
    "        \n",
    "        # Valutazione\n",
    "        val_loss, val_acc, val_f1 = eval_model(model, val_loader, device)\n",
    "        \n",
    "        # Salvataggio del modello migliore\n",
    "        if val_acc > best_accuracy:\n",
    "            torch.save(model.state_dict(),  f\"{dataset}_best_model_state.bin\")\n",
    "            best_accuracy = val_acc\n",
    "\n",
    "        # Salvataggio delle metriche\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            patience_counter = 0 \n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"La loss sul validation set non è migliorata per {patience_counter} epoche.\")\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping attivato dopo {patience_counter} epoche senza miglioramenti\")\n",
    "            break\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_training_time = end_time - start_time\n",
    "\n",
    "    emissions = tracker.stop()\n",
    "    print(f\"\\nEmissioni CO₂ totali: {emissions:.4f} kg\")  \n",
    "\n",
    "    return history, total_training_time, emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione di training\n",
    "def train_model(model, data_loader, optimizer, scheduler, device):\n",
    "\n",
    "    model = model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    loop = tqdm(data_loader, desc=f\"Training  \", leave=True)\n",
    "\n",
    "    for batch in loop:\n",
    "\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # --- Forward pass ---\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            labels=labels \n",
    "        )\n",
    "\n",
    "        loss = outputs.loss  \n",
    "        logits = outputs.logits  \n",
    "\n",
    "        # --- Backward pass ---\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        preds = torch.argmax(logits, dim=1)  # Predizioni multiclasse\n",
    "\n",
    "        all_preds.extend(preds.detach().cpu().numpy())\n",
    "        all_labels.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "        loop.set_postfix(loss=total_loss / (loop.n + 1), accuracy=accuracy_score(all_labels, all_preds))\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione di valutazione\n",
    "def eval_model(model, data_loader, device):\n",
    "\n",
    "    model = model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        loop = tqdm(data_loader, desc=f\"Evaluating\", leave=True)\n",
    "        for batch in loop:\n",
    "            \n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            token_type_ids = batch[\"token_type_ids\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids,\n",
    "                labels=labels\n",
    "            )\n",
    "\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.detach().cpu().numpy())\n",
    "            all_labels.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "            loop.set_postfix(loss=total_loss / (loop.n + 1), accuracy=accuracy_score(all_labels, all_preds))\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "    \n",
    "    return avg_loss, accuracy, f1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Pretrained model\n",
    "lora_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "\n",
    "# LoRA config\n",
    "lora_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=128,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"query\", \"key\", \"value\"],  \n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "lora_model = get_peft_model(lora_model, lora_config)\n",
    "lora_model.print_trainable_parameters()\n",
    "lora_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in lora_model.named_parameters():\n",
    "    if \"classifier\" in name:\n",
    "        param.requires_grad = True\n",
    "\n",
    "for name, param in lora_model.named_parameters():\n",
    "    if \"classifier\" in name:\n",
    "        print(f\"{name}: requires_grad = {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametri principali\n",
    "learning_rate = 5e-4\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Creo i DataLoader\n",
    "sent140_train_loader = DataLoader(sent140_training_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "sent140_val_loader = DataLoader(sent140_validation_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "sent140_test_loader = DataLoader(sent140_test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "total_steps = len(sent140_train_loader) * EPOCHS\n",
    "\n",
    "# Ottimizzatore\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, lora_model.parameters()), lr = learning_rate)\n",
    "\n",
    "\n",
    "# Scheduler\n",
    "scheduler = transformers.get_cosine_schedule_with_warmup(optimizer = optimizer,\n",
    "                                                       num_warmup_steps = 0,\n",
    "                                                       num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history, total_time, emissions = train_and_evaluate_model(\n",
    "    lora_model,\"sent140\", sent140_train_loader, sent140_val_loader, optimizer, scheduler, device, epochs=EPOCHS\n",
    ") \n",
    "print(f\"\\nBERT with LoRA Training Time: {total_time:.2f} seconds, {total_time/60:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model.load_state_dict(torch.load(\"sent140_best_model_state.bin\"))\n",
    "    \n",
    "test_loss, test_acc, test_f1 = eval_model(lora_model, sent140_test_loader, device)\n",
    "print(f\"LoRA Fine-Tuning - Test loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}, F1 score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance = []\n",
    "\n",
    "# Funzione per memorizzare le performance sul task appena addestrato\n",
    "def add_task_results(task_name, training_time, emissions, test_loss, test_acc, test_f1):\n",
    "    model_performance.append({\n",
    "        \"Task\": task_name,\n",
    "        \"Training Time\": training_time,\n",
    "        \"CO2 Emissions\": emissions,\n",
    "        \"Test Loss\": test_loss,\n",
    "        \"Accuracy\": test_acc,\n",
    "        \"F1 Score\": test_f1,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memorizzazione dei risultati su Sentiment140\n",
    "add_task_results(\n",
    "    task_name=\"sentiment140\", \n",
    "    training_time=total_time,\n",
    "    emissions=emissions,\n",
    "    test_loss=test_loss,\n",
    "    test_acc=test_acc,\n",
    "    test_f1=test_f1,\n",
    ")\n",
    "\n",
    "performance = pd.DataFrame(model_performance)\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB Rewiews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T17:08:19.354532Z",
     "iopub.status.busy": "2025-03-13T17:08:19.353919Z",
     "iopub.status.idle": "2025-03-13T17:08:23.335338Z",
     "shell.execute_reply": "2025-03-13T17:08:23.334648Z",
     "shell.execute_reply.started": "2025-03-13T17:08:19.354505Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c64e3ba8d04b414db6c66764e8d7348a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/7.81k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8adbdb65ec314b3e9a7ee17c5876ace7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe615c040bd243f08dccd6eb112f7d9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "242e8538386d47c3b0de3149d3b8c05a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unsupervised-00000-of-00001.parquet:   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be48224dc254618a9b1016c12a6d907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7997c15a7724907bcc2592e50705b20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bceb6dbc75734d57b9f1283592d07efc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "    unsupervised: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Ottenimento del dataset\n",
    "imdb_dataset = load_dataset(\"stanfordnlp/imdb\")\n",
    "print(imdb_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T17:08:23.336608Z",
     "iopub.status.busy": "2025-03-13T17:08:23.336333Z",
     "iopub.status.idle": "2025-03-13T17:08:26.154090Z",
     "shell.execute_reply": "2025-03-13T17:08:26.153164Z",
     "shell.execute_reply.started": "2025-03-13T17:08:23.336586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensioni dei set:\n",
      "Train: 40000\n",
      "Validation: 5000\n",
      "Test: 5000\n",
      "\n",
      "Distribuzione delle etichette:\n",
      "Train: Counter({0: 20000, 1: 20000})\n",
      "Validation: Counter({0: 2500, 1: 2500})\n",
      "Test: Counter({1: 2500, 0: 2500})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "imdb_train_data = pd.DataFrame(imdb_dataset[\"train\"])\n",
    "imdb_test_data = pd.DataFrame(imdb_dataset[\"test\"])\n",
    "\n",
    "imdb_data = Dataset.from_pandas(pd.concat([imdb_train_data, imdb_test_data], ignore_index=True))\n",
    "imdb_data = imdb_data.shuffle(seed=42)\n",
    "\n",
    "imdb_temp_sentences, imdb_test_sentences, imdb_temp_labels, imdb_test_labels = train_test_split(\n",
    "                                                imdb_data['text'],\n",
    "                                                imdb_data['label'], \n",
    "                                                test_size=0.1, \n",
    "                                                random_state=42,\n",
    "                                                stratify=imdb_data['label'])\n",
    "\n",
    "imdb_train_sentences, imdb_val_sentences, imdb_train_labels, imdb_val_labels = train_test_split(\n",
    "                                                imdb_temp_sentences,\n",
    "                                                imdb_temp_labels,\n",
    "                                                test_size=0.1111,\n",
    "                                                random_state=42,\n",
    "                                                stratify=imdb_temp_labels)\n",
    "\n",
    "print(\"Dimensioni dei set:\")\n",
    "print(f\"Train: {len(imdb_train_sentences)}\")\n",
    "print(f\"Validation: {len(imdb_val_sentences)}\")\n",
    "print(f\"Test: {len(imdb_test_sentences)}\")\n",
    "\n",
    "# Verifica distribuzione delle etichette\n",
    "print(\"\\nDistribuzione delle etichette:\")\n",
    "print(f\"Train: {Counter(imdb_train_labels)}\")\n",
    "print(f\"Validation: {Counter(imdb_val_labels)}\")\n",
    "print(f\"Test: {Counter(imdb_test_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 128\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Inizializzo il Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Ottiengo i dataset\n",
    "imdb_training_data = ClassificationDataset(sentences = imdb_train_sentences,\n",
    "                           labels = imdb_train_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)\n",
    "\n",
    "imdb_validation_data = ClassificationDataset(sentences = imdb_val_sentences,\n",
    "                           labels = imdb_val_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)\n",
    "\n",
    "imdb_test_data = ClassificationDataset(sentences = imdb_test_sentences,\n",
    "                           labels = imdb_test_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Pretrained model\n",
    "lora_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "\n",
    "# LoRA config\n",
    "lora_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=128,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"query\", \"key\", \"value\"],  \n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "lora_model = get_peft_model(lora_model, lora_config)\n",
    "lora_model.print_trainable_parameters()\n",
    "lora_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in lora_model.named_parameters():\n",
    "    if \"classifier\" in name:\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametri principali\n",
    "learning_rate = 5e-4\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Creo i DataLoader\n",
    "imdb_train_loader = DataLoader(imdb_training_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "imdb_val_loader = DataLoader(imdb_validation_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "imdb_test_loader = DataLoader(imdb_test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "total_steps = len(imdb_train_loader) * EPOCHS\n",
    "\n",
    "# Ottimizzatore\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, lora_model.parameters()), lr = learning_rate)\n",
    "\n",
    "\n",
    "# Scheduler\n",
    "scheduler = transformers.get_cosine_schedule_with_warmup(optimizer = optimizer,\n",
    "                                                       num_warmup_steps = 0,\n",
    "                                                       num_training_steps = total_steps) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history, total_time, emissions = train_and_evaluate_model(\n",
    "    lora_model,\"imdb\", imdb_train_loader, imdb_val_loader, optimizer, scheduler, device, epochs=EPOCHS\n",
    ") \n",
    "print(f\"\\nBERT with LoRA Training Time: {total_time:.2f} seconds, {total_time/60:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model.load_state_dict(torch.load(\"imdb_best_model_state.bin\"))\n",
    "test_loss, test_acc, test_f1 = eval_model(lora_model, imdb_test_loader, device)\n",
    "print(f\"LoRA Fine-Tuning - Test loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}, F1 score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_task_results(\n",
    "    task_name=\"imdb\", \n",
    "    training_time=total_time,\n",
    "    emissions=emissions,\n",
    "    test_loss=test_loss,\n",
    "    test_acc=test_acc,\n",
    "    test_f1=test_f1,\n",
    ")\n",
    "\n",
    "performance = pd.DataFrame(model_performance)\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20 News Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T15:24:44.832174Z",
     "iopub.status.busy": "2025-03-12T15:24:44.831851Z",
     "iopub.status.idle": "2025-03-12T15:24:46.579559Z",
     "shell.execute_reply": "2025-03-12T15:24:46.578547Z",
     "shell.execute_reply.started": "2025-03-12T15:24:44.832141Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5348256cf284baca8759757a90114a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/734 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ac6d54e5d94a7da644c29f1f16e10f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train.jsonl:   0%|          | 0.00/14.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d088506503e4c3f9b70860fbe62e935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test.jsonl:   0%|          | 0.00/8.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd42468edd14d9eba70b7cbf4cceb48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/11314 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "027fe9fedb794e25b5e08ca27e36a769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/7532 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label', 'label_text'],\n",
      "        num_rows: 11314\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label', 'label_text'],\n",
      "        num_rows: 7532\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Ottenimento del dataset\n",
    "news_dataset = load_dataset(\"SetFit/20_newsgroups\")\n",
    "print(news_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T15:24:46.581200Z",
     "iopub.status.busy": "2025-03-12T15:24:46.580831Z",
     "iopub.status.idle": "2025-03-12T15:24:47.829140Z",
     "shell.execute_reply": "2025-03-12T15:24:47.828070Z",
     "shell.execute_reply.started": "2025-03-12T15:24:46.581163Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensioni dei set:\n",
      "Train: 15076\n",
      "Validation: 1885\n",
      "Test: 1885\n",
      "\n",
      "Distribuzione delle etichette:\n",
      "Train: Counter({10: 799, 15: 797, 8: 796, 9: 795, 11: 793, 13: 792, 7: 792, 5: 790, 14: 789, 12: 788, 2: 788, 3: 786, 6: 780, 1: 779, 4: 771, 17: 752, 16: 728, 0: 639, 18: 620, 19: 502})\n",
      "Validation: Counter({10: 100, 8: 100, 9: 100, 15: 100, 14: 99, 13: 99, 7: 99, 11: 99, 5: 99, 3: 98, 12: 98, 2: 98, 6: 97, 1: 97, 4: 96, 17: 94, 16: 91, 0: 80, 18: 78, 19: 63})\n",
      "Test: Counter({8: 100, 10: 100, 15: 100, 11: 99, 9: 99, 7: 99, 13: 99, 14: 99, 5: 99, 2: 99, 6: 98, 3: 98, 12: 98, 1: 97, 4: 96, 17: 94, 16: 91, 0: 80, 18: 77, 19: 63})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "news_train_data = pd.DataFrame(news_dataset[\"train\"])\n",
    "news_test_data = pd.DataFrame(news_dataset[\"test\"])\n",
    "\n",
    "news_data = Dataset.from_pandas(pd.concat([news_train_data, news_test_data], ignore_index=True))\n",
    "news_data = news_data.shuffle(seed=42)\n",
    "\n",
    "news_temp_sentences, news_test_sentences, news_temp_labels, news_test_labels = train_test_split(\n",
    "                                                news_data['text'],\n",
    "                                                news_data['label'], \n",
    "                                                test_size=0.1, \n",
    "                                                random_state=42,\n",
    "                                                stratify=news_data['label'])\n",
    "\n",
    "news_train_sentences, news_val_sentences, news_train_labels, news_val_labels = train_test_split(\n",
    "                                                news_temp_sentences,\n",
    "                                                news_temp_labels,\n",
    "                                                test_size=0.1111,\n",
    "                                                random_state=42,\n",
    "                                                stratify=news_temp_labels)\n",
    "\n",
    "print(\"Dimensioni dei set:\")\n",
    "print(f\"Train: {len(news_train_sentences)}\")\n",
    "print(f\"Validation: {len(news_val_sentences)}\")\n",
    "print(f\"Test: {len(news_test_sentences)}\")\n",
    "\n",
    "# Verifica distribuzione delle etichette\n",
    "print(\"\\nDistribuzione delle etichette:\")\n",
    "print(f\"Train: {Counter(news_train_labels)}\")\n",
    "print(f\"Validation: {Counter(news_val_labels)}\")\n",
    "print(f\"Test: {Counter(news_test_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 128\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Inizializzo il Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Ottiengo i dataset\n",
    "news_training_data = ClassificationDataset(sentences = news_train_sentences,\n",
    "                           labels = news_train_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)\n",
    "\n",
    "news_validation_data = ClassificationDataset(sentences = news_val_sentences,\n",
    "                           labels = news_val_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)\n",
    "\n",
    "news_test_data = ClassificationDataset(sentences = news_test_sentences,\n",
    "                           labels = news_test_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Pretrained model\n",
    "lora_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=20)\n",
    "\n",
    "# LoRA config\n",
    "lora_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=128,\n",
    "    lora_dropout=0.2,\n",
    "    target_modules=[\"query\", \"key\", \"value\"],  \n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "lora_model = get_peft_model(lora_model, lora_config)\n",
    "lora_model.print_trainable_parameters()\n",
    "lora_model.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametri principali\n",
    "learning_rate = 5e-4\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Creo i DataLoader\n",
    "news_train_loader = DataLoader(news_training_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "news_val_loader = DataLoader(news_validation_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "news_test_loader = DataLoader(news_test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "total_steps = len(news_train_loader) * EPOCHS\n",
    "\n",
    "# Ottimizzatore\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, lora_model.parameters()), lr = learning_rate)\n",
    "\n",
    "\n",
    "# Scheduler\n",
    "scheduler = transformers.get_cosine_schedule_with_warmup(optimizer = optimizer,\n",
    "                                                       num_warmup_steps = 0,\n",
    "                                                       num_training_steps = total_steps) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history, total_time, emissions = train_and_evaluate_model(\n",
    "    lora_model,\"news\", news_train_loader, news_val_loader, optimizer, scheduler, device, epochs=EPOCHS \n",
    ") \n",
    "print(f\"\\nBERT with LoRA Training Time: {total_time:.2f} seconds, {total_time/60:.2f} minutes.\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model.load_state_dict(torch.load(\"news_best_model_state.bin\"))\n",
    "test_loss, test_acc, test_f1 = eval_model(lora_model, news_test_loader, device)\n",
    "print(f\"LoRA Fine-Tuning - Test loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}, F1 score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_task_results(\n",
    "    task_name=\"news\", \n",
    "    training_time=total_time,\n",
    "    emissions=emissions\n",
    "    test_loss=test_loss,\n",
    "    test_acc=test_acc,\n",
    "    test_f1=test_f1,\n",
    ")\n",
    "\n",
    "performance = pd.DataFrame(model_performance)\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBpedia 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T17:37:18.628330Z",
     "iopub.status.busy": "2025-03-12T17:37:18.628052Z",
     "iopub.status.idle": "2025-03-12T17:37:25.322964Z",
     "shell.execute_reply": "2025-03-12T17:37:25.321572Z",
     "shell.execute_reply.started": "2025-03-12T17:37:18.628309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensioni dei set:\n",
      "Train: 28000\n",
      "Validation: 5000\n",
      "Test: 5000\n",
      "\n",
      "Distribuzione delle etichette:\n",
      "Train: Counter({0: 2000, 1: 2000, 2: 2000, 3: 2000, 4: 2000, 5: 2000, 6: 2000, 7: 2000, 8: 2000, 9: 2000, 10: 2000, 11: 2000, 12: 2000, 13: 2000})\n",
      "Validation: Counter({11: 358, 9: 358, 2: 357, 7: 357, 1: 357, 10: 357, 6: 357, 3: 357, 0: 357, 13: 357, 12: 357, 5: 357, 8: 357, 4: 357})\n",
      "Test: Counter({12: 358, 10: 358, 1: 357, 6: 357, 3: 357, 5: 357, 9: 357, 4: 357, 2: 357, 0: 357, 11: 357, 8: 357, 7: 357, 13: 357})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-db0f45ac6817>:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  dbpedia_train_dataset = dbpedia_train_dataset.groupby(\"label\").apply(lambda x: x.sample(n=2000, random_state=42))\n"
     ]
    }
   ],
   "source": [
    "# Ottenimento del dataset\n",
    "dbpedia_train_dataset = pd.read_csv('/kaggle/input/dbpedia-ontology-dataset/train.csv')\n",
    "dbpedia_val_test_dataset = pd.read_csv('/kaggle/input/dbpedia-ontology-dataset/test.csv')\n",
    "\n",
    "# Costruisco il training set in modo da avere 2000 esempi per ognuna delle 14 classi\n",
    "dbpedia_train_dataset = dbpedia_train_dataset.groupby(\"label\").apply(lambda x: x.sample(n=2000, random_state=42))\n",
    "dbpedia_train_dataset.reset_index(drop=True, inplace=True)\n",
    "\n",
    "dbpedia_train_sentences, dbpedia_train_labels = dbpedia_train_dataset['content'], dbpedia_train_dataset['label']\n",
    "\n",
    "# Divido i dati di test in test e val set\n",
    "dbpedia_val_sentences, dbpedia_test_sentences, dbpedia_val_labels, dbpedia_test_labels = train_test_split(\n",
    "                                                dbpedia_val_test_dataset['content'], \n",
    "                                                dbpedia_val_test_dataset['label'], \n",
    "                                                train_size=5000,\n",
    "                                                test_size=5000,\n",
    "                                                random_state=42,\n",
    "                                                stratify=dbpedia_val_test_dataset['label']\n",
    "                                            )\n",
    "\n",
    "dbpedia_val_sentences = dbpedia_val_sentences.reset_index(drop=True)\n",
    "dbpedia_val_labels = dbpedia_val_labels.reset_index(drop=True)\n",
    "\n",
    "dbpedia_test_sentences = dbpedia_test_sentences.reset_index(drop=True)\n",
    "dbpedia_test_labels = dbpedia_test_labels.reset_index(drop=True)\n",
    "\n",
    "print(\"Dimensioni dei set:\")\n",
    "print(f\"Train: {len(dbpedia_train_sentences)}\")\n",
    "print(f\"Validation: {len(dbpedia_val_sentences)}\")\n",
    "print(f\"Test: {len(dbpedia_test_sentences)}\")\n",
    "\n",
    "print(\"\\nDistribuzione delle etichette:\")\n",
    "print(f\"Train: {Counter(dbpedia_train_labels.tolist())}\")\n",
    "print(f\"Validation: {Counter(dbpedia_val_labels.tolist())}\")\n",
    "print(f\"Test: {Counter(dbpedia_test_labels.tolist())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 512\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Inizializzo il Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Ottiengo i dataset\n",
    "dbpedia_training_data = ClassificationDataset(sentences = dbpedia_train_sentences,\n",
    "                           labels = dbpedia_train_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)\n",
    "\n",
    "dbpedia_validation_data = ClassificationDataset(sentences = dbpedia_val_sentences,\n",
    "                           labels = dbpedia_val_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)\n",
    "\n",
    "dbpedia_test_data = ClassificationDataset(sentences = dbpedia_test_sentences,\n",
    "                           labels = dbpedia_test_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Pretrained model\n",
    "lora_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=14)\n",
    "\n",
    "# LoRA config\n",
    "lora_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=128,\n",
    "    lora_dropout=0.2,\n",
    "    target_modules=[\"query\", \"key\", \"value\"],  \n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "lora_model = get_peft_model(lora_model, lora_config)\n",
    "lora_model.print_trainable_parameters()\n",
    "lora_model.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in lora_model.named_parameters():\n",
    "    if \"classifier\" in name:\n",
    "        param.requires_grad = True\n",
    "\n",
    "for name, param in lora_model.named_parameters():\n",
    "    if \"classifier\" in name:\n",
    "        print(f\"{name}: requires_grad = {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametri principali\n",
    "learning_rate = 5e-4\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Creo i DataLoader\n",
    "dbpedia_train_loader = DataLoader(dbpedia_training_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dbpedia_val_loader = DataLoader(dbpedia_validation_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "dbpedia_test_loader = DataLoader(dbpedia_test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "total_steps = len(dbpedia_train_loader) * EPOCHS\n",
    "\n",
    "# Ottimizzatore\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, lora_model.parameters()), lr = learning_rate)\n",
    "\n",
    "\n",
    "# Scheduler\n",
    "scheduler = transformers.get_cosine_schedule_with_warmup(optimizer = optimizer,\n",
    "                                                       num_warmup_steps = 0,\n",
    "                                                       num_training_steps = total_steps) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history, total_time, emissions = train_and_evaluate_model(\n",
    "    lora_model,\"dbpedia\", dbpedia_train_loader, dbpedia_val_loader, optimizer, scheduler, device, epochs=EPOCHS \n",
    ")\n",
    "print(f\"\\nBERT with LoRA Training Time: {total_time:.2f} seconds, {total_time/60:.2f} minutes.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model.load_state_dict(torch.load(\"dbpedia_best_model_state.bin\"))\n",
    "test_loss, test_acc, test_f1 = eval_model(lora_model, dbpedia_test_loader, device)\n",
    "print(f\"LoRA Fine-Tuning - Test loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}, F1 score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_task_results(\n",
    "    task_name=\"dbpedia\", \n",
    "    training_time=total_time,\n",
    "    emissions=emissions,\n",
    "    test_loss=test_loss,\n",
    "    test_acc=test_acc,\n",
    "    test_f1=test_f1,\n",
    ")\n",
    "\n",
    "performance = pd.DataFrame(model_performance)\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotion Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 16000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Ottenimento del dataset\n",
    "emotion_dataset = load_dataset(\"dair-ai/emotion\")\n",
    "print(emotion_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensioni dei set:\n",
      "Train: 16000\n",
      "Validation: 2000\n",
      "Test: 2000\n",
      "\n",
      "Distribuzione delle etichette:\n",
      "Train: Counter({1: 5362, 0: 4666, 3: 2159, 4: 1937, 2: 1304, 5: 572})\n",
      "Validation: Counter({1: 704, 0: 550, 3: 275, 4: 212, 2: 178, 5: 81})\n",
      "Test: Counter({1: 695, 0: 581, 3: 275, 4: 224, 2: 159, 5: 66})\n"
     ]
    }
   ],
   "source": [
    "#Divido i dati in training, validation e test set\n",
    "emotion_train_data = emotion_dataset[\"train\"].shuffle(seed=42)\n",
    "emotion_val_data = emotion_dataset[\"validation\"].shuffle(seed=42)\n",
    "emotion_test_data = emotion_dataset[\"test\"].shuffle(seed=42)\n",
    "\n",
    "emotion_train_sentences, emotion_train_labels = emotion_train_data['text'],emotion_train_data['label']\n",
    "emotion_val_sentences, emotion_val_labels = emotion_val_data['text'],emotion_val_data['label']\n",
    "emotion_test_sentences, emotion_test_labels = emotion_test_data['text'],emotion_test_data['label']\n",
    "\n",
    "print(\"Dimensioni dei set:\")\n",
    "print(f\"Train: {len(emotion_train_sentences)}\")\n",
    "print(f\"Validation: {len(emotion_val_sentences)}\")\n",
    "print(f\"Test: {len(emotion_test_sentences)}\")\n",
    "\n",
    "# Verifica distribuzione delle etichette\n",
    "print(\"\\nDistribuzione delle etichette:\")\n",
    "print(f\"Train: {Counter(emotion_train_labels)}\")\n",
    "print(f\"Validation: {Counter(emotion_val_labels)}\")\n",
    "print(f\"Test: {Counter(emotion_test_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 128\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Inizializzo il Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Ottiengo i dataset\n",
    "emotion_training_data = ClassificationDataset(\n",
    "                            sentences = emotion_train_sentences,\n",
    "                            labels = emotion_train_labels,\n",
    "                            tokenizer = tokenizer,\n",
    "                            max_len = MAX_SEQ_LEN)\n",
    "\n",
    "emotion_validation_data = ClassificationDataset(\n",
    "                            sentences = emotion_val_sentences,\n",
    "                            labels = emotion_val_labels,\n",
    "                            tokenizer = tokenizer,\n",
    "                            max_len = MAX_SEQ_LEN)\n",
    "\n",
    "emotion_test_data = ClassificationDataset(\n",
    "                            sentences = emotion_test_sentences,\n",
    "                            labels = emotion_test_labels,\n",
    "                            tokenizer = tokenizer,\n",
    "                            max_len = MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,769,472 || all params: 111,256,326 || trainable%: 1.5904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): BertForSequenceClassification(\n",
       "      (bert): BertModel(\n",
       "        (embeddings): BertEmbeddings(\n",
       "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "          (position_embeddings): Embedding(512, 768)\n",
       "          (token_type_embeddings): Embedding(2, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): BertEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSdpaSelfAttention(\n",
       "                  (query): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.3, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (key): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.3, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (value): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.3, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (pooler): BertPooler(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (activation): Tanh()\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Pretrained model\n",
    "lora_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=6)\n",
    "\n",
    "# LoRA config\n",
    "lora_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=128,\n",
    "    lora_dropout=0.3,\n",
    "    target_modules=[\"query\", \"key\", \"value\"],  \n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "lora_model = get_peft_model(lora_model, lora_config)\n",
    "lora_model.print_trainable_parameters()\n",
    "lora_model.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametri principali\n",
    "learning_rate = 2e-4\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Creo i DataLoader\n",
    "emotion_train_loader = DataLoader(emotion_training_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "emotion_val_loader = DataLoader(emotion_validation_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "emotion_test_loader = DataLoader(emotion_test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "total_steps = len(emotion_train_loader) * EPOCHS\n",
    "\n",
    "# Ottimizzatore\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, lora_model.parameters()), lr = learning_rate)\n",
    "\n",
    "\n",
    "# Scheduler\n",
    "scheduler = transformers.get_cosine_schedule_with_warmup(optimizer = optimizer,\n",
    "                                                       num_warmup_steps = 0,\n",
    "                                                       num_training_steps = total_steps) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in lora_model.named_parameters():\n",
    "    if \"classifier\" in name:\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 09:27:05] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 09:27:05] [setup] CPU Tracking...\n",
      "[codecarbon INFO @ 09:27:05] Tracking Intel CPU via RAPL interface\n",
      "[codecarbon INFO @ 09:27:06] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 09:27:06] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 09:27:06] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:27:06] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:27:06] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:27:06] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:27:06] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:27:06] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:27:06] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon WARNING @ 09:27:06] You have 8 GPUs but we will monitor only 1 of them. Check your configuration.\n",
      "[codecarbon INFO @ 09:27:06] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 09:27:06]   Platform system: Linux-6.8.0-55-generic-x86_64-with-glibc2.39\n",
      "[codecarbon INFO @ 09:27:06]   Python version: 3.12.3\n",
      "[codecarbon INFO @ 09:27:06]   CodeCarbon version: 2.8.3\n",
      "[codecarbon INFO @ 09:27:06]   Available RAM : 754.342 GB\n",
      "[codecarbon INFO @ 09:27:06]   CPU count: 96\n",
      "[codecarbon INFO @ 09:27:06]   CPU model: Intel(R) Xeon(R) Gold 6248R CPU @ 3.00GHz\n",
      "[codecarbon INFO @ 09:27:06]   GPU count: 1\n",
      "[codecarbon INFO @ 09:27:06]   GPU model: 8 x NVIDIA A30 BUT only tracking these GPU ids : [6]\n",
      "[codecarbon INFO @ 09:27:09] Saving emissions data to file /home/notebook/riccardo_cantini/tesisti/Dagostino/carbon_emissions/emissions.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :  14%|█▍        | 71/500 [00:14<01:27,  4.88it/s, accuracy=0.338, loss=1.57][codecarbon INFO @ 09:27:24] Energy consumed for RAM : 0.001183 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:27:24] Energy consumed for all CPUs : 0.000351 kWh. Total CPU Power : 83.96225757274186 W\n",
      "[codecarbon INFO @ 09:27:24] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:27:24] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:27:24] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:27:24] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:27:24] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:27:24] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:27:24] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:27:24] Energy consumed for all GPUs : 0.000607 kWh. Total GPU Power : 145.21206471849285 W\n",
      "[codecarbon INFO @ 09:27:24] 0.002141 kWh of electricity used since the beginning.\n",
      "Training  :  29%|██▉       | 144/500 [00:29<01:13,  4.84it/s, accuracy=0.452, loss=1.42][codecarbon INFO @ 09:27:39] Energy consumed for RAM : 0.002358 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:27:39] Energy consumed for all CPUs : 0.000698 kWh. Total CPU Power : 83.40345882994079 W\n",
      "[codecarbon INFO @ 09:27:39] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:27:39] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:27:39] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:27:39] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:27:39] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:27:39] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:27:39] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:27:39] Energy consumed for all GPUs : 0.001229 kWh. Total GPU Power : 149.74647491966329 W\n",
      "[codecarbon INFO @ 09:27:39] 0.004284 kWh of electricity used since the beginning.\n",
      "Training  :  43%|████▎     | 216/500 [00:44<00:58,  4.82it/s, accuracy=0.534, loss=1.28][codecarbon INFO @ 09:27:54] Energy consumed for RAM : 0.003532 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:27:54] Energy consumed for all CPUs : 0.001045 kWh. Total CPU Power : 83.65078939858134 W\n",
      "[codecarbon INFO @ 09:27:54] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:27:54] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:27:54] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:27:54] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:27:54] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:27:54] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:27:54] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:27:54] Energy consumed for all GPUs : 0.001856 kWh. Total GPU Power : 150.87995307307355 W\n",
      "[codecarbon INFO @ 09:27:54] 0.006433 kWh of electricity used since the beginning.\n",
      "Training  :  58%|█████▊    | 288/500 [00:59<00:44,  4.78it/s, accuracy=0.588, loss=1.18][codecarbon INFO @ 09:28:09] Energy consumed for RAM : 0.004708 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:28:09] Energy consumed for all CPUs : 0.001393 kWh. Total CPU Power : 83.7965329117548 W\n",
      "[codecarbon INFO @ 09:28:09] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:28:09] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:28:09] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:28:09] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:28:09] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:28:09] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:28:09] GPU number 7 will not be monitored, at your request.\n",
      "Training  :  58%|█████▊    | 289/500 [01:00<00:44,  4.79it/s, accuracy=0.589, loss=1.18][codecarbon INFO @ 09:28:09] Energy consumed for all GPUs : 0.002480 kWh. Total GPU Power : 150.0560705609621 W\n",
      "[codecarbon INFO @ 09:28:09] 0.008580 kWh of electricity used since the beginning.\n",
      "Training  :  72%|███████▏  | 360/500 [01:14<00:29,  4.78it/s, accuracy=0.632, loss=1.09][codecarbon INFO @ 09:28:24] Energy consumed for RAM : 0.005882 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:28:24] Energy consumed for all CPUs : 0.001742 kWh. Total CPU Power : 83.93006042330263 W\n",
      "[codecarbon INFO @ 09:28:24] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:28:24] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:28:24] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:28:24] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:28:24] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:28:24] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:28:24] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:28:24] Energy consumed for all GPUs : 0.003109 kWh. Total GPU Power : 151.56061999852966 W\n",
      "[codecarbon INFO @ 09:28:24] 0.010733 kWh of electricity used since the beginning.\n",
      "Training  :  86%|████████▋ | 432/500 [01:29<00:14,  4.76it/s, accuracy=0.666, loss=1.02][codecarbon INFO @ 09:28:39] Energy consumed for RAM : 0.007057 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:28:39] Energy consumed for all CPUs : 0.002091 kWh. Total CPU Power : 83.96831584529578 W\n",
      "[codecarbon INFO @ 09:28:39] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:28:39] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:28:39] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:28:39] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:28:39] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:28:39] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:28:39] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:28:39] Energy consumed for all GPUs : 0.003735 kWh. Total GPU Power : 150.65822400164188 W\n",
      "[codecarbon INFO @ 09:28:39] 0.012884 kWh of electricity used since the beginning.\n",
      "Training  : 100%|██████████| 500/500 [01:44<00:00,  4.79it/s, accuracy=0.692, loss=0.962]\n",
      "Evaluating:   8%|▊         | 5/63 [00:00<00:06,  9.25it/s, accuracy=0.912, loss=0.471][codecarbon INFO @ 09:28:54] Energy consumed for RAM : 0.008231 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:28:54] Energy consumed for all CPUs : 0.002440 kWh. Total CPU Power : 84.10111396442228 W\n",
      "[codecarbon INFO @ 09:28:54] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:28:54] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:28:54] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:28:54] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:28:54] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:28:54] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:28:54] GPU number 7 will not be monitored, at your request.\n",
      "Evaluating:  10%|▉         | 6/63 [00:00<00:06,  9.29it/s, accuracy=0.906, loss=0.475][codecarbon INFO @ 09:28:54] Energy consumed for all GPUs : 0.004364 kWh. Total GPU Power : 151.3812954506469 W\n",
      "[codecarbon INFO @ 09:28:54] 0.015034 kWh of electricity used since the beginning.\n",
      "Evaluating: 100%|██████████| 63/63 [00:06<00:00,  9.27it/s, accuracy=0.907, loss=0.484]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :   8%|▊         | 40/500 [00:08<01:35,  4.84it/s, accuracy=0.896, loss=0.524][codecarbon INFO @ 09:29:09] Energy consumed for RAM : 0.009406 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:29:09] Energy consumed for all CPUs : 0.002790 kWh. Total CPU Power : 84.46513782203752 W\n",
      "[codecarbon INFO @ 09:29:09] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:29:09] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:29:09] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:29:09] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:29:09] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:29:09] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:29:09] GPU number 7 will not be monitored, at your request.\n",
      "Training  :   8%|▊         | 41/500 [00:08<01:34,  4.84it/s, accuracy=0.894, loss=0.524][codecarbon INFO @ 09:29:09] Energy consumed for all GPUs : 0.005000 kWh. Total GPU Power : 153.34711710736408 W\n",
      "[codecarbon INFO @ 09:29:09] 0.017196 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 09:29:09] 0.047349 g.CO2eq/s mean an estimation of 1,493.1875116988829 kg.CO2eq/year\n",
      "Training  :  23%|██▎       | 113/500 [00:23<01:20,  4.81it/s, accuracy=0.892, loss=0.516][codecarbon INFO @ 09:29:24] Energy consumed for RAM : 0.010580 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:29:24] Energy consumed for all CPUs : 0.003139 kWh. Total CPU Power : 84.04062579165029 W\n",
      "[codecarbon INFO @ 09:29:24] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:29:24] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:29:24] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:29:24] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:29:24] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:29:24] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:29:24] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:29:24] Energy consumed for all GPUs : 0.005636 kWh. Total GPU Power : 153.1111771377508 W\n",
      "[codecarbon INFO @ 09:29:24] 0.019355 kWh of electricity used since the beginning.\n",
      "Training  :  37%|███▋      | 185/500 [00:38<01:06,  4.77it/s, accuracy=0.898, loss=0.501][codecarbon INFO @ 09:29:39] Energy consumed for RAM : 0.011754 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:29:39] Energy consumed for all CPUs : 0.003492 kWh. Total CPU Power : 84.9003180971959 W\n",
      "[codecarbon INFO @ 09:29:39] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:29:39] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:29:39] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:29:39] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:29:39] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:29:39] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:29:39] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:29:39] Energy consumed for all GPUs : 0.006281 kWh. Total GPU Power : 155.37324019807153 W\n",
      "[codecarbon INFO @ 09:29:39] 0.021527 kWh of electricity used since the beginning.\n",
      "Training  :  51%|█████     | 256/500 [00:53<00:51,  4.75it/s, accuracy=0.902, loss=0.487][codecarbon INFO @ 09:29:54] Energy consumed for RAM : 0.012929 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:29:54] Energy consumed for all CPUs : 0.003840 kWh. Total CPU Power : 83.94458677496166 W\n",
      "[codecarbon INFO @ 09:29:54] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:29:54] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:29:54] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:29:54] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:29:54] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:29:54] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:29:54] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:29:54] Energy consumed for all GPUs : 0.006924 kWh. Total GPU Power : 154.85500719462155 W\n",
      "[codecarbon INFO @ 09:29:54] 0.023693 kWh of electricity used since the beginning.\n",
      "Training  :  65%|██████▌   | 327/500 [01:08<00:36,  4.75it/s, accuracy=0.903, loss=0.478][codecarbon INFO @ 09:30:09] Energy consumed for RAM : 0.014103 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:30:09] Energy consumed for all CPUs : 0.004189 kWh. Total CPU Power : 83.8743821726581 W\n",
      "[codecarbon INFO @ 09:30:09] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:30:09] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:30:09] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:30:09] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:30:09] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:30:09] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:30:09] GPU number 7 will not be monitored, at your request.\n",
      "Training  :  66%|██████▌   | 328/500 [01:08<00:36,  4.73it/s, accuracy=0.903, loss=0.478][codecarbon INFO @ 09:30:09] Energy consumed for all GPUs : 0.007569 kWh. Total GPU Power : 155.19041447490332 W\n",
      "[codecarbon INFO @ 09:30:09] 0.025860 kWh of electricity used since the beginning.\n",
      "Training  :  80%|███████▉  | 398/500 [01:23<00:21,  4.68it/s, accuracy=0.907, loss=0.467][codecarbon INFO @ 09:30:24] Energy consumed for RAM : 0.015278 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:30:24] Energy consumed for all CPUs : 0.004537 kWh. Total CPU Power : 83.97622971624094 W\n",
      "[codecarbon INFO @ 09:30:24] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:30:24] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:30:24] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:30:24] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:30:24] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:30:24] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:30:24] GPU number 7 will not be monitored, at your request.\n",
      "Training  :  80%|███████▉  | 399/500 [01:23<00:21,  4.61it/s, accuracy=0.907, loss=0.467][codecarbon INFO @ 09:30:24] Energy consumed for all GPUs : 0.008209 kWh. Total GPU Power : 154.12384967881096 W\n",
      "[codecarbon INFO @ 09:30:24] 0.028024 kWh of electricity used since the beginning.\n",
      "Training  :  94%|█████████▍| 469/500 [01:38<00:06,  4.70it/s, accuracy=0.91, loss=0.458][codecarbon INFO @ 09:30:39] Energy consumed for RAM : 0.016453 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:30:39] Energy consumed for all CPUs : 0.004886 kWh. Total CPU Power : 83.94948819447933 W\n",
      "[codecarbon INFO @ 09:30:39] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:30:39] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:30:39] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:30:39] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:30:39] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:30:39] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:30:39] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:30:39] Energy consumed for all GPUs : 0.008853 kWh. Total GPU Power : 154.94780143632744 W\n",
      "[codecarbon INFO @ 09:30:39] 0.030191 kWh of electricity used since the beginning.\n",
      "Training  : 100%|██████████| 500/500 [01:44<00:00,  4.76it/s, accuracy=0.909, loss=0.457]\n",
      "Evaluating: 100%|██████████| 63/63 [00:06<00:00,  9.19it/s, accuracy=0.931, loss=0.345]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :   1%|          | 5/500 [00:01<01:43,  4.78it/s, accuracy=0.9, loss=0.437][codecarbon INFO @ 09:30:54] Energy consumed for RAM : 0.017627 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:30:54] Energy consumed for all CPUs : 0.005237 kWh. Total CPU Power : 84.49913545717597 W\n",
      "[codecarbon INFO @ 09:30:54] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:30:54] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:30:54] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:30:54] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:30:54] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:30:54] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:30:54] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:30:54] Energy consumed for all GPUs : 0.009486 kWh. Total GPU Power : 152.40248944823932 W\n",
      "[codecarbon INFO @ 09:30:54] 0.032350 kWh of electricity used since the beginning.\n",
      "Training  :  15%|█▌        | 77/500 [00:16<01:28,  4.79it/s, accuracy=0.92, loss=0.396][codecarbon INFO @ 09:31:09] Energy consumed for RAM : 0.018802 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:31:09] Energy consumed for all CPUs : 0.005586 kWh. Total CPU Power : 84.07722145971138 W\n",
      "[codecarbon INFO @ 09:31:09] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:31:09] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:31:09] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:31:09] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:31:09] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:31:09] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:31:09] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:31:09] Energy consumed for all GPUs : 0.010143 kWh. Total GPU Power : 158.17702550329884 W\n",
      "[codecarbon INFO @ 09:31:09] 0.034531 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 09:31:09] 0.047777 g.CO2eq/s mean an estimation of 1,506.6808037717567 kg.CO2eq/year\n",
      "Training  :  30%|██▉       | 149/500 [00:31<01:13,  4.76it/s, accuracy=0.92, loss=0.39][codecarbon INFO @ 09:31:24] Energy consumed for RAM : 0.019977 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:31:24] Energy consumed for all CPUs : 0.005936 kWh. Total CPU Power : 84.05751423614663 W\n",
      "[codecarbon INFO @ 09:31:24] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:31:24] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:31:24] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:31:24] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:31:24] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:31:24] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:31:24] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:31:24] Energy consumed for all GPUs : 0.010792 kWh. Total GPU Power : 156.2841006918758 W\n",
      "[codecarbon INFO @ 09:31:24] 0.036705 kWh of electricity used since the beginning.\n",
      "Training  :  44%|████▍     | 220/500 [00:46<00:59,  4.74it/s, accuracy=0.927, loss=0.378][codecarbon INFO @ 09:31:39] Energy consumed for RAM : 0.021150 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:31:39] Energy consumed for all CPUs : 0.006284 kWh. Total CPU Power : 84.12440792474581 W\n",
      "[codecarbon INFO @ 09:31:39] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:31:39] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:31:39] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:31:39] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:31:39] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:31:39] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:31:39] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:31:39] Energy consumed for all GPUs : 0.011439 kWh. Total GPU Power : 155.92006018304951 W\n",
      "[codecarbon INFO @ 09:31:39] 0.038874 kWh of electricity used since the beginning.\n",
      "Training  :  58%|█████▊    | 291/500 [01:00<00:44,  4.73it/s, accuracy=0.926, loss=0.377][codecarbon INFO @ 09:31:54] Energy consumed for RAM : 0.022325 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:31:54] Energy consumed for all CPUs : 0.006633 kWh. Total CPU Power : 83.83348746458185 W\n",
      "[codecarbon INFO @ 09:31:54] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:31:54] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:31:54] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:31:54] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:31:54] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:31:54] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:31:54] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:31:54] Energy consumed for all GPUs : 0.012090 kWh. Total GPU Power : 156.66744059882794 W\n",
      "[codecarbon INFO @ 09:31:54] 0.041047 kWh of electricity used since the beginning.\n",
      "Training  :  72%|███████▏  | 362/500 [01:16<00:29,  4.73it/s, accuracy=0.927, loss=0.375][codecarbon INFO @ 09:32:09] Energy consumed for RAM : 0.023500 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:32:09] Energy consumed for all CPUs : 0.006981 kWh. Total CPU Power : 83.8958827728827 W\n",
      "[codecarbon INFO @ 09:32:09] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:32:09] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:32:09] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:32:09] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:32:09] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:32:09] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:32:09] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:32:09] Energy consumed for all GPUs : 0.012737 kWh. Total GPU Power : 155.74554549564607 W\n",
      "[codecarbon INFO @ 09:32:09] 0.043218 kWh of electricity used since the beginning.\n",
      "Training  :  87%|████████▋ | 433/500 [01:31<00:14,  4.68it/s, accuracy=0.928, loss=0.371][codecarbon INFO @ 09:32:24] Energy consumed for RAM : 0.024675 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:32:24] Energy consumed for all CPUs : 0.007330 kWh. Total CPU Power : 83.92687971044137 W\n",
      "[codecarbon INFO @ 09:32:24] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:32:24] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:32:24] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:32:24] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:32:24] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:32:24] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:32:24] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:32:24] Energy consumed for all GPUs : 0.013386 kWh. Total GPU Power : 156.2067098605081 W\n",
      "[codecarbon INFO @ 09:32:24] 0.045391 kWh of electricity used since the beginning.\n",
      "Training  : 100%|██████████| 500/500 [01:45<00:00,  4.75it/s, accuracy=0.927, loss=0.371]\n",
      "Evaluating:  10%|▉         | 6/63 [00:00<00:06,  9.21it/s, accuracy=0.943, loss=0.317][codecarbon INFO @ 09:32:39] Energy consumed for RAM : 0.025848 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:32:39] Energy consumed for all CPUs : 0.007678 kWh. Total CPU Power : 83.88649275940332 W\n",
      "[codecarbon INFO @ 09:32:39] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:32:39] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:32:39] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:32:39] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:32:39] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:32:39] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:32:39] GPU number 7 will not be monitored, at your request.\n",
      "Evaluating:  11%|█         | 7/63 [00:00<00:06,  9.18it/s, accuracy=0.938, loss=0.316][codecarbon INFO @ 09:32:39] Energy consumed for all GPUs : 0.014029 kWh. Total GPU Power : 155.03426161758915 W\n",
      "[codecarbon INFO @ 09:32:39] 0.047555 kWh of electricity used since the beginning.\n",
      "Evaluating: 100%|██████████| 63/63 [00:06<00:00,  9.19it/s, accuracy=0.928, loss=0.31] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :   8%|▊         | 42/500 [00:08<01:35,  4.79it/s, accuracy=0.943, loss=0.337][codecarbon INFO @ 09:32:54] Energy consumed for RAM : 0.027023 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:32:54] Energy consumed for all CPUs : 0.008027 kWh. Total CPU Power : 84.12399889411157 W\n",
      "[codecarbon INFO @ 09:32:54] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:32:54] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:32:54] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:32:54] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:32:54] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:32:54] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:32:54] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:32:54] Energy consumed for all GPUs : 0.014681 kWh. Total GPU Power : 156.9682526383707 W\n",
      "[codecarbon INFO @ 09:32:54] 0.049731 kWh of electricity used since the beginning.\n",
      "Training  :  23%|██▎       | 114/500 [00:23<01:20,  4.79it/s, accuracy=0.94, loss=0.336][codecarbon INFO @ 09:33:09] Energy consumed for RAM : 0.028198 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:33:09] Energy consumed for all CPUs : 0.008375 kWh. Total CPU Power : 83.63829694623023 W\n",
      "[codecarbon INFO @ 09:33:09] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:33:09] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:33:09] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:33:09] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:33:09] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:33:09] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:33:09] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:33:09] Energy consumed for all GPUs : 0.015337 kWh. Total GPU Power : 157.76810246641563 W\n",
      "[codecarbon INFO @ 09:33:09] 0.051909 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 09:33:09] 0.047890 g.CO2eq/s mean an estimation of 1,510.2745712108645 kg.CO2eq/year\n",
      "Training  :  37%|███▋      | 186/500 [00:38<01:05,  4.77it/s, accuracy=0.938, loss=0.34][codecarbon INFO @ 09:33:24] Energy consumed for RAM : 0.029372 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:33:24] Energy consumed for all CPUs : 0.008722 kWh. Total CPU Power : 83.54947951381354 W\n",
      "[codecarbon INFO @ 09:33:24] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:33:24] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:33:24] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:33:24] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:33:24] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:33:24] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:33:24] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:33:24] Energy consumed for all GPUs : 0.015989 kWh. Total GPU Power : 157.0582736451722 W\n",
      "[codecarbon INFO @ 09:33:24] 0.054083 kWh of electricity used since the beginning.\n",
      "Training  :  51%|█████▏    | 257/500 [00:53<00:51,  4.75it/s, accuracy=0.939, loss=0.338][codecarbon INFO @ 09:33:39] Energy consumed for RAM : 0.030547 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:33:39] Energy consumed for all CPUs : 0.009069 kWh. Total CPU Power : 83.66791423549293 W\n",
      "[codecarbon INFO @ 09:33:39] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:33:39] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:33:39] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:33:39] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:33:39] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:33:39] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:33:39] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:33:39] Energy consumed for all GPUs : 0.016637 kWh. Total GPU Power : 156.08298558813775 W\n",
      "[codecarbon INFO @ 09:33:39] 0.056254 kWh of electricity used since the beginning.\n",
      "Training  :  66%|██████▌   | 328/500 [01:08<00:36,  4.73it/s, accuracy=0.938, loss=0.337][codecarbon INFO @ 09:33:54] Energy consumed for RAM : 0.031722 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:33:54] Energy consumed for all CPUs : 0.009417 kWh. Total CPU Power : 83.67755359711089 W\n",
      "[codecarbon INFO @ 09:33:54] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:33:54] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:33:54] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:33:54] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:33:54] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:33:54] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:33:54] GPU number 7 will not be monitored, at your request.\n",
      "Training  :  66%|██████▌   | 329/500 [01:08<00:36,  4.72it/s, accuracy=0.938, loss=0.337][codecarbon INFO @ 09:33:54] Energy consumed for all GPUs : 0.017286 kWh. Total GPU Power : 156.219964256187 W\n",
      "[codecarbon INFO @ 09:33:54] 0.058425 kWh of electricity used since the beginning.\n",
      "Training  :  80%|███████▉  | 399/500 [01:23<00:21,  4.72it/s, accuracy=0.936, loss=0.339][codecarbon INFO @ 09:34:09] Energy consumed for RAM : 0.032896 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:34:09] Energy consumed for all CPUs : 0.009764 kWh. Total CPU Power : 83.75401024446208 W\n",
      "[codecarbon INFO @ 09:34:09] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:34:09] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:34:09] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:34:09] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:34:09] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:34:09] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:34:09] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:34:09] Energy consumed for all GPUs : 0.017930 kWh. Total GPU Power : 155.08083294901638 W\n",
      "[codecarbon INFO @ 09:34:09] 0.060590 kWh of electricity used since the beginning.\n",
      "Training  :  94%|█████████▍| 470/500 [01:38<00:06,  4.69it/s, accuracy=0.937, loss=0.337][codecarbon INFO @ 09:34:24] Energy consumed for RAM : 0.034071 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:34:24] Energy consumed for all CPUs : 0.010112 kWh. Total CPU Power : 83.63113080096849 W\n",
      "[codecarbon INFO @ 09:34:24] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:34:24] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:34:24] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:34:24] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:34:24] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:34:24] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:34:24] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:34:24] Energy consumed for all GPUs : 0.018574 kWh. Total GPU Power : 155.08946009788679 W\n",
      "[codecarbon INFO @ 09:34:24] 0.062756 kWh of electricity used since the beginning.\n",
      "Training  : 100%|██████████| 500/500 [01:45<00:00,  4.75it/s, accuracy=0.937, loss=0.336]\n",
      "Evaluating: 100%|██████████| 63/63 [00:06<00:00,  9.19it/s, accuracy=0.944, loss=0.284]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :   1%|          | 6/500 [00:01<01:42,  4.82it/s, accuracy=0.938, loss=0.33][codecarbon INFO @ 09:34:39] Energy consumed for RAM : 0.035245 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:34:39] Energy consumed for all CPUs : 0.010461 kWh. Total CPU Power : 84.04731749227292 W\n",
      "[codecarbon INFO @ 09:34:39] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:34:39] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:34:39] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:34:39] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:34:39] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:34:39] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:34:39] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:34:39] Energy consumed for all GPUs : 0.019213 kWh. Total GPU Power : 153.83118756153635 W\n",
      "[codecarbon INFO @ 09:34:39] 0.064918 kWh of electricity used since the beginning.\n",
      "Training  :  16%|█▌        | 78/500 [00:16<01:27,  4.81it/s, accuracy=0.952, loss=0.3][codecarbon INFO @ 09:34:54] Energy consumed for RAM : 0.036420 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:34:54] Energy consumed for all CPUs : 0.010807 kWh. Total CPU Power : 83.46993185252171 W\n",
      "[codecarbon INFO @ 09:34:54] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:34:54] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:34:54] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:34:54] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:34:54] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:34:54] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:34:54] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:34:54] Energy consumed for all GPUs : 0.019865 kWh. Total GPU Power : 157.04305409466582 W\n",
      "[codecarbon INFO @ 09:34:54] 0.067093 kWh of electricity used since the beginning.\n",
      "Training  :  30%|███       | 150/500 [00:31<01:13,  4.78it/s, accuracy=0.949, loss=0.308][codecarbon INFO @ 09:35:09] Energy consumed for RAM : 0.037595 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:35:09] Energy consumed for all CPUs : 0.011154 kWh. Total CPU Power : 83.45038359439991 W\n",
      "[codecarbon INFO @ 09:35:09] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:35:09] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:35:09] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:35:09] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:35:09] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:35:09] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:35:09] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:35:09] Energy consumed for all GPUs : 0.020519 kWh. Total GPU Power : 157.3431140590717 W\n",
      "[codecarbon INFO @ 09:35:09] 0.069267 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 09:35:09] 0.047838 g.CO2eq/s mean an estimation of 1,508.6276727296301 kg.CO2eq/year\n",
      "Training  :  44%|████▍     | 222/500 [00:46<00:58,  4.76it/s, accuracy=0.948, loss=0.308][codecarbon INFO @ 09:35:24] Energy consumed for RAM : 0.038770 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:35:24] Energy consumed for all CPUs : 0.011500 kWh. Total CPU Power : 83.36888086746772 W\n",
      "[codecarbon INFO @ 09:35:24] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:35:24] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:35:24] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:35:24] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:35:24] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:35:24] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:35:24] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:35:24] Energy consumed for all GPUs : 0.021166 kWh. Total GPU Power : 155.95469647126774 W\n",
      "[codecarbon INFO @ 09:35:24] 0.071436 kWh of electricity used since the beginning.\n",
      "Training  :  59%|█████▊    | 293/500 [01:01<00:43,  4.74it/s, accuracy=0.947, loss=0.312][codecarbon INFO @ 09:35:39] Energy consumed for RAM : 0.039944 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:35:39] Energy consumed for all CPUs : 0.011846 kWh. Total CPU Power : 83.3723957902861 W\n",
      "[codecarbon INFO @ 09:35:39] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:35:39] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:35:39] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:35:39] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:35:39] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:35:39] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:35:39] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:35:39] Energy consumed for all GPUs : 0.021816 kWh. Total GPU Power : 156.41351083592266 W\n",
      "[codecarbon INFO @ 09:35:39] 0.073607 kWh of electricity used since the beginning.\n",
      "Training  :  73%|███████▎  | 364/500 [01:16<00:28,  4.74it/s, accuracy=0.947, loss=0.312][codecarbon INFO @ 09:35:54] Energy consumed for RAM : 0.041120 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:35:54] Energy consumed for all CPUs : 0.012193 kWh. Total CPU Power : 83.3183960313 W\n",
      "[codecarbon INFO @ 09:35:54] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:35:54] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:35:54] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:35:54] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:35:54] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:35:54] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:35:54] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:35:54] Energy consumed for all GPUs : 0.022463 kWh. Total GPU Power : 155.56815631499077 W\n",
      "[codecarbon INFO @ 09:35:54] 0.075775 kWh of electricity used since the beginning.\n",
      "Training  :  87%|████████▋ | 435/500 [01:31<00:13,  4.71it/s, accuracy=0.946, loss=0.312][codecarbon INFO @ 09:36:09] Energy consumed for RAM : 0.042294 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:36:09] Energy consumed for all CPUs : 0.012539 kWh. Total CPU Power : 83.53171374624323 W\n",
      "[codecarbon INFO @ 09:36:09] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:36:09] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:36:09] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:36:09] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:36:09] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:36:09] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:36:09] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:36:09] Energy consumed for all GPUs : 0.023109 kWh. Total GPU Power : 155.73668758433587 W\n",
      "[codecarbon INFO @ 09:36:09] 0.077942 kWh of electricity used since the beginning.\n",
      "Training  : 100%|██████████| 500/500 [01:45<00:00,  4.76it/s, accuracy=0.946, loss=0.31] \n",
      "Evaluating:  17%|█▋        | 11/63 [00:01<00:05,  9.17it/s, accuracy=0.94, loss=0.284][codecarbon INFO @ 09:36:24] Energy consumed for RAM : 0.043469 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:36:24] Energy consumed for all CPUs : 0.012887 kWh. Total CPU Power : 83.63471992182335 W\n",
      "[codecarbon INFO @ 09:36:24] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:36:24] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:36:24] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:36:24] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:36:24] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:36:24] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:36:24] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:36:24] Energy consumed for all GPUs : 0.023753 kWh. Total GPU Power : 154.96031384555988 W\n",
      "[codecarbon INFO @ 09:36:24] 0.080109 kWh of electricity used since the beginning.\n",
      "Evaluating: 100%|██████████| 63/63 [00:06<00:00,  9.20it/s, accuracy=0.94, loss=0.282] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :   9%|▉         | 45/500 [00:09<01:34,  4.82it/s, accuracy=0.954, loss=0.29][codecarbon INFO @ 09:36:39] Energy consumed for RAM : 0.044644 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:36:39] Energy consumed for all CPUs : 0.013235 kWh. Total CPU Power : 83.90084959249604 W\n",
      "[codecarbon INFO @ 09:36:39] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:36:39] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:36:39] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:36:39] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:36:39] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:36:39] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:36:39] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:36:39] Energy consumed for all GPUs : 0.024408 kWh. Total GPU Power : 157.65354574604788 W\n",
      "[codecarbon INFO @ 09:36:39] 0.082287 kWh of electricity used since the beginning.\n",
      "Training  :  23%|██▎       | 117/500 [00:24<01:19,  4.79it/s, accuracy=0.953, loss=0.296][codecarbon INFO @ 09:36:54] Energy consumed for RAM : 0.045818 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:36:54] Energy consumed for all CPUs : 0.013582 kWh. Total CPU Power : 83.51324484402016 W\n",
      "[codecarbon INFO @ 09:36:54] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:36:54] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:36:54] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:36:54] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:36:54] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:36:54] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:36:54] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:36:54] Energy consumed for all GPUs : 0.025059 kWh. Total GPU Power : 156.89627955410012 W\n",
      "[codecarbon INFO @ 09:36:54] 0.084460 kWh of electricity used since the beginning.\n",
      "Training  :  38%|███▊      | 188/500 [00:39<01:05,  4.77it/s, accuracy=0.952, loss=0.298][codecarbon INFO @ 09:37:09] Energy consumed for RAM : 0.046993 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:37:09] Energy consumed for all CPUs : 0.013929 kWh. Total CPU Power : 83.489227976825 W\n",
      "[codecarbon INFO @ 09:37:09] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:37:09] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:37:09] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:37:09] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:37:09] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:37:09] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:37:09] GPU number 7 will not be monitored, at your request.\n",
      "Training  :  38%|███▊      | 189/500 [00:39<01:05,  4.76it/s, accuracy=0.952, loss=0.298][codecarbon INFO @ 09:37:09] Energy consumed for all GPUs : 0.025708 kWh. Total GPU Power : 156.14533731701889 W\n",
      "[codecarbon INFO @ 09:37:09] 0.086629 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 09:37:09] 0.047848 g.CO2eq/s mean an estimation of 1,508.9238385693393 kg.CO2eq/year\n",
      "Training  :  52%|█████▏    | 260/500 [00:54<00:50,  4.76it/s, accuracy=0.953, loss=0.297][codecarbon INFO @ 09:37:24] Energy consumed for RAM : 0.048167 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:37:24] Energy consumed for all CPUs : 0.014275 kWh. Total CPU Power : 83.33736470566217 W\n",
      "[codecarbon INFO @ 09:37:24] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:37:24] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:37:24] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:37:24] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:37:24] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:37:24] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:37:24] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:37:24] Energy consumed for all GPUs : 0.026357 kWh. Total GPU Power : 156.34455188191765 W\n",
      "[codecarbon INFO @ 09:37:24] 0.088799 kWh of electricity used since the beginning.\n",
      "Training  :  66%|██████▌   | 331/500 [01:09<00:35,  4.74it/s, accuracy=0.953, loss=0.296][codecarbon INFO @ 09:37:39] Energy consumed for RAM : 0.049342 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:37:39] Energy consumed for all CPUs : 0.014621 kWh. Total CPU Power : 83.26830996482175 W\n",
      "[codecarbon INFO @ 09:37:39] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:37:39] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:37:39] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:37:39] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:37:39] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:37:39] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:37:39] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:37:39] Energy consumed for all GPUs : 0.027002 kWh. Total GPU Power : 155.2390780361215 W\n",
      "[codecarbon INFO @ 09:37:39] 0.090965 kWh of electricity used since the beginning.\n",
      "Training  :  80%|████████  | 402/500 [01:24<00:20,  4.73it/s, accuracy=0.953, loss=0.295][codecarbon INFO @ 09:37:54] Energy consumed for RAM : 0.050517 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:37:54] Energy consumed for all CPUs : 0.014966 kWh. Total CPU Power : 83.06428783947788 W\n",
      "[codecarbon INFO @ 09:37:54] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:37:54] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:37:54] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:37:54] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:37:54] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:37:54] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:37:54] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:37:54] Energy consumed for all GPUs : 0.027653 kWh. Total GPU Power : 156.63455112034487 W\n",
      "[codecarbon INFO @ 09:37:54] 0.093136 kWh of electricity used since the beginning.\n",
      "Training  :  95%|█████████▍| 473/500 [01:39<00:05,  4.71it/s, accuracy=0.953, loss=0.294][codecarbon INFO @ 09:38:09] Energy consumed for RAM : 0.051692 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:38:09] Energy consumed for all CPUs : 0.015310 kWh. Total CPU Power : 82.8634593208883 W\n",
      "[codecarbon INFO @ 09:38:09] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:38:09] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:38:09] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:38:09] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:38:09] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:38:09] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:38:09] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:38:09] Energy consumed for all GPUs : 0.028295 kWh. Total GPU Power : 154.52341463501597 W\n",
      "[codecarbon INFO @ 09:38:09] 0.095297 kWh of electricity used since the beginning.\n",
      "Training  : 100%|██████████| 500/500 [01:45<00:00,  4.76it/s, accuracy=0.953, loss=0.294]\n",
      "Evaluating: 100%|██████████| 63/63 [00:06<00:00,  9.20it/s, accuracy=0.941, loss=0.27] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :   2%|▏         | 11/500 [00:02<01:41,  4.82it/s, accuracy=0.969, loss=0.263][codecarbon INFO @ 09:38:24] Energy consumed for RAM : 0.052866 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:38:24] Energy consumed for all CPUs : 0.015657 kWh. Total CPU Power : 83.5017077668835 W\n",
      "[codecarbon INFO @ 09:38:24] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:38:24] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:38:24] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:38:24] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:38:24] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:38:24] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:38:24] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:38:24] Energy consumed for all GPUs : 0.028943 kWh. Total GPU Power : 156.05941753495378 W\n",
      "[codecarbon INFO @ 09:38:24] 0.097466 kWh of electricity used since the beginning.\n",
      "Training  :  17%|█▋        | 83/500 [00:17<01:26,  4.80it/s, accuracy=0.959, loss=0.279][codecarbon INFO @ 09:38:39] Energy consumed for RAM : 0.054041 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:38:39] Energy consumed for all CPUs : 0.016002 kWh. Total CPU Power : 83.01302519612318 W\n",
      "[codecarbon INFO @ 09:38:39] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:38:39] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:38:39] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:38:39] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:38:39] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:38:39] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:38:39] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:38:39] Energy consumed for all GPUs : 0.029598 kWh. Total GPU Power : 157.67950110894748 W\n",
      "[codecarbon INFO @ 09:38:39] 0.099640 kWh of electricity used since the beginning.\n",
      "Training  :  31%|███       | 155/500 [00:32<01:11,  4.80it/s, accuracy=0.962, loss=0.273][codecarbon INFO @ 09:38:54] Energy consumed for RAM : 0.055216 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:38:54] Energy consumed for all CPUs : 0.016347 kWh. Total CPU Power : 83.12424359198195 W\n",
      "[codecarbon INFO @ 09:38:54] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:38:54] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:38:54] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:38:54] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:38:54] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:38:54] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:38:54] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:38:54] Energy consumed for all GPUs : 0.030248 kWh. Total GPU Power : 156.69411235776033 W\n",
      "[codecarbon INFO @ 09:38:54] 0.101811 kWh of electricity used since the beginning.\n",
      "Training  :  45%|████▌     | 227/500 [00:47<00:57,  4.77it/s, accuracy=0.96, loss=0.278][codecarbon INFO @ 09:39:09] Energy consumed for RAM : 0.056391 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:39:09] Energy consumed for all CPUs : 0.016692 kWh. Total CPU Power : 83.0686265989594 W\n",
      "[codecarbon INFO @ 09:39:09] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:39:09] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:39:09] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:39:09] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:39:09] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:39:09] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:39:09] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:39:09] Energy consumed for all GPUs : 0.030898 kWh. Total GPU Power : 156.46282934269303 W\n",
      "[codecarbon INFO @ 09:39:09] 0.103981 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 09:39:09] 0.047818 g.CO2eq/s mean an estimation of 1,507.9890479153173 kg.CO2eq/year\n",
      "Training  :  60%|█████▉    | 298/500 [01:02<00:42,  4.74it/s, accuracy=0.958, loss=0.278][codecarbon INFO @ 09:39:24] Energy consumed for RAM : 0.057565 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:39:24] Energy consumed for all CPUs : 0.017037 kWh. Total CPU Power : 83.24852852129402 W\n",
      "[codecarbon INFO @ 09:39:24] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:39:24] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:39:24] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:39:24] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:39:24] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:39:24] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:39:24] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:39:24] Energy consumed for all GPUs : 0.031548 kWh. Total GPU Power : 156.51618138159643 W\n",
      "[codecarbon INFO @ 09:39:24] 0.106151 kWh of electricity used since the beginning.\n",
      "Training  :  74%|███████▍  | 369/500 [01:17<00:27,  4.71it/s, accuracy=0.957, loss=0.281][codecarbon INFO @ 09:39:39] Energy consumed for RAM : 0.058740 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:39:39] Energy consumed for all CPUs : 0.017382 kWh. Total CPU Power : 82.99104779976166 W\n",
      "[codecarbon INFO @ 09:39:39] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:39:39] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:39:39] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:39:39] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:39:39] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:39:39] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:39:39] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:39:39] Energy consumed for all GPUs : 0.032192 kWh. Total GPU Power : 154.9674167560339 W\n",
      "[codecarbon INFO @ 09:39:39] 0.108313 kWh of electricity used since the beginning.\n",
      "Training  :  88%|████████▊ | 439/500 [01:32<00:12,  4.70it/s, accuracy=0.958, loss=0.279][codecarbon INFO @ 09:39:54] Energy consumed for RAM : 0.059914 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:39:54] Energy consumed for all CPUs : 0.017728 kWh. Total CPU Power : 83.39331228117973 W\n",
      "[codecarbon INFO @ 09:39:54] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:39:54] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:39:54] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:39:54] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:39:54] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:39:54] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:39:54] GPU number 7 will not be monitored, at your request.\n",
      "Training  :  88%|████████▊ | 440/500 [01:32<00:12,  4.70it/s, accuracy=0.958, loss=0.279][codecarbon INFO @ 09:39:54] Energy consumed for all GPUs : 0.032841 kWh. Total GPU Power : 156.3049942698722 W\n",
      "[codecarbon INFO @ 09:39:54] 0.110483 kWh of electricity used since the beginning.\n",
      "Training  : 100%|██████████| 500/500 [01:45<00:00,  4.75it/s, accuracy=0.957, loss=0.279]\n",
      "Evaluating:  32%|███▏      | 20/63 [00:02<00:04,  9.14it/s, accuracy=0.931, loss=0.283][codecarbon INFO @ 09:40:09] Energy consumed for RAM : 0.061089 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:40:09] Energy consumed for all CPUs : 0.018076 kWh. Total CPU Power : 83.63668266569854 W\n",
      "[codecarbon INFO @ 09:40:09] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:40:09] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:40:09] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:40:09] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:40:09] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:40:09] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:40:09] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:40:09] Energy consumed for all GPUs : 0.033488 kWh. Total GPU Power : 155.59073919270784 W\n",
      "[codecarbon INFO @ 09:40:09] 0.112653 kWh of electricity used since the beginning.\n",
      "Evaluating: 100%|██████████| 63/63 [00:06<00:00,  9.19it/s, accuracy=0.944, loss=0.264]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :   9%|▉         | 47/500 [00:09<01:34,  4.81it/s, accuracy=0.965, loss=0.267][codecarbon INFO @ 09:40:24] Energy consumed for RAM : 0.062263 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:40:24] Energy consumed for all CPUs : 0.018424 kWh. Total CPU Power : 83.97928918465172 W\n",
      "[codecarbon INFO @ 09:40:24] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:40:24] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:40:24] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:40:24] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:40:24] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:40:24] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:40:24] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:40:24] Energy consumed for all GPUs : 0.034127 kWh. Total GPU Power : 154.087819740371 W\n",
      "[codecarbon INFO @ 09:40:24] 0.114815 kWh of electricity used since the beginning.\n",
      "Training  :  24%|██▍       | 119/500 [00:24<01:19,  4.79it/s, accuracy=0.968, loss=0.266][codecarbon INFO @ 09:40:39] Energy consumed for RAM : 0.063438 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:40:39] Energy consumed for all CPUs : 0.018771 kWh. Total CPU Power : 83.41694996990145 W\n",
      "[codecarbon INFO @ 09:40:39] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:40:39] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:40:39] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:40:39] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:40:39] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:40:39] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:40:39] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:40:39] Energy consumed for all GPUs : 0.034781 kWh. Total GPU Power : 157.46949429949063 W\n",
      "[codecarbon INFO @ 09:40:39] 0.116991 kWh of electricity used since the beginning.\n",
      "Training  :  38%|███▊      | 190/500 [00:39<01:05,  4.77it/s, accuracy=0.963, loss=0.27][codecarbon INFO @ 09:40:54] Energy consumed for RAM : 0.064613 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:40:54] Energy consumed for all CPUs : 0.019118 kWh. Total CPU Power : 83.48593919496585 W\n",
      "[codecarbon INFO @ 09:40:54] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:40:54] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:40:54] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:40:54] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:40:54] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:40:54] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:40:54] GPU number 7 will not be monitored, at your request.\n",
      "Training  :  38%|███▊      | 191/500 [00:39<01:04,  4.76it/s, accuracy=0.963, loss=0.27][codecarbon INFO @ 09:40:54] Energy consumed for all GPUs : 0.035430 kWh. Total GPU Power : 156.05267744567297 W\n",
      "[codecarbon INFO @ 09:40:54] 0.119161 kWh of electricity used since the beginning.\n",
      "Training  :  52%|█████▏    | 262/500 [00:54<00:50,  4.75it/s, accuracy=0.962, loss=0.272][codecarbon INFO @ 09:41:09] Energy consumed for RAM : 0.065788 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:41:09] Energy consumed for all CPUs : 0.019464 kWh. Total CPU Power : 83.43830673058831 W\n",
      "[codecarbon INFO @ 09:41:09] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:41:09] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:41:09] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:41:09] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:41:09] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:41:09] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:41:09] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:41:09] Energy consumed for all GPUs : 0.036079 kWh. Total GPU Power : 156.39797626565357 W\n",
      "[codecarbon INFO @ 09:41:09] 0.121331 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 09:41:09] 0.047816 g.CO2eq/s mean an estimation of 1,507.9323068096446 kg.CO2eq/year\n",
      "Training  :  67%|██████▋   | 333/500 [01:09<00:35,  4.72it/s, accuracy=0.962, loss=0.273][codecarbon INFO @ 09:41:24] Energy consumed for RAM : 0.066962 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:41:24] Energy consumed for all CPUs : 0.019811 kWh. Total CPU Power : 83.58703877923438 W\n",
      "[codecarbon INFO @ 09:41:24] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:41:24] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:41:24] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:41:24] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:41:24] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:41:24] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:41:24] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:41:24] Energy consumed for all GPUs : 0.036731 kWh. Total GPU Power : 156.99059565384673 W\n",
      "[codecarbon INFO @ 09:41:24] 0.123505 kWh of electricity used since the beginning.\n",
      "Training  :  81%|████████  | 404/500 [01:24<00:20,  4.71it/s, accuracy=0.961, loss=0.274][codecarbon INFO @ 09:41:39] Energy consumed for RAM : 0.068137 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:41:39] Energy consumed for all CPUs : 0.020158 kWh. Total CPU Power : 83.50188805830172 W\n",
      "[codecarbon INFO @ 09:41:39] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:41:39] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:41:39] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:41:39] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:41:39] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:41:39] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:41:39] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:41:39] Energy consumed for all GPUs : 0.037374 kWh. Total GPU Power : 154.79219438593788 W\n",
      "[codecarbon INFO @ 09:41:39] 0.125670 kWh of electricity used since the beginning.\n",
      "Training  :  95%|█████████▍| 474/500 [01:39<00:05,  4.69it/s, accuracy=0.962, loss=0.272][codecarbon INFO @ 09:41:54] Energy consumed for RAM : 0.069311 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:41:54] Energy consumed for all CPUs : 0.020505 kWh. Total CPU Power : 83.5588702844256 W\n",
      "[codecarbon INFO @ 09:41:54] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:41:54] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:41:54] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:41:54] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:41:54] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:41:54] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:41:54] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:41:54] Energy consumed for all GPUs : 0.038021 kWh. Total GPU Power : 155.8498757735779 W\n",
      "[codecarbon INFO @ 09:41:54] 0.127837 kWh of electricity used since the beginning.\n",
      "Training  : 100%|██████████| 500/500 [01:45<00:00,  4.75it/s, accuracy=0.962, loss=0.272]\n",
      "Evaluating: 100%|██████████| 63/63 [00:06<00:00,  9.19it/s, accuracy=0.946, loss=0.262]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :   2%|▏         | 10/500 [00:02<01:41,  4.81it/s, accuracy=0.969, loss=0.266][codecarbon INFO @ 09:42:09] Energy consumed for RAM : 0.070486 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:42:09] Energy consumed for all CPUs : 0.020854 kWh. Total CPU Power : 84.03199494985459 W\n",
      "[codecarbon INFO @ 09:42:09] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:42:09] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:42:09] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:42:09] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:42:09] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:42:09] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:42:09] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:42:09] Energy consumed for all GPUs : 0.038655 kWh. Total GPU Power : 152.62313096088272 W\n",
      "[codecarbon INFO @ 09:42:09] 0.129995 kWh of electricity used since the beginning.\n",
      "Training  :  16%|█▋        | 82/500 [00:17<01:27,  4.80it/s, accuracy=0.963, loss=0.274][codecarbon INFO @ 09:42:24] Energy consumed for RAM : 0.071660 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:42:24] Energy consumed for all CPUs : 0.021201 kWh. Total CPU Power : 83.4739046701904 W\n",
      "[codecarbon INFO @ 09:42:24] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:42:24] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:42:24] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:42:24] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:42:24] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:42:24] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:42:24] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:42:24] Energy consumed for all GPUs : 0.039306 kWh. Total GPU Power : 156.75976803201314 W\n",
      "[codecarbon INFO @ 09:42:24] 0.132167 kWh of electricity used since the beginning.\n",
      "Training  :  31%|███       | 154/500 [00:32<01:12,  4.79it/s, accuracy=0.963, loss=0.272][codecarbon INFO @ 09:42:39] Energy consumed for RAM : 0.072835 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:42:39] Energy consumed for all CPUs : 0.021547 kWh. Total CPU Power : 83.49926029201652 W\n",
      "[codecarbon INFO @ 09:42:39] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:42:39] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:42:39] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:42:39] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:42:39] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:42:39] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:42:39] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:42:39] Energy consumed for all GPUs : 0.039960 kWh. Total GPU Power : 157.3516977735472 W\n",
      "[codecarbon INFO @ 09:42:39] 0.134342 kWh of electricity used since the beginning.\n",
      "Training  :  45%|████▌     | 225/500 [00:47<00:57,  4.75it/s, accuracy=0.962, loss=0.27][codecarbon INFO @ 09:42:54] Energy consumed for RAM : 0.074010 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:42:54] Energy consumed for all CPUs : 0.021894 kWh. Total CPU Power : 83.44264780835684 W\n",
      "[codecarbon INFO @ 09:42:54] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:42:54] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:42:54] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:42:54] GPU number 3 will not be monitored, at your request.\n",
      "Training  :  45%|████▌     | 225/500 [00:47<00:57,  4.75it/s, accuracy=0.962, loss=0.27][codecarbon INFO @ 09:42:54] GPU number 4 will not be monitored, at your request.\n",
      "Training  :  45%|████▌     | 226/500 [00:47<00:57,  4.74it/s, accuracy=0.962, loss=0.27][codecarbon INFO @ 09:42:54] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:42:54] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:42:54] Energy consumed for all GPUs : 0.040606 kWh. Total GPU Power : 155.59356817860717 W\n",
      "[codecarbon INFO @ 09:42:54] 0.136510 kWh of electricity used since the beginning.\n",
      "Training  :  59%|█████▉    | 297/500 [01:02<00:42,  4.75it/s, accuracy=0.962, loss=0.269][codecarbon INFO @ 09:43:09] Energy consumed for RAM : 0.075184 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:43:09] Energy consumed for all CPUs : 0.022241 kWh. Total CPU Power : 83.63265658407032 W\n",
      "[codecarbon INFO @ 09:43:09] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:43:09] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:43:09] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:43:09] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:43:09] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:43:09] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:43:09] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:43:09] Energy consumed for all GPUs : 0.041256 kWh. Total GPU Power : 156.50507830329812 W\n",
      "[codecarbon INFO @ 09:43:09] 0.138681 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 09:43:09] 0.047817 g.CO2eq/s mean an estimation of 1,507.9673778492304 kg.CO2eq/year\n",
      "Training  :  74%|███████▎  | 368/500 [01:17<00:27,  4.73it/s, accuracy=0.962, loss=0.269][codecarbon INFO @ 09:43:24] Energy consumed for RAM : 0.076359 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:43:24] Energy consumed for all CPUs : 0.022588 kWh. Total CPU Power : 83.4740061817613 W\n",
      "[codecarbon INFO @ 09:43:24] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:43:24] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:43:24] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:43:24] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:43:24] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:43:24] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:43:24] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:43:24] Energy consumed for all GPUs : 0.041902 kWh. Total GPU Power : 155.4757713060656 W\n",
      "[codecarbon INFO @ 09:43:24] 0.140849 kWh of electricity used since the beginning.\n",
      "Training  :  88%|████████▊ | 439/500 [01:32<00:12,  4.71it/s, accuracy=0.963, loss=0.268][codecarbon INFO @ 09:43:39] Energy consumed for RAM : 0.077534 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:43:39] Energy consumed for all CPUs : 0.022934 kWh. Total CPU Power : 83.43226509782289 W\n",
      "[codecarbon INFO @ 09:43:39] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:43:39] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:43:39] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:43:39] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:43:39] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:43:39] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:43:39] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:43:39] Energy consumed for all GPUs : 0.042545 kWh. Total GPU Power : 154.99763046618213 W\n",
      "[codecarbon INFO @ 09:43:39] 0.143014 kWh of electricity used since the beginning.\n",
      "Training  : 100%|██████████| 500/500 [01:45<00:00,  4.75it/s, accuracy=0.963, loss=0.269]\n",
      "Evaluating:  29%|██▊       | 18/63 [00:01<00:04,  9.13it/s, accuracy=0.929, loss=0.29][codecarbon INFO @ 09:43:54] Energy consumed for RAM : 0.078709 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:43:54] Energy consumed for all CPUs : 0.023282 kWh. Total CPU Power : 83.60149883117873 W\n",
      "[codecarbon INFO @ 09:43:54] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:43:54] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:43:54] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:43:54] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:43:54] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:43:54] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:43:54] GPU number 7 will not be monitored, at your request.\n",
      "Evaluating:  30%|███       | 19/63 [00:02<00:04,  9.15it/s, accuracy=0.929, loss=0.288][codecarbon INFO @ 09:43:54] Energy consumed for all GPUs : 0.043192 kWh. Total GPU Power : 155.78893593556126 W\n",
      "[codecarbon INFO @ 09:43:54] 0.145183 kWh of electricity used since the beginning.\n",
      "Evaluating: 100%|██████████| 63/63 [00:06<00:00,  9.20it/s, accuracy=0.944, loss=0.263]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La loss sul validation set non è migliorata per 1 epoche.\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :  10%|▉         | 49/500 [00:10<01:33,  4.81it/s, accuracy=0.956, loss=0.271][codecarbon INFO @ 09:44:09] Energy consumed for RAM : 0.079884 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:44:09] Energy consumed for all CPUs : 0.023629 kWh. Total CPU Power : 83.61752241205264 W\n",
      "[codecarbon INFO @ 09:44:09] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:44:09] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:44:09] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:44:09] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:44:09] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:44:09] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:44:09] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:44:09] Energy consumed for all GPUs : 0.043841 kWh. Total GPU Power : 156.03840347836447 W\n",
      "[codecarbon INFO @ 09:44:09] 0.147353 kWh of electricity used since the beginning.\n",
      "Training  :  24%|██▍       | 121/500 [00:25<01:18,  4.80it/s, accuracy=0.962, loss=0.266][codecarbon INFO @ 09:44:24] Energy consumed for RAM : 0.081058 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:44:24] Energy consumed for all CPUs : 0.023976 kWh. Total CPU Power : 83.39244360608077 W\n",
      "[codecarbon INFO @ 09:44:24] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:44:24] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:44:24] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:44:24] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:44:24] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:44:24] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:44:24] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:44:24] Energy consumed for all GPUs : 0.044494 kWh. Total GPU Power : 157.19782660088632 W\n",
      "[codecarbon INFO @ 09:44:24] 0.149528 kWh of electricity used since the beginning.\n",
      "Training  :  38%|███▊      | 192/500 [00:40<01:04,  4.77it/s, accuracy=0.964, loss=0.264][codecarbon INFO @ 09:44:39] Energy consumed for RAM : 0.082233 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:44:39] Energy consumed for all CPUs : 0.024321 kWh. Total CPU Power : 83.27272268984412 W\n",
      "[codecarbon INFO @ 09:44:39] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:44:39] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:44:39] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:44:39] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:44:39] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:44:39] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:44:39] GPU number 7 will not be monitored, at your request.\n",
      "Training  :  39%|███▊      | 193/500 [00:40<01:04,  4.76it/s, accuracy=0.963, loss=0.265][codecarbon INFO @ 09:44:39] Energy consumed for all GPUs : 0.045144 kWh. Total GPU Power : 156.51519976934338 W\n",
      "[codecarbon INFO @ 09:44:39] 0.151698 kWh of electricity used since the beginning.\n",
      "Training  :  53%|█████▎    | 264/500 [00:55<00:49,  4.75it/s, accuracy=0.964, loss=0.265][codecarbon INFO @ 09:44:54] Energy consumed for RAM : 0.083408 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:44:54] Energy consumed for all CPUs : 0.024667 kWh. Total CPU Power : 83.3205852272604 W\n",
      "[codecarbon INFO @ 09:44:54] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:44:54] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:44:54] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:44:54] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:44:54] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:44:54] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:44:54] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:44:54] Energy consumed for all GPUs : 0.045791 kWh. Total GPU Power : 155.82398208264115 W\n",
      "[codecarbon INFO @ 09:44:54] 0.153866 kWh of electricity used since the beginning.\n",
      "Training  :  67%|██████▋   | 335/500 [01:10<00:34,  4.73it/s, accuracy=0.965, loss=0.263][codecarbon INFO @ 09:45:09] Energy consumed for RAM : 0.084582 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:45:09] Energy consumed for all CPUs : 0.025013 kWh. Total CPU Power : 83.27942901180282 W\n",
      "[codecarbon INFO @ 09:45:09] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:45:09] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:45:09] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:45:09] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:45:09] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:45:09] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:45:09] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:45:09] Energy consumed for all GPUs : 0.046437 kWh. Total GPU Power : 155.62153395949423 W\n",
      "[codecarbon INFO @ 09:45:09] 0.156033 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 09:45:09] 0.047818 g.CO2eq/s mean an estimation of 1,507.9968601455053 kg.CO2eq/year\n",
      "Training  :  81%|████████  | 406/500 [01:25<00:19,  4.73it/s, accuracy=0.964, loss=0.263][codecarbon INFO @ 09:45:24] Energy consumed for RAM : 0.085757 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:45:24] Energy consumed for all CPUs : 0.025360 kWh. Total CPU Power : 83.41804440339658 W\n",
      "[codecarbon INFO @ 09:45:24] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:45:24] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:45:24] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:45:24] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:45:24] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:45:24] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:45:24] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:45:24] Energy consumed for all GPUs : 0.047080 kWh. Total GPU Power : 154.86941356697875 W\n",
      "[codecarbon INFO @ 09:45:24] 0.158197 kWh of electricity used since the beginning.\n",
      "Training  :  95%|█████████▌| 477/500 [01:40<00:04,  4.70it/s, accuracy=0.964, loss=0.264][codecarbon INFO @ 09:45:39] Energy consumed for RAM : 0.086932 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:45:39] Energy consumed for all CPUs : 0.025706 kWh. Total CPU Power : 83.43778403798458 W\n",
      "[codecarbon INFO @ 09:45:39] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:45:39] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:45:39] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:45:39] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:45:39] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:45:39] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:45:39] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:45:39] Energy consumed for all GPUs : 0.047722 kWh. Total GPU Power : 154.4427270710593 W\n",
      "[codecarbon INFO @ 09:45:39] 0.160360 kWh of electricity used since the beginning.\n",
      "Training  : 100%|██████████| 500/500 [01:45<00:00,  4.76it/s, accuracy=0.964, loss=0.264]\n",
      "Evaluating: 100%|██████████| 63/63 [00:06<00:00,  9.20it/s, accuracy=0.943, loss=0.263]\n",
      "[codecarbon INFO @ 09:45:51] Energy consumed for RAM : 0.087848 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 09:45:51] Energy consumed for all CPUs : 0.025978 kWh. Total CPU Power : 83.81579824093379 W\n",
      "[codecarbon INFO @ 09:45:51] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:45:51] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:45:51] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:45:51] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:45:51] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:45:51] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:45:51] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 09:45:51] Energy consumed for all GPUs : 0.048231 kWh. Total GPU Power : 157.12694976303257 W\n",
      "[codecarbon INFO @ 09:45:51] 0.162057 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La loss sul validation set non è migliorata per 2 epoche.\n",
      "\n",
      "Emissioni CO₂ totali: 0.0536 kg\n",
      "\n",
      "BERT with LoRA Training Time: 1121.75 seconds, 18.70 minutes.\n"
     ]
    }
   ],
   "source": [
    "history, total_time, emissions = train_and_evaluate_model(\n",
    "    lora_model,\"emotion\", emotion_train_loader, emotion_val_loader, optimizer, scheduler, device, epochs=EPOCHS \n",
    ") \n",
    "print(f\"\\nBERT with LoRA Training Time: {total_time:.2f} seconds, {total_time/60:.2f} minutes.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 63/63 [00:06<00:00,  9.27it/s, accuracy=0.929, loss=0.284]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA Fine-Tuning - Test loss: 0.2841, Accuracy: 0.9295, F1 score: 0.8848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lora_model.load_state_dict(torch.load(\"emotion_best_model_state.bin\"))\n",
    " \n",
    "test_loss, test_acc, test_f1 = eval_model(lora_model, emotion_test_loader, device)\n",
    "print(f\"LoRA Fine-Tuning - Test loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}, F1 score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_task_results(\n",
    "    task_name=\"emotion\", \n",
    "    training_time=total_time,\n",
    "    emissions=emissions,\n",
    "    test_loss=test_loss,\n",
    "    test_acc=test_acc,\n",
    "    test_f1=test_f1,\n",
    ")\n",
    "\n",
    "performance = pd.DataFrame(model_performance)\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T10:39:21.540395Z",
     "iopub.status.busy": "2025-03-14T10:39:21.540107Z",
     "iopub.status.idle": "2025-03-14T10:39:26.432634Z",
     "shell.execute_reply": "2025-03-14T10:39:26.431943Z",
     "shell.execute_reply.started": "2025-03-14T10:39:21.540372Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cdca01b1c23435db4b64114801e47e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/35.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4fc62eaf7ae45958b569496ce9b1d53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/584k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb1c33141c9e46aaa016022993438f0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/69.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "274ac71075f747e0a434e5cb23a2e7c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/621k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade79e1133a04d86943a6086f09291bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/2490 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e6b28e0c574e43ad05934d3a8e42f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a7365f393674675a6fd710b4a90a2bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 2490\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 277\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 3000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Ottenimento del dataset\n",
    "rte_dataset = load_dataset(\"glue\", \"rte\")\n",
    "print(rte_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T10:39:26.433913Z",
     "iopub.status.busy": "2025-03-14T10:39:26.433615Z",
     "iopub.status.idle": "2025-03-14T10:39:26.619715Z",
     "shell.execute_reply": "2025-03-14T10:39:26.619027Z",
     "shell.execute_reply.started": "2025-03-14T10:39:26.433890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 2213\n",
      "Validation: 277\n",
      "Test: 277\n",
      "\n",
      "Distribuzione delle etichette:\n",
      "Train: Counter({0: 1115, 1: 1098})\n",
      "Validation: Counter({0: 140, 1: 137})\n",
      "Test: Counter({0: 140, 1: 137})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "rte_train_data = pd.DataFrame(rte_dataset[\"train\"])\n",
    "rte_val_data = pd.DataFrame(rte_dataset[\"validation\"])\n",
    "\n",
    "rte_data = Dataset.from_pandas(pd.concat([rte_train_data, rte_val_data], ignore_index=True))\n",
    "rte_data = rte_data.shuffle(seed=42)\n",
    "\n",
    "rte_temp_sentences1, rte_test_sentences1, rte_temp_sentences2, rte_test_sentences2,  rte_temp_labels, rte_test_labels = train_test_split(\n",
    "                                                rte_data['sentence1'],\n",
    "                                                rte_data['sentence2'],\n",
    "                                                rte_data['label'], \n",
    "                                                test_size=0.1, \n",
    "                                                random_state=42,\n",
    "                                                stratify=rte_data['label'])\n",
    "\n",
    "rte_train_sentences1, rte_val_sentences1, rte_train_sentences2, rte_val_sentences2, rte_train_labels, rte_val_labels = train_test_split(\n",
    "                                                rte_temp_sentences1,\n",
    "                                                rte_temp_sentences2,\n",
    "                                                rte_temp_labels,\n",
    "                                                test_size=0.1111,\n",
    "                                                random_state=42,\n",
    "                                                stratify=rte_temp_labels)\n",
    "\n",
    "print(f\"Train: {len(rte_train_sentences1)}\")\n",
    "print(f\"Validation: {len(rte_val_sentences1)}\")\n",
    "print(f\"Test: {len(rte_test_sentences1)}\")\n",
    "\n",
    "# Verifica distribuzione delle etichette\n",
    "print(\"\\nDistribuzione delle etichette:\")\n",
    "print(f\"Train: {Counter(rte_train_labels)}\")\n",
    "print(f\"Validation: {Counter(rte_val_labels)}\")\n",
    "print(f\"Test: {Counter(rte_test_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class NLIDataset(Dataset):\n",
    "\n",
    "    def __init__(self, sentences1, sentences2 , labels, tokenizer, max_len):\n",
    "        self.sentences1 = sentences1\n",
    "        self.sentences2 = sentences2\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentences1)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        sentence1 = self.sentences1[index]\n",
    "        sentence2 = self.sentences2[index]\n",
    "        label = self.labels[index]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            sentence1,\n",
    "            sentence2,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True,\n",
    "            padding=\"max_length\",\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt')\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'token_type_ids': encoding[\"token_type_ids\"].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 256\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Inizializzo il Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Ottiengo i dataset\n",
    "rte_training_data = NLIDataset(\n",
    "                           sentences1 = rte_train_sentences1,\n",
    "                           sentences2 = rte_train_sentences2,\n",
    "                           labels = rte_train_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)\n",
    "\n",
    "rte_validation_data = NLIDataset(\n",
    "                           sentences1 = rte_val_sentences1,\n",
    "                           sentences2 = rte_val_sentences2,\n",
    "                           labels = rte_val_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)\n",
    "\n",
    "rte_test_data = NLIDataset(\n",
    "                           sentences1 = rte_test_sentences1,\n",
    "                           sentences2 = rte_test_sentences2,\n",
    "                           labels = rte_test_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Pretrained model\n",
    "lora_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "\n",
    "# LoRA config\n",
    "lora_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=128,\n",
    "    lora_dropout=0.2,\n",
    "    target_modules=[\"query\", \"key\", \"value\"],  \n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "lora_model = get_peft_model(lora_model, lora_config)\n",
    "lora_model.print_trainable_parameters()\n",
    "lora_model.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in lora_model.named_parameters():\n",
    "    if \"classifier\" in name:\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametri principali\n",
    "learning_rate = 2e-4\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Creo i DataLoader\n",
    "rte_train_loader = DataLoader(rte_training_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "rte_val_loader = DataLoader(rte_validation_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "rte_test_loader = DataLoader(rte_test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "total_steps = len(rte_train_loader) * EPOCHS\n",
    "\n",
    "# Ottimizzatore\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, lora_model.parameters()), lr = learning_rate)\n",
    "\n",
    "\n",
    "# Scheduler\n",
    "scheduler = transformers.get_cosine_schedule_with_warmup(optimizer = optimizer,\n",
    "                                                       num_warmup_steps = 0,\n",
    "                                                       num_training_steps = total_steps) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history, total_time = train_and_evaluate_model(\n",
    "    lora_model,\"rte\", rte_train_loader, rte_val_loader, optimizer, scheduler, device, apochs= EPOCHS\n",
    ") \n",
    "print(f\"\\nBERT with LoRA Training Time: {total_time:.2f} seconds, {total_time/60:.2f} minutes.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model.load_state_dict(torch.load(\"rte_best_model_state.bin\"))\n",
    "test_loss, test_acc, test_f1 = eval_model(lora_model, rte_test_loader, device)\n",
    "print(f\"LoRA Fine-Tuning - Test loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}, F1 score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_task_results(\n",
    "    task_name=\"rte\", \n",
    "    training_time=total_time,\n",
    "    test_loss=test_loss,\n",
    "    test_acc=test_acc,\n",
    "    test_f1=test_f1,\n",
    ")\n",
    "\n",
    "performance = pd.DataFrame(model_performance)\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QQP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T16:14:09.156371Z",
     "iopub.status.busy": "2025-03-14T16:14:09.155975Z",
     "iopub.status.idle": "2025-03-14T16:14:14.680506Z",
     "shell.execute_reply": "2025-03-14T16:14:14.679765Z",
     "shell.execute_reply.started": "2025-03-14T16:14:09.156347Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed49012160e47c38aeb1e78e7a23163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/35.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa734f196e524c239c0c3c8f051e711e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/33.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af71a95a96804f85ac483bf18a2752eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/3.73M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbccb64e50de47b48e7f8c7612bb2b85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/36.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cc0e5ad45644455900b72e7ca95196a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/363846 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61f9cf4088dd4b5db2f49ee42b355b05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/40430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93ec67964c744f0b5e9f8b18f4da010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/390965 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question1', 'question2', 'label', 'idx'],\n",
      "        num_rows: 363846\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['question1', 'question2', 'label', 'idx'],\n",
      "        num_rows: 40430\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['question1', 'question2', 'label', 'idx'],\n",
      "        num_rows: 390965\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Ottenimento del dataset\n",
    "qqp_dataset = load_dataset(\"glue\", \"qqp\")\n",
    "print(qqp_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T16:14:14.681859Z",
     "iopub.status.busy": "2025-03-14T16:14:14.681573Z",
     "iopub.status.idle": "2025-03-14T16:14:41.432290Z",
     "shell.execute_reply": "2025-03-14T16:14:41.431566Z",
     "shell.execute_reply.started": "2025-03-14T16:14:14.681836Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensioni dei set:\n",
      "Train: 20000\n",
      "Validation: 5000\n",
      "Test: 5000\n",
      "\n",
      "Distribuzione delle etichette:\n",
      "Train: Counter({1: 10000, 0: 10000})\n",
      "Validation: Counter({0: 2500, 1: 2500})\n",
      "Test: Counter({0: 2500, 1: 2500})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "from collections import Counter\n",
    "from datasets import Dataset\n",
    "\n",
    "def balance_dataset(dataset, num_example):\n",
    "    class_0 = [example for example in dataset if example[\"label\"] == 0][:num_example]\n",
    "    class_1 = [example for example in dataset if example[\"label\"] == 1][:num_example]\n",
    "\n",
    "    balanced_data = class_0 + class_1\n",
    "\n",
    "    balanced_dataset = Dataset.from_list(balanced_data)\n",
    "    balanced_dataset = balanced_dataset.shuffle(seed=42)\n",
    "\n",
    "    return balanced_dataset \n",
    " \n",
    "\n",
    "\n",
    "def get_val_test_set(dataset, val_size, test_size):\n",
    "    class_0 = [example for example in dataset if example[\"label\"] == 0]\n",
    "    class_1 = [example for example in dataset if example[\"label\"] == 1]    \n",
    "\n",
    "    val_set = class_0[:val_size//2] + class_1[:val_size//2]\n",
    "    test_set = class_0[val_size//2:val_size//2 + test_size//2] + class_1[val_size//2:val_size//2 + test_size//2]\n",
    "\n",
    "    val_set = Dataset.from_dict({k: [example[k] for example in val_set] for k in val_set[0]})\n",
    "    test_set = Dataset.from_dict({k: [example[k] for example in test_set] for k in test_set[0]})\n",
    "    \n",
    "    val_set = val_set.shuffle(seed=42)\n",
    "    test_set = test_set.shuffle(seed=42)\n",
    "\n",
    "    return val_set, test_set\n",
    "\n",
    "\n",
    "qqp_train_data = qqp_dataset[\"train\"]\n",
    "qqp_val_test_data = qqp_dataset[\"validation\"]\n",
    "\n",
    "qqp_train_data = balance_dataset(qqp_train_data,10000)\n",
    "qqp_val_data, qqp_test_data  =  get_val_test_set(qqp_val_test_data, 5000, 5000)\n",
    "\n",
    "qqp_train_questions1, qqp_train_questions2, qqp_train_labels = qqp_train_data['question1'],  qqp_train_data['question2'], qqp_train_data['label']\n",
    "qqp_val_questions1, qqp_val_questions2, qqp_val_labels = qqp_val_data['question1'],  qqp_val_data['question2'], qqp_val_data['label']\n",
    "qqp_test_questions1, qqp_test_questions2, qqp_test_labels = qqp_test_data['question1'],  qqp_test_data['question2'], qqp_test_data['label']\n",
    "\n",
    "\n",
    "print(\"Dimensioni dei set:\")\n",
    "print(f\"Train: {len(qqp_train_questions1)}\")\n",
    "print(f\"Validation: {len(qqp_val_questions1)}\")\n",
    "print(f\"Test: {len(qqp_test_questions1)}\")\n",
    "\n",
    "print(\"\\nDistribuzione delle etichette:\")\n",
    "print(f\"Train: {Counter(qqp_train_labels)}\")\n",
    "print(f\"Validation: {Counter(qqp_val_labels)}\")\n",
    "print(f\"Test: {Counter(qqp_test_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 256\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Inizializzo il Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Ottiengo i dataset\n",
    "qqp_training_data = NLIDataset(\n",
    "                           sentences1 = qqp_train_questions1,\n",
    "                           sentences2 = qqp_train_questions2,\n",
    "                           labels = qqp_train_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)\n",
    "\n",
    "qqp_validation_data = NLIDataset(\n",
    "                           sentences1 = qqp_val_questions1,\n",
    "                           sentences2 = qqp_val_questions2,\n",
    "                           labels = qqp_val_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)\n",
    "\n",
    "qqp_test_data = NLIDataset(\n",
    "                           sentences1 = qqp_test_questions1,\n",
    "                           sentences2 = qqp_test_questions2,\n",
    "                           labels = qqp_test_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Pretrained model\n",
    "lora_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "\n",
    "# LoRA config\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=128,\n",
    "    lora_dropout=0.3,\n",
    "    target_modules=[\"query\", \"key\", \"value\"],  \n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "lora_model = get_peft_model(lora_model, lora_config)\n",
    "lora_model.print_trainable_parameters()\n",
    "lora_model.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in lora_model.named_parameters():\n",
    "    if \"classifier\" in name:\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametri principali\n",
    "learning_rate = 5e-5\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Creo i DataLoader\n",
    "qqp_train_loader = DataLoader(qqp_training_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "qqp_val_loader = DataLoader(qqp_validation_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "qqp_test_loader = DataLoader(qqp_test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "total_steps = len(qqp_train_loader) * EPOCHS\n",
    "\n",
    "# Ottimizzatore\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, lora_model.parameters()), lr = learning_rate)\n",
    "\n",
    "\n",
    "# Scheduler\n",
    "scheduler = transformers.get_cosine_schedule_with_warmup(optimizer = optimizer,\n",
    "                                                       num_warmup_steps = 0,\n",
    "                                                       num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history, total_time, emissions = train_and_evaluate_model(\n",
    "    lora_model,\"qqp\", qqp_train_loader, qqp_val_loader, optimizer, scheduler, device, epochs=EPOCHS \n",
    ") \n",
    "print(f\"\\nBERT with LoRA Training Time: {total_time:.2f} seconds, {total_time/60:.2f} minutes.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model.load_state_dict(torch.load(\"qqp_best_model_state.bin\"))\n",
    "test_loss, test_acc, test_f1 = eval_model(lora_model, qqp_test_loader, device)\n",
    "print(f\"LoRA Fine-Tuning - Test loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}, F1 score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_task_results(\n",
    "    task_name=\"qqp\", \n",
    "    training_time=total_time,\n",
    "    emissions=emissions,\n",
    "    test_loss=test_loss,\n",
    "    test_acc=test_acc,\n",
    "    test_f1=test_f1,\n",
    ")\n",
    "\n",
    "performance = pd.DataFrame(model_performance)\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 8551\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 1043\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 1063\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Ottenimento del dataset\n",
    "cola_dataset = load_dataset(\"glue\", \"cola\")\n",
    "print(cola_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensioni dei set:\n",
      "Train: 7674\n",
      "Validation: 960\n",
      "Test: 960\n",
      "\n",
      "Distribuzione delle etichette:\n",
      "Train: Counter({1: 5394, 0: 2280})\n",
      "Validation: Counter({1: 675, 0: 285})\n",
      "Test: Counter({1: 675, 0: 285})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "cola_train_data = pd.DataFrame(cola_dataset[\"train\"])\n",
    "cola_val_data = pd.DataFrame(cola_dataset[\"validation\"])\n",
    "\n",
    "cola_data = Dataset.from_pandas(pd.concat([cola_train_data, cola_val_data], ignore_index=True))\n",
    "cola_data = cola_data.shuffle(seed=42)\n",
    "\n",
    "cola_temp_sentences, cola_test_sentences, cola_temp_labels, cola_test_labels = train_test_split(\n",
    "                                                cola_data['sentence'],\n",
    "                                                cola_data['label'], \n",
    "                                                test_size=0.1, \n",
    "                                                random_state=42,\n",
    "                                                stratify=cola_data['label'])\n",
    "\n",
    "cola_train_sentences, cola_val_sentences, cola_train_labels, cola_val_labels = train_test_split(\n",
    "                                                cola_temp_sentences, \n",
    "                                                cola_temp_labels,\n",
    "                                                test_size=0.1111,\n",
    "                                                random_state=42,\n",
    "                                                stratify=cola_temp_labels)\n",
    "\n",
    "print(\"Dimensioni dei set:\")\n",
    "print(f\"Train: {len(cola_train_sentences)}\")\n",
    "print(f\"Validation: {len(cola_val_sentences)}\")\n",
    "print(f\"Test: {len(cola_test_sentences)}\")\n",
    "\n",
    "# Verifica distribuzione delle etichette\n",
    "print(\"\\nDistribuzione delle etichette:\")\n",
    "print(f\"Train: {Counter(cola_train_labels)}\")\n",
    "print(f\"Validation: {Counter(cola_val_labels)}\")\n",
    "print(f\"Test: {Counter(cola_test_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 128\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Inizializzo il Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Ottiengo i dataset\n",
    "cola_training_data = ClassificationDataset(sentences = cola_train_sentences,\n",
    "                           labels = cola_train_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)\n",
    "\n",
    "cola_validation_data = ClassificationDataset(sentences = cola_val_sentences,\n",
    "                           labels = cola_val_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)\n",
    "\n",
    "cola_test_data = ClassificationDataset(sentences = cola_test_sentences,\n",
    "                           labels = cola_test_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 110,368,514 || trainable%: 0.8016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): BertForSequenceClassification(\n",
       "      (bert): BertModel(\n",
       "        (embeddings): BertEmbeddings(\n",
       "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "          (position_embeddings): Embedding(512, 768)\n",
       "          (token_type_embeddings): Embedding(2, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): BertEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSdpaSelfAttention(\n",
       "                  (query): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.3, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (key): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.3, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (value): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.3, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (pooler): BertPooler(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (activation): Tanh()\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Pretrained model\n",
    "lora_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "\n",
    "# LoRA config\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=128,\n",
    "    lora_dropout=0.3,\n",
    "    target_modules=[\"query\", \"key\", \"value\"],  \n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "lora_model = get_peft_model(lora_model, lora_config)\n",
    "lora_model.print_trainable_parameters()\n",
    "lora_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametri principali\n",
    "learning_rate = 5e-5\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Creo i DataLoader\n",
    "cola_train_loader = DataLoader( cola_training_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "cola_val_loader = DataLoader( cola_validation_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "cola_test_loader = DataLoader( cola_test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "total_steps = len( cola_train_loader) * EPOCHS\n",
    "\n",
    "# Ottimizzatore\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, lora_model.parameters()), lr = learning_rate)\n",
    "\n",
    "\n",
    "# Scheduler\n",
    "scheduler = transformers.get_cosine_schedule_with_warmup(optimizer = optimizer,\n",
    "                                                       num_warmup_steps = 0,\n",
    "                                                       num_training_steps = total_steps) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 10:30:22] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 10:30:22] [setup] CPU Tracking...\n",
      "[codecarbon INFO @ 10:30:22] Tracking Intel CPU via RAPL interface\n",
      "[codecarbon INFO @ 10:30:23] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 10:30:23] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 10:30:23] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:30:23] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:30:23] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:30:23] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:30:23] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:30:23] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:30:23] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon WARNING @ 10:30:23] You have 8 GPUs but we will monitor only 1 of them. Check your configuration.\n",
      "[codecarbon INFO @ 10:30:23] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 10:30:23]   Platform system: Linux-6.8.0-55-generic-x86_64-with-glibc2.39\n",
      "[codecarbon INFO @ 10:30:23]   Python version: 3.12.3\n",
      "[codecarbon INFO @ 10:30:23]   CodeCarbon version: 2.8.3\n",
      "[codecarbon INFO @ 10:30:23]   Available RAM : 754.342 GB\n",
      "[codecarbon INFO @ 10:30:23]   CPU count: 96\n",
      "[codecarbon INFO @ 10:30:23]   CPU model: Intel(R) Xeon(R) Gold 6248R CPU @ 3.00GHz\n",
      "[codecarbon INFO @ 10:30:23]   GPU count: 1\n",
      "[codecarbon INFO @ 10:30:23]   GPU model: 8 x NVIDIA A30 BUT only tracking these GPU ids : [6]\n",
      "[codecarbon INFO @ 10:30:26] Saving emissions data to file /home/notebook/riccardo_cantini/tesisti/Dagostino/carbon_emissions/emissions.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :  31%|███       | 74/240 [00:14<00:33,  4.97it/s, accuracy=0.733, loss=0.531][codecarbon INFO @ 10:30:41] Energy consumed for RAM : 0.001181 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 10:30:41] Energy consumed for all CPUs : 0.000344 kWh. Total CPU Power : 82.26544695669658 W\n",
      "[codecarbon INFO @ 10:30:41] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:30:41] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:30:41] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:30:41] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:30:41] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:30:41] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:30:41] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:30:41] Energy consumed for all GPUs : 0.000623 kWh. Total GPU Power : 149.13961766893053 W\n",
      "[codecarbon INFO @ 10:30:41] 0.002148 kWh of electricity used since the beginning.\n",
      "Training  :  62%|██████▏   | 149/240 [00:29<00:18,  4.96it/s, accuracy=0.745, loss=0.52][codecarbon INFO @ 10:30:56] Energy consumed for RAM : 0.002356 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 10:30:56] Energy consumed for all CPUs : 0.000687 kWh. Total CPU Power : 82.74970228155507 W\n",
      "[codecarbon INFO @ 10:30:56] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:30:56] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:30:56] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:30:56] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:30:56] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:30:56] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:30:56] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:30:56] Energy consumed for all GPUs : 0.001248 kWh. Total GPU Power : 150.55688550519633 W\n",
      "[codecarbon INFO @ 10:30:56] 0.004292 kWh of electricity used since the beginning.\n",
      "Training  :  93%|█████████▎| 223/240 [00:44<00:03,  4.94it/s, accuracy=0.76, loss=0.502][codecarbon INFO @ 10:31:11] Energy consumed for RAM : 0.003531 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 10:31:11] Energy consumed for all CPUs : 0.001029 kWh. Total CPU Power : 82.30016609047554 W\n",
      "[codecarbon INFO @ 10:31:11] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:31:11] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:31:11] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:31:11] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:31:11] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:31:11] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:31:11] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:31:11] Energy consumed for all GPUs : 0.001864 kWh. Total GPU Power : 148.35532922259233 W\n",
      "[codecarbon INFO @ 10:31:11] 0.006424 kWh of electricity used since the beginning.\n",
      "Training  : 100%|██████████| 240/240 [00:48<00:00,  4.97it/s, accuracy=0.76, loss=0.502] \n",
      "Evaluating: 100%|██████████| 30/30 [00:03<00:00,  9.69it/s, accuracy=0.78, loss=0.499] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :  17%|█▋        | 40/240 [00:08<00:40,  4.98it/s, accuracy=0.802, loss=0.459][codecarbon INFO @ 10:31:26] Energy consumed for RAM : 0.004705 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 10:31:26] Energy consumed for all CPUs : 0.001372 kWh. Total CPU Power : 82.54307345029055 W\n",
      "[codecarbon INFO @ 10:31:26] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:31:26] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:31:26] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:31:26] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:31:26] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:31:26] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:31:26] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:31:26] Energy consumed for all GPUs : 0.002486 kWh. Total GPU Power : 149.677021162879 W\n",
      "[codecarbon INFO @ 10:31:26] 0.008563 kWh of electricity used since the beginning.\n",
      "Training  :  48%|████▊     | 114/240 [00:22<00:25,  4.97it/s, accuracy=0.8, loss=0.452][codecarbon INFO @ 10:31:41] Energy consumed for RAM : 0.005880 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 10:31:41] Energy consumed for all CPUs : 0.001714 kWh. Total CPU Power : 82.2592283071015 W\n",
      "[codecarbon INFO @ 10:31:41] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:31:41] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:31:41] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:31:41] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:31:41] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:31:41] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:31:41] GPU number 7 will not be monitored, at your request.\n",
      "Training  :  48%|████▊     | 115/240 [00:23<00:25,  4.97it/s, accuracy=0.799, loss=0.453][codecarbon INFO @ 10:31:41] Energy consumed for all GPUs : 0.003118 kWh. Total GPU Power : 152.21835809582586 W\n",
      "[codecarbon INFO @ 10:31:41] 0.010712 kWh of electricity used since the beginning.\n",
      "Training  :  79%|███████▉  | 189/240 [00:38<00:10,  4.92it/s, accuracy=0.797, loss=0.45][codecarbon INFO @ 10:31:56] Energy consumed for RAM : 0.007056 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 10:31:56] Energy consumed for all CPUs : 0.002055 kWh. Total CPU Power : 82.13230932186592 W\n",
      "[codecarbon INFO @ 10:31:56] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:31:56] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:31:56] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:31:56] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:31:56] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:31:56] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:31:56] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:31:56] Energy consumed for all GPUs : 0.003754 kWh. Total GPU Power : 153.0185156705885 W\n",
      "[codecarbon INFO @ 10:31:56] 0.012865 kWh of electricity used since the beginning.\n",
      "Training  : 100%|██████████| 240/240 [00:48<00:00,  4.96it/s, accuracy=0.797, loss=0.448]\n",
      "Evaluating: 100%|██████████| 30/30 [00:03<00:00,  9.63it/s, accuracy=0.797, loss=0.467]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :   2%|▏         | 5/240 [00:01<00:47,  4.94it/s, accuracy=0.787, loss=0.428][codecarbon INFO @ 10:32:11] Energy consumed for RAM : 0.008230 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 10:32:11] Energy consumed for all CPUs : 0.002398 kWh. Total CPU Power : 82.76436635971723 W\n",
      "[codecarbon INFO @ 10:32:11] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:32:11] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:32:11] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:32:11] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:32:11] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:32:11] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:32:11] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:32:11] Energy consumed for all GPUs : 0.004375 kWh. Total GPU Power : 149.59288245044513 W\n",
      "[codecarbon INFO @ 10:32:11] 0.015004 kWh of electricity used since the beginning.\n",
      "Training  :  33%|███▎      | 79/240 [00:15<00:32,  4.94it/s, accuracy=0.809, loss=0.416][codecarbon INFO @ 10:32:26] Energy consumed for RAM : 0.009405 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 10:32:26] Energy consumed for all CPUs : 0.002740 kWh. Total CPU Power : 82.33642493920686 W\n",
      "[codecarbon INFO @ 10:32:26] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:32:26] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:32:26] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:32:26] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:32:26] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:32:26] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:32:26] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:32:26] Energy consumed for all GPUs : 0.005016 kWh. Total GPU Power : 154.1985940370108 W\n",
      "[codecarbon INFO @ 10:32:26] 0.017162 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 10:32:26] 0.047260 g.CO2eq/s mean an estimation of 1,490.3958089421815 kg.CO2eq/year\n",
      "Training  :  64%|██████▍   | 153/240 [00:30<00:17,  4.92it/s, accuracy=0.807, loss=0.417][codecarbon INFO @ 10:32:41] Energy consumed for RAM : 0.010579 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 10:32:41] Energy consumed for all CPUs : 0.003083 kWh. Total CPU Power : 82.57382514515764 W\n",
      "[codecarbon INFO @ 10:32:41] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:32:41] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:32:41] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:32:41] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:32:41] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:32:41] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:32:41] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:32:41] Energy consumed for all GPUs : 0.005661 kWh. Total GPU Power : 155.25233505477428 W\n",
      "[codecarbon INFO @ 10:32:41] 0.019323 kWh of electricity used since the beginning.\n",
      "Training  :  95%|█████████▍| 227/240 [00:46<00:02,  4.89it/s, accuracy=0.812, loss=0.414][codecarbon INFO @ 10:32:56] Energy consumed for RAM : 0.011754 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 10:32:56] Energy consumed for all CPUs : 0.003427 kWh. Total CPU Power : 82.67740638565925 W\n",
      "[codecarbon INFO @ 10:32:56] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:32:56] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:32:56] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:32:56] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:32:56] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:32:56] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:32:56] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:32:56] Energy consumed for all GPUs : 0.006298 kWh. Total GPU Power : 153.53222915530725 W\n",
      "[codecarbon INFO @ 10:32:56] 0.021479 kWh of electricity used since the beginning.\n",
      "Training  : 100%|██████████| 240/240 [00:48<00:00,  4.93it/s, accuracy=0.811, loss=0.417]\n",
      "Evaluating: 100%|██████████| 30/30 [00:03<00:00,  9.57it/s, accuracy=0.803, loss=0.457]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :  18%|█▊        | 43/240 [00:08<00:39,  4.95it/s, accuracy=0.83, loss=0.397][codecarbon INFO @ 10:33:11] Energy consumed for RAM : 0.012929 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 10:33:11] Energy consumed for all CPUs : 0.003770 kWh. Total CPU Power : 82.74054556723999 W\n",
      "[codecarbon INFO @ 10:33:11] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:33:11] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:33:11] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:33:11] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:33:11] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:33:11] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:33:11] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:33:11] Energy consumed for all GPUs : 0.006935 kWh. Total GPU Power : 153.17300962935593 W\n",
      "[codecarbon INFO @ 10:33:11] 0.023634 kWh of electricity used since the beginning.\n",
      "Training  :  49%|████▉     | 117/240 [00:23<00:25,  4.91it/s, accuracy=0.831, loss=0.39][codecarbon INFO @ 10:33:26] Energy consumed for RAM : 0.014104 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 10:33:26] Energy consumed for all CPUs : 0.004115 kWh. Total CPU Power : 82.90415598470389 W\n",
      "[codecarbon INFO @ 10:33:26] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:33:26] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:33:26] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:33:26] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:33:26] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:33:26] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:33:26] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:33:26] Energy consumed for all GPUs : 0.007583 kWh. Total GPU Power : 156.08527840355273 W\n",
      "[codecarbon INFO @ 10:33:26] 0.025802 kWh of electricity used since the beginning.\n",
      "Training  :  79%|███████▉  | 190/240 [00:38<00:10,  4.89it/s, accuracy=0.832, loss=0.386][codecarbon INFO @ 10:33:41] Energy consumed for RAM : 0.015279 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 10:33:41] Energy consumed for all CPUs : 0.004459 kWh. Total CPU Power : 82.99399665276295 W\n",
      "[codecarbon INFO @ 10:33:41] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:33:41] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:33:41] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:33:41] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:33:41] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:33:41] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:33:41] GPU number 7 will not be monitored, at your request.\n",
      "Training  :  80%|███████▉  | 191/240 [00:38<00:10,  4.89it/s, accuracy=0.832, loss=0.386][codecarbon INFO @ 10:33:41] Energy consumed for all GPUs : 0.008231 kWh. Total GPU Power : 155.86599100136965 W\n",
      "[codecarbon INFO @ 10:33:41] 0.027969 kWh of electricity used since the beginning.\n",
      "Training  : 100%|██████████| 240/240 [00:48<00:00,  4.92it/s, accuracy=0.831, loss=0.386]\n",
      "Evaluating: 100%|██████████| 30/30 [00:03<00:00,  9.54it/s, accuracy=0.805, loss=0.476]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La loss sul validation set non è migliorata per 1 epoche.\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :   2%|▎         | 6/240 [00:01<00:47,  4.93it/s, accuracy=0.802, loss=0.398][codecarbon INFO @ 10:33:56] Energy consumed for RAM : 0.016453 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 10:33:56] Energy consumed for all CPUs : 0.004805 kWh. Total CPU Power : 83.22540061343426 W\n",
      "[codecarbon INFO @ 10:33:56] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:33:56] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:33:56] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:33:56] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:33:56] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:33:56] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:33:56] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:33:56] Energy consumed for all GPUs : 0.008868 kWh. Total GPU Power : 153.47591902612916 W\n",
      "[codecarbon INFO @ 10:33:56] 0.030127 kWh of electricity used since the beginning.\n",
      "Training  :  33%|███▎      | 80/240 [00:16<00:32,  4.92it/s, accuracy=0.838, loss=0.376][codecarbon INFO @ 10:34:11] Energy consumed for RAM : 0.017629 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 10:34:11] Energy consumed for all CPUs : 0.005151 kWh. Total CPU Power : 83.25808806871382 W\n",
      "[codecarbon INFO @ 10:34:11] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:34:11] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:34:11] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:34:11] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:34:11] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:34:11] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:34:11] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:34:11] Energy consumed for all GPUs : 0.009521 kWh. Total GPU Power : 157.17528041407024 W\n",
      "[codecarbon INFO @ 10:34:11] 0.032301 kWh of electricity used since the beginning.\n",
      "Training  :  64%|██████▍   | 154/240 [00:31<00:17,  4.90it/s, accuracy=0.835, loss=0.376][codecarbon INFO @ 10:34:26] Energy consumed for RAM : 0.018804 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 10:34:26] Energy consumed for all CPUs : 0.005497 kWh. Total CPU Power : 83.25135969020022 W\n",
      "[codecarbon INFO @ 10:34:26] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:34:26] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:34:26] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:34:26] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:34:26] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:34:26] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:34:26] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:34:26] Energy consumed for all GPUs : 0.010170 kWh. Total GPU Power : 156.2843476119088 W\n",
      "[codecarbon INFO @ 10:34:26] 0.034471 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 10:34:26] 0.047704 g.CO2eq/s mean an estimation of 1,504.3857728571456 kg.CO2eq/year\n",
      "Training  :  95%|█████████▍| 227/240 [00:46<00:02,  4.88it/s, accuracy=0.838, loss=0.372][codecarbon INFO @ 10:34:41] Energy consumed for RAM : 0.019978 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 10:34:41] Energy consumed for all CPUs : 0.005842 kWh. Total CPU Power : 83.15458664348681 W\n",
      "[codecarbon INFO @ 10:34:41] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:34:41] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:34:41] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:34:41] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:34:41] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:34:41] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:34:41] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:34:41] Energy consumed for all GPUs : 0.010821 kWh. Total GPU Power : 156.7427206108046 W\n",
      "[codecarbon INFO @ 10:34:41] 0.036642 kWh of electricity used since the beginning.\n",
      "Training  : 100%|██████████| 240/240 [00:48<00:00,  4.91it/s, accuracy=0.84, loss=0.368] \n",
      "Evaluating: 100%|██████████| 30/30 [00:03<00:00,  9.53it/s, accuracy=0.806, loss=0.473]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La loss sul validation set non è migliorata per 2 epoche.\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :  18%|█▊        | 43/240 [00:08<00:39,  4.93it/s, accuracy=0.843, loss=0.356][codecarbon INFO @ 10:34:56] Energy consumed for RAM : 0.021153 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 10:34:56] Energy consumed for all CPUs : 0.006189 kWh. Total CPU Power : 83.6402955869812 W\n",
      "[codecarbon INFO @ 10:34:56] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:34:56] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:34:56] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:34:56] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:34:56] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:34:56] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:34:56] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:34:56] Energy consumed for all GPUs : 0.011461 kWh. Total GPU Power : 153.98094396832573 W\n",
      "[codecarbon INFO @ 10:34:56] 0.038803 kWh of electricity used since the beginning.\n",
      "Training  :  49%|████▉     | 117/240 [00:23<00:25,  4.90it/s, accuracy=0.851, loss=0.353][codecarbon INFO @ 10:35:11] Energy consumed for RAM : 0.022328 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 10:35:11] Energy consumed for all CPUs : 0.006538 kWh. Total CPU Power : 83.76136153499688 W\n",
      "[codecarbon INFO @ 10:35:11] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:35:11] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:35:11] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:35:11] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:35:11] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:35:11] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:35:11] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:35:11] Energy consumed for all GPUs : 0.012111 kWh. Total GPU Power : 156.55782358497282 W\n",
      "[codecarbon INFO @ 10:35:11] 0.040977 kWh of electricity used since the beginning.\n",
      "Training  :  79%|███████▉  | 190/240 [00:38<00:10,  4.88it/s, accuracy=0.852, loss=0.353][codecarbon INFO @ 10:35:26] Energy consumed for RAM : 0.023503 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 10:35:26] Energy consumed for all CPUs : 0.006885 kWh. Total CPU Power : 83.54623269353809 W\n",
      "[codecarbon INFO @ 10:35:26] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:35:26] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:35:26] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:35:26] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:35:26] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:35:26] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:35:26] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:35:26] Energy consumed for all GPUs : 0.012765 kWh. Total GPU Power : 157.30609207824693 W\n",
      "[codecarbon INFO @ 10:35:26] 0.043152 kWh of electricity used since the beginning.\n",
      "Training  : 100%|██████████| 240/240 [00:48<00:00,  4.90it/s, accuracy=0.85, loss=0.353] \n",
      "Evaluating: 100%|██████████| 30/30 [00:03<00:00,  9.52it/s, accuracy=0.809, loss=0.454]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :   2%|▎         | 6/240 [00:01<00:47,  4.95it/s, accuracy=0.839, loss=0.369][codecarbon INFO @ 10:35:41] Energy consumed for RAM : 0.024678 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 10:35:41] Energy consumed for all CPUs : 0.007232 kWh. Total CPU Power : 83.70848519921483 W\n",
      "[codecarbon INFO @ 10:35:41] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:35:41] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:35:41] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:35:41] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:35:41] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:35:41] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:35:41] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:35:41] Energy consumed for all GPUs : 0.013404 kWh. Total GPU Power : 153.8346988740152 W\n",
      "[codecarbon INFO @ 10:35:41] 0.045314 kWh of electricity used since the beginning.\n",
      "Training  :  33%|███▎      | 79/240 [00:16<00:32,  4.92it/s, accuracy=0.849, loss=0.351][codecarbon INFO @ 10:35:56] Energy consumed for RAM : 0.025852 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 10:35:56] Energy consumed for all CPUs : 0.007578 kWh. Total CPU Power : 83.40625258220857 W\n",
      "[codecarbon INFO @ 10:35:56] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:35:56] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:35:56] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:35:56] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:35:56] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:35:56] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:35:56] GPU number 7 will not be monitored, at your request.\n",
      "Training  :  33%|███▎      | 80/240 [00:16<00:32,  4.92it/s, accuracy=0.848, loss=0.352][codecarbon INFO @ 10:35:56] Energy consumed for all GPUs : 0.014054 kWh. Total GPU Power : 156.6746159018562 W\n",
      "[codecarbon INFO @ 10:35:56] 0.047484 kWh of electricity used since the beginning.\n",
      "Training  :  64%|██████▍   | 153/240 [00:31<00:17,  4.90it/s, accuracy=0.856, loss=0.342][codecarbon INFO @ 10:36:11] Energy consumed for RAM : 0.027027 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 10:36:11] Energy consumed for all CPUs : 0.007924 kWh. Total CPU Power : 83.27937482982476 W\n",
      "[codecarbon INFO @ 10:36:11] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:36:11] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:36:11] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:36:11] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:36:11] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:36:11] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:36:11] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:36:11] Energy consumed for all GPUs : 0.014710 kWh. Total GPU Power : 157.85699822050057 W\n",
      "[codecarbon INFO @ 10:36:11] 0.049661 kWh of electricity used since the beginning.\n",
      "Training  :  94%|█████████▍| 226/240 [00:46<00:02,  4.87it/s, accuracy=0.855, loss=0.345][codecarbon INFO @ 10:36:26] Energy consumed for RAM : 0.028202 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 10:36:26] Energy consumed for all CPUs : 0.008271 kWh. Total CPU Power : 83.38652020109595 W\n",
      "[codecarbon INFO @ 10:36:26] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:36:26] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:36:26] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:36:26] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:36:26] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:36:26] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:36:26] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:36:26] Energy consumed for all GPUs : 0.015359 kWh. Total GPU Power : 156.28078528943018 W\n",
      "[codecarbon INFO @ 10:36:26] 0.051832 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 10:36:26] 0.047846 g.CO2eq/s mean an estimation of 1,508.8758323436389 kg.CO2eq/year\n",
      "Training  : 100%|██████████| 240/240 [00:48<00:00,  4.90it/s, accuracy=0.855, loss=0.348]\n",
      "Evaluating: 100%|██████████| 30/30 [00:03<00:00,  9.52it/s, accuracy=0.816, loss=0.453]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :  18%|█▊        | 42/240 [00:08<00:40,  4.92it/s, accuracy=0.876, loss=0.307][codecarbon INFO @ 10:36:41] Energy consumed for RAM : 0.029376 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 10:36:41] Energy consumed for all CPUs : 0.008617 kWh. Total CPU Power : 83.40487793708266 W\n",
      "[codecarbon INFO @ 10:36:41] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:36:41] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:36:41] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:36:41] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:36:41] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:36:41] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:36:41] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:36:41] Energy consumed for all GPUs : 0.016002 kWh. Total GPU Power : 154.69801584307058 W\n",
      "[codecarbon INFO @ 10:36:41] 0.053995 kWh of electricity used since the beginning.\n",
      "Training  :  48%|████▊     | 116/240 [00:23<00:25,  4.90it/s, accuracy=0.861, loss=0.334][codecarbon INFO @ 10:36:56] Energy consumed for RAM : 0.030552 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 10:36:56] Energy consumed for all CPUs : 0.008962 kWh. Total CPU Power : 83.08383776952982 W\n",
      "[codecarbon INFO @ 10:36:56] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:36:56] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:36:56] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:36:56] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:36:56] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:36:56] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:36:56] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:36:56] Energy consumed for all GPUs : 0.016654 kWh. Total GPU Power : 156.94241830314695 W\n",
      "[codecarbon INFO @ 10:36:56] 0.056168 kWh of electricity used since the beginning.\n",
      "Training  :  79%|███████▉  | 189/240 [00:38<00:10,  4.88it/s, accuracy=0.862, loss=0.333][codecarbon INFO @ 10:37:11] Energy consumed for RAM : 0.031726 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 10:37:11] Energy consumed for all CPUs : 0.009309 kWh. Total CPU Power : 83.37240547625285 W\n",
      "[codecarbon INFO @ 10:37:11] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:37:11] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:37:11] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:37:11] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:37:11] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:37:11] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:37:11] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:37:11] Energy consumed for all GPUs : 0.017307 kWh. Total GPU Power : 157.388075640834 W\n",
      "[codecarbon INFO @ 10:37:11] 0.058342 kWh of electricity used since the beginning.\n",
      "Training  : 100%|██████████| 240/240 [00:48<00:00,  4.90it/s, accuracy=0.863, loss=0.334]\n",
      "Evaluating: 100%|██████████| 30/30 [00:03<00:00,  9.51it/s, accuracy=0.811, loss=0.469]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La loss sul validation set non è migliorata per 1 epoche.\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :   3%|▎         | 7/240 [00:01<00:47,  4.94it/s, accuracy=0.848, loss=0.329][codecarbon INFO @ 10:37:26] Energy consumed for RAM : 0.032900 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 10:37:26] Energy consumed for all CPUs : 0.009654 kWh. Total CPU Power : 83.29834615485152 W\n",
      "[codecarbon INFO @ 10:37:26] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:37:26] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:37:26] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:37:26] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:37:26] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:37:26] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:37:26] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:37:26] Energy consumed for all GPUs : 0.017960 kWh. Total GPU Power : 157.25899491092224 W\n",
      "[codecarbon INFO @ 10:37:26] 0.060515 kWh of electricity used since the beginning.\n",
      "Training  :  34%|███▍      | 81/240 [00:16<00:32,  4.92it/s, accuracy=0.87, loss=0.322][codecarbon INFO @ 10:37:41] Energy consumed for RAM : 0.034075 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 10:37:41] Energy consumed for all CPUs : 0.009999 kWh. Total CPU Power : 82.91153504035194 W\n",
      "[codecarbon INFO @ 10:37:41] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:37:41] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:37:41] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:37:41] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:37:41] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:37:41] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:37:41] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:37:41] Energy consumed for all GPUs : 0.018614 kWh. Total GPU Power : 157.4142812904696 W\n",
      "[codecarbon INFO @ 10:37:41] 0.062688 kWh of electricity used since the beginning.\n",
      "Training  :  64%|██████▍   | 154/240 [00:31<00:17,  4.89it/s, accuracy=0.863, loss=0.331][codecarbon INFO @ 10:37:56] Energy consumed for RAM : 0.035250 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 10:37:56] Energy consumed for all CPUs : 0.010344 kWh. Total CPU Power : 83.13702106233853 W\n",
      "[codecarbon INFO @ 10:37:56] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:37:56] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:37:56] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:37:56] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:37:56] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:37:56] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:37:56] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:37:56] Energy consumed for all GPUs : 0.019264 kWh. Total GPU Power : 156.54818613224936 W\n",
      "[codecarbon INFO @ 10:37:56] 0.064858 kWh of electricity used since the beginning.\n",
      "Training  :  95%|█████████▍| 227/240 [00:46<00:02,  4.87it/s, accuracy=0.862, loss=0.333][codecarbon INFO @ 10:38:11] Energy consumed for RAM : 0.036425 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 10:38:11] Energy consumed for all CPUs : 0.010690 kWh. Total CPU Power : 83.22625073386926 W\n",
      "[codecarbon INFO @ 10:38:11] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:38:11] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:38:11] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:38:11] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:38:11] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:38:11] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:38:11] GPU number 7 will not be monitored, at your request.\n",
      "Training  :  95%|█████████▌| 228/240 [00:46<00:02,  4.86it/s, accuracy=0.862, loss=0.333][codecarbon INFO @ 10:38:11] Energy consumed for all GPUs : 0.019918 kWh. Total GPU Power : 157.30847826987477 W\n",
      "[codecarbon INFO @ 10:38:11] 0.067033 kWh of electricity used since the beginning.\n",
      "Training  : 100%|██████████| 240/240 [00:48<00:00,  4.90it/s, accuracy=0.861, loss=0.335]\n",
      "Evaluating: 100%|██████████| 30/30 [00:03<00:00,  9.52it/s, accuracy=0.816, loss=0.458]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La loss sul validation set non è migliorata per 2 epoche.\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :  19%|█▉        | 46/240 [00:09<00:39,  4.93it/s, accuracy=0.867, loss=0.331][codecarbon INFO @ 10:38:26] Energy consumed for RAM : 0.037600 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 10:38:26] Energy consumed for all CPUs : 0.011036 kWh. Total CPU Power : 83.37826227118813 W\n",
      "[codecarbon INFO @ 10:38:26] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:38:26] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:38:26] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:38:26] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:38:26] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:38:26] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:38:26] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:38:26] Energy consumed for all GPUs : 0.020579 kWh. Total GPU Power : 159.18872128308843 W\n",
      "[codecarbon INFO @ 10:38:26] 0.069215 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 10:38:26] 0.047907 g.CO2eq/s mean an estimation of 1,510.7838802359704 kg.CO2eq/year\n",
      "Training  :  50%|█████     | 120/240 [00:24<00:24,  4.90it/s, accuracy=0.866, loss=0.333][codecarbon INFO @ 10:38:41] Energy consumed for RAM : 0.038775 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 10:38:41] Energy consumed for all CPUs : 0.011380 kWh. Total CPU Power : 82.80595026083559 W\n",
      "[codecarbon INFO @ 10:38:41] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:38:41] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:38:41] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:38:41] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:38:41] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:38:41] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:38:41] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:38:41] Energy consumed for all GPUs : 0.021229 kWh. Total GPU Power : 156.4022873901302 W\n",
      "[codecarbon INFO @ 10:38:41] 0.071384 kWh of electricity used since the beginning.\n",
      "Training  :  80%|████████  | 193/240 [00:39<00:09,  4.88it/s, accuracy=0.862, loss=0.337][codecarbon INFO @ 10:38:56] Energy consumed for RAM : 0.039948 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 10:38:56] Energy consumed for all CPUs : 0.011724 kWh. Total CPU Power : 82.87875742605385 W\n",
      "[codecarbon INFO @ 10:38:56] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:38:56] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:38:56] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:38:56] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:38:56] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:38:56] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:38:56] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:38:56] Energy consumed for all GPUs : 0.021881 kWh. Total GPU Power : 157.15705515932822 W\n",
      "[codecarbon INFO @ 10:38:56] 0.073554 kWh of electricity used since the beginning.\n",
      "Training  : 100%|██████████| 240/240 [00:48<00:00,  4.90it/s, accuracy=0.867, loss=0.33] \n",
      "Evaluating: 100%|██████████| 30/30 [00:03<00:00,  9.52it/s, accuracy=0.814, loss=0.462]\n",
      "[codecarbon INFO @ 10:39:09] Energy consumed for RAM : 0.040944 kWh. RAM Power : 282.8781752586365 W\n",
      "[codecarbon INFO @ 10:39:09] Energy consumed for all CPUs : 0.012019 kWh. Total CPU Power : 83.69693043755746 W\n",
      "[codecarbon INFO @ 10:39:09] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:39:09] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:39:09] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:39:09] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:39:09] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:39:09] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:39:09] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 10:39:09] Energy consumed for all GPUs : 0.022431 kWh. Total GPU Power : 155.9746190221796 W\n",
      "[codecarbon INFO @ 10:39:09] 0.075393 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La loss sul validation set non è migliorata per 3 epoche.\n",
      "Early stopping attivato dopo 3 epoche senza miglioramenti\n",
      "\n",
      "Emissioni CO₂ totali: 0.0249 kg\n",
      "\n",
      "BERT with LoRA Training Time: 522.73 seconds, 8.71 minutes.\n"
     ]
    }
   ],
   "source": [
    "history, total_time, emissions = train_and_evaluate_model(\n",
    "    lora_model,\" cola\",  cola_train_loader,  cola_val_loader, optimizer, scheduler, device, epochs=EPOCHS \n",
    ") \n",
    "print(f\"\\nBERT with LoRA Training Time: {total_time:.2f} seconds, {total_time/60:.2f} minutes.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 30/30 [00:03<00:00,  9.53it/s, accuracy=0.815, loss=0.441]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA Fine-Tuning - Test loss: 0.4411, Accuracy: 0.8146, F1 score: 0.7593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lora_model.load_state_dict(torch.load(\" cola_best_model_state.bin\"))\n",
    "test_loss, test_acc, test_f1 = eval_model(lora_model,  cola_test_loader, device)\n",
    "print(f\"LoRA Fine-Tuning - Test loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}, F1 score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_task_results(\n",
    "    task_name=\"cola\", \n",
    "    training_time=total_time,\n",
    "    emissions=emissions,\n",
    "    test_loss=test_loss,\n",
    "    test_acc=test_acc,\n",
    "    test_f1=test_f1,\n",
    ")\n",
    "\n",
    "performance = pd.DataFrame(model_performance)\n",
    "print(performance)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4095790,
     "sourceId": 7104655,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6601208,
     "sourceId": 10784419,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python tesisti_RC (GPU 6)",
   "language": "python",
   "name": "tesisti_rc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
