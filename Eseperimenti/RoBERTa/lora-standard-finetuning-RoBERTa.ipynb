{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# Fine-Tuning standard con LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configurazioni generali"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T08:24:16.998582Z",
     "iopub.status.busy": "2025-02-16T08:24:16.998293Z",
     "iopub.status.idle": "2025-02-16T08:24:17.003779Z",
     "shell.execute_reply": "2025-02-16T08:24:17.002668Z",
     "shell.execute_reply.started": "2025-02-16T08:24:16.998561Z"
    }
   },
   "source": [
    "Installazione delle librerie necessarie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importo i moduli necessari."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 16:02:38.509806: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-04 16:02:38.524593: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743782558.542598  145844 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743782558.548266  145844 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743782558.562083  145844 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743782558.562101  145844 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743782558.562103  145844 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743782558.562104  145844 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-04 16:02:38.567083: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from transformers import BertTokenizer\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import RobertaTokenizer\n",
    "from transformers import RobertaForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impostazione del seme casuale per la riproducibilità."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 42\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "torch.manual_seed(seed_value)\n",
    "\n",
    "# Imposto il seme casuale anche per i calcoli CUDA\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)  \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'date', 'user', 'sentiment', 'query'],\n",
      "        num_rows: 1600000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'date', 'user', 'sentiment', 'query'],\n",
      "        num_rows: 498\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Ottenimento del dataset\n",
    "sent140_dataset = load_dataset(\"stanfordnlp/sentiment140\",trust_remote_code=True)\n",
    "print(sent140_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensioni dei set:\n",
      "Train: 20000\n",
      "Validation: 1000\n",
      "Test: 1024\n",
      "\n",
      "Distribuzione delle etichette:\n",
      "Train: Counter({0: 10000, 1: 10000})\n",
      "Validation: Counter({1: 500, 0: 500})\n",
      "Test: Counter({1: 512, 0: 512})\n"
     ]
    }
   ],
   "source": [
    "# Divido i dati in training, validation e test set\n",
    "sent140_data = sent140_dataset[\"train\"].shuffle(seed=42)\n",
    "\n",
    "sent140_temp_sentences, sent140_test_sentences, sent140_temp_labels, sent140_test_labels = train_test_split(\n",
    "                                                sent140_data['text'], \n",
    "                                                sent140_data['sentiment'], \n",
    "                                                test_size=1024, \n",
    "                                                random_state=42,\n",
    "                                                stratify=sent140_data['sentiment'])\n",
    "\n",
    "sent140_train_sentences, sent140_val_sentences, sent140_train_labels, sent140_val_labels = train_test_split(\n",
    "                                                sent140_temp_sentences, \n",
    "                                                sent140_temp_labels, \n",
    "                                                train_size=20000,\n",
    "                                                test_size=1000,\n",
    "                                                random_state=42,\n",
    "                                                stratify=sent140_temp_labels)\n",
    "\n",
    "# Trasformazione delle etichette 0 -> 0 e 4->1\n",
    "sent140_train_labels = [1 if label == 4 else 0 for label in sent140_train_labels]\n",
    "sent140_val_labels = [1 if label == 4 else 0 for label in sent140_val_labels]\n",
    "sent140_test_labels = [1 if label == 4 else 0 for label in sent140_test_labels]\n",
    "\n",
    "\n",
    "print(\"Dimensioni dei set:\")\n",
    "print(f\"Train: {len(sent140_train_sentences)}\")\n",
    "print(f\"Validation: {len(sent140_val_sentences)}\")\n",
    "print(f\"Test: {len(sent140_test_sentences)}\")\n",
    "\n",
    "# Verifica distribuzione delle etichette\n",
    "print(\"\\nDistribuzione delle etichette:\")\n",
    "print(f\"Train: {Counter(sent140_train_labels)}\")\n",
    "print(f\"Validation: {Counter(sent140_val_labels)}\")\n",
    "print(f\"Test: {Counter(sent140_test_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationDataset(Dataset):\n",
    "\n",
    "    def __init__(self, sentences, labels, tokenizer, max_len):\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        sentence = self.sentences[index]\n",
    "        label = self.labels[index]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            sentence,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True,\n",
    "            padding=\"max_length\",\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt')\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'token_type_ids': encoding[\"token_type_ids\"].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 128\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Inizializzo il Tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Ottiengo i dataset\n",
    "sent140_training_data = ClassificationDataset(\n",
    "                           sentences = sent140_train_sentences,\n",
    "                           labels = sent140_train_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)\n",
    "\n",
    "sent140_validation_data = ClassificationDataset(\n",
    "                           sentences = sent140_val_sentences,\n",
    "                           labels = sent140_val_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)\n",
    "\n",
    "sent140_test_data = ClassificationDataset(\n",
    "                           sentences = sent140_test_sentences,\n",
    "                           labels = sent140_test_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch.nn as nn\n",
    "from codecarbon import EmissionsTracker\n",
    "\n",
    "\n",
    "# Funzione di training e valutazione\n",
    "def train_and_evaluate_model(model, dataset, train_loader, val_loader, optimizer, scheduler, device, epochs=10, patience=3):\n",
    "\n",
    "    os.makedirs(\"carbon_emissions\", exist_ok=True)\n",
    "    tracker = EmissionsTracker(output_dir=\"carbon_emissions\", output_file=\"emissions.csv\")  \n",
    "    tracker.start()  \n",
    "\n",
    "    history = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "    best_accuracy = 0\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0  \n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "        # Training\n",
    "        train_loss, train_acc = train_model(model, train_loader, optimizer, scheduler, device)\n",
    "        \n",
    "        # Valutazione\n",
    "        val_loss, val_acc, val_f1 = eval_model(model, val_loader, device)\n",
    "        \n",
    "        # Salvataggio del modello migliore\n",
    "        if val_acc > best_accuracy:\n",
    "            torch.save(model.state_dict(),  f\"{dataset}_best_model_state.bin\")\n",
    "            best_accuracy = val_acc\n",
    "\n",
    "        # Salvataggio delle metriche\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            patience_counter = 0 \n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"La loss sul validation set non è migliorata per {patience_counter} epoche.\")\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping attivato dopo {patience_counter} epoche senza miglioramenti\")\n",
    "            break\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_training_time = end_time - start_time\n",
    "\n",
    "    emissions = tracker.stop()\n",
    "    print(f\"\\nEmissioni CO₂ totali: {emissions:.4f} kg\")  \n",
    "\n",
    "    return history, total_training_time, emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione di training\n",
    "def train_model(model, data_loader, optimizer, scheduler, device):\n",
    "\n",
    "    model = model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    loop = tqdm(data_loader, desc=f\"Training  \", leave=True)\n",
    "\n",
    "    for batch in loop:\n",
    "\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # --- Forward pass ---\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            labels=labels \n",
    "        )\n",
    "\n",
    "        loss = outputs.loss  \n",
    "        logits = outputs.logits  \n",
    "\n",
    "        # --- Backward pass ---\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        preds = torch.argmax(logits, dim=1)  # Predizioni multiclasse\n",
    "\n",
    "        all_preds.extend(preds.detach().cpu().numpy())\n",
    "        all_labels.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "        loop.set_postfix(loss=total_loss / (loop.n + 1), accuracy=accuracy_score(all_labels, all_preds))\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione di valutazione\n",
    "def eval_model(model, data_loader, device):\n",
    "\n",
    "    model = model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        loop = tqdm(data_loader, desc=f\"Evaluating\", leave=True)\n",
    "        for batch in loop:\n",
    "            \n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            token_type_ids = batch[\"token_type_ids\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids,\n",
    "                labels=labels\n",
    "            )\n",
    "\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.detach().cpu().numpy())\n",
    "            all_labels.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "            loop.set_postfix(loss=total_loss / (loop.n + 1), accuracy=accuracy_score(all_labels, all_preds))\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "    \n",
    "    return avg_loss, accuracy, f1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,769,472 || all params: 126,416,642 || trainable%: 1.3997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): RobertaForSequenceClassification(\n",
       "      (roberta): RobertaModel(\n",
       "        (embeddings): RobertaEmbeddings(\n",
       "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): RobertaEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSdpaSelfAttention(\n",
       "                  (query): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.2, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (key): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.2, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (value): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.2, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (classifier): RobertaClassificationHead(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Pretrained model\n",
    "lora_model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2)\n",
    "\n",
    "# LoRA config\n",
    "lora_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=128,\n",
    "    lora_dropout=0.2,\n",
    "    target_modules=[\"query\", \"key\", \"value\"],  \n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "lora_model = get_peft_model(lora_model, lora_config)\n",
    "lora_model.print_trainable_parameters()\n",
    "lora_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.classifier.dense.weight: requires_grad = True\n",
      "base_model.model.classifier.dense.bias: requires_grad = True\n",
      "base_model.model.classifier.out_proj.weight: requires_grad = True\n",
      "base_model.model.classifier.out_proj.bias: requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "for name, param in lora_model.named_parameters():\n",
    "    if \"classifier\" in name:\n",
    "        param.requires_grad = True\n",
    "\n",
    "for name, param in lora_model.named_parameters():\n",
    "    if \"classifier\" in name:\n",
    "        print(f\"{name}: requires_grad = {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametri principali\n",
    "learning_rate = 2e-4\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Creo i DataLoader\n",
    "sent140_train_loader = DataLoader(sent140_training_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "sent140_val_loader = DataLoader(sent140_validation_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "sent140_test_loader = DataLoader(sent140_test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "total_steps = len(sent140_train_loader) * EPOCHS\n",
    "\n",
    "# Ottimizzatore\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, lora_model.parameters()), lr = learning_rate)\n",
    "\n",
    "\n",
    "# Scheduler\n",
    "scheduler = transformers.get_cosine_schedule_with_warmup(optimizer = optimizer,\n",
    "                                                       num_warmup_steps = 0,\n",
    "                                                       num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history, total_time, emissions = train_and_evaluate_model(\n",
    "    lora_model,\"sent140\", sent140_train_loader, sent140_val_loader, optimizer, scheduler, device, epochs=EPOCHS\n",
    ") \n",
    "print(f\"\\nBERT with LoRA Training Time: {total_time:.2f} seconds, {total_time/60:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 32/32 [00:03<00:00,  9.61it/s, accuracy=0.887, loss=0.343]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA Fine-Tuning - Test loss: 0.3434, Accuracy: 0.8867, F1 score: 0.8867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lora_model.load_state_dict(torch.load(\"sent140_best_model_state.bin\"))\n",
    "    \n",
    "test_loss, test_acc, test_f1 = eval_model(lora_model, sent140_test_loader, device)\n",
    "print(f\"LoRA Fine-Tuning - Test loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}, F1 score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance = []\n",
    "\n",
    "# Funzione per memorizzare le performance sul task appena addestrato\n",
    "def add_task_results(task_name, training_time, emissions, test_loss, test_acc, test_f1):\n",
    "    model_performance.append({\n",
    "        \"Task\": task_name,\n",
    "        \"Training Time\": training_time,\n",
    "        \"CO2 Emissions\": emissions,\n",
    "        \"Test Loss\": test_loss,\n",
    "        \"Accuracy\": test_acc,\n",
    "        \"F1 Score\": test_f1,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'add_task_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Memorizzazione dei risultati su Sentiment140\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43madd_task_results\u001b[49m(\n\u001b[32m      3\u001b[39m     task_name=\u001b[33m\"\u001b[39m\u001b[33msentiment140\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m      4\u001b[39m     training_time=total_time,\n\u001b[32m      5\u001b[39m     emissions=emissions,\n\u001b[32m      6\u001b[39m     test_loss=test_loss,\n\u001b[32m      7\u001b[39m     test_acc=test_acc,\n\u001b[32m      8\u001b[39m     test_f1=test_f1,\n\u001b[32m      9\u001b[39m )\n\u001b[32m     11\u001b[39m performance = pd.DataFrame(model_performance)\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(performance)\n",
      "\u001b[31mNameError\u001b[39m: name 'add_task_results' is not defined"
     ]
    }
   ],
   "source": [
    "# Memorizzazione dei risultati su Sentiment140\n",
    "add_task_results(\n",
    "    task_name=\"sentiment140\", \n",
    "    training_time=total_time,\n",
    "    emissions=emissions,\n",
    "    test_loss=test_loss,\n",
    "    test_acc=test_acc,\n",
    "    test_f1=test_f1,\n",
    ")\n",
    "\n",
    "performance = pd.DataFrame(model_performance)\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB Rewiews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "    unsupervised: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Ottenimento del dataset\n",
    "imdb_dataset = load_dataset(\"stanfordnlp/imdb\")\n",
    "print(imdb_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensioni dei set:\n",
      "Train: 40000\n",
      "Validation: 5000\n",
      "Test: 5000\n",
      "\n",
      "Distribuzione delle etichette:\n",
      "Train: Counter({0: 20000, 1: 20000})\n",
      "Validation: Counter({0: 2500, 1: 2500})\n",
      "Test: Counter({1: 2500, 0: 2500})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "imdb_train_data = pd.DataFrame(imdb_dataset[\"train\"])\n",
    "imdb_test_data = pd.DataFrame(imdb_dataset[\"test\"])\n",
    "\n",
    "imdb_data = Dataset.from_pandas(pd.concat([imdb_train_data, imdb_test_data], ignore_index=True))\n",
    "imdb_data = imdb_data.shuffle(seed=42)\n",
    "\n",
    "imdb_temp_sentences, imdb_test_sentences, imdb_temp_labels, imdb_test_labels = train_test_split(\n",
    "                                                imdb_data['text'],\n",
    "                                                imdb_data['label'], \n",
    "                                                test_size=0.1, \n",
    "                                                random_state=42,\n",
    "                                                stratify=imdb_data['label'])\n",
    "\n",
    "imdb_train_sentences, imdb_val_sentences, imdb_train_labels, imdb_val_labels = train_test_split(\n",
    "                                                imdb_temp_sentences,\n",
    "                                                imdb_temp_labels,\n",
    "                                                test_size=0.1111,\n",
    "                                                random_state=42,\n",
    "                                                stratify=imdb_temp_labels)\n",
    "\n",
    "print(\"Dimensioni dei set:\")\n",
    "print(f\"Train: {len(imdb_train_sentences)}\")\n",
    "print(f\"Validation: {len(imdb_val_sentences)}\")\n",
    "print(f\"Test: {len(imdb_test_sentences)}\")\n",
    "\n",
    "# Verifica distribuzione delle etichette\n",
    "print(\"\\nDistribuzione delle etichette:\")\n",
    "print(f\"Train: {Counter(imdb_train_labels)}\")\n",
    "print(f\"Validation: {Counter(imdb_val_labels)}\")\n",
    "print(f\"Test: {Counter(imdb_test_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 128\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Inizializzo il Tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Ottiengo i dataset\n",
    "imdb_training_data = ClassificationDataset(sentences = imdb_train_sentences,\n",
    "                           labels = imdb_train_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)\n",
    "\n",
    "imdb_validation_data = ClassificationDataset(sentences = imdb_val_sentences,\n",
    "                           labels = imdb_val_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)\n",
    "\n",
    "imdb_test_data = ClassificationDataset(sentences = imdb_test_sentences,\n",
    "                           labels = imdb_test_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,769,472 || all params: 126,416,642 || trainable%: 1.3997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): RobertaForSequenceClassification(\n",
       "      (roberta): RobertaModel(\n",
       "        (embeddings): RobertaEmbeddings(\n",
       "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): RobertaEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSdpaSelfAttention(\n",
       "                  (query): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.2, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (key): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.2, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (value): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.2, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (classifier): RobertaClassificationHead(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Pretrained model\n",
    "lora_model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2)\n",
    "\n",
    "# LoRA config\n",
    "lora_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=128,\n",
    "    lora_dropout=0.2,\n",
    "    target_modules=[\"query\", \"key\", \"value\"],  \n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "lora_model = get_peft_model(lora_model, lora_config)\n",
    "lora_model.print_trainable_parameters()\n",
    "lora_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in lora_model.named_parameters():\n",
    "    if \"classifier\" in name:\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametri principali\n",
    "learning_rate = 2e-4\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Creo i DataLoader\n",
    "imdb_train_loader = DataLoader(imdb_training_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "imdb_val_loader = DataLoader(imdb_validation_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "imdb_test_loader = DataLoader(imdb_test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "total_steps = len(imdb_train_loader) * EPOCHS\n",
    "\n",
    "# Ottimizzatore\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, lora_model.parameters()), lr = learning_rate)\n",
    "\n",
    "\n",
    "# Scheduler\n",
    "scheduler = transformers.get_cosine_schedule_with_warmup(optimizer = optimizer,\n",
    "                                                       num_warmup_steps = 0,\n",
    "                                                       num_training_steps = total_steps) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history, total_time, emissions = train_and_evaluate_model(\n",
    "    lora_model,\"imdb\", imdb_train_loader, imdb_val_loader, optimizer, scheduler, device, epochs=EPOCHS\n",
    ") \n",
    "print(f\"\\nBERT with LoRA Training Time: {total_time:.2f} seconds, {total_time/60:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 157/157 [00:22<00:00,  6.87it/s, accuracy=0.911, loss=0.289]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA Fine-Tuning - Test loss: 0.2892, Accuracy: 0.9110, F1 score: 0.9110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lora_model.load_state_dict(torch.load(\"imdb_best_model_state.bin\"))\n",
    "test_loss, test_acc, test_f1 = eval_model(lora_model, imdb_test_loader, device)\n",
    "print(f\"LoRA Fine-Tuning - Test loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}, F1 score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Task  Training Time  CO2 Emissions  Test Loss  Accuracy  F1 Score\n",
      "0  sentiment140     528.088084       0.025174   0.343413  0.886719  0.886717\n",
      "1          imdb    2023.450950       0.094632   0.289216  0.911000  0.910982\n"
     ]
    }
   ],
   "source": [
    "add_task_results(\n",
    "    task_name=\"imdb\", \n",
    "    training_time=total_time,\n",
    "    emissions=emissions,\n",
    "    test_loss=test_loss,\n",
    "    test_acc=test_acc,\n",
    "    test_f1=test_f1,\n",
    ")\n",
    "\n",
    "performance = pd.DataFrame(model_performance)\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20 News Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label', 'label_text'],\n",
      "        num_rows: 11314\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label', 'label_text'],\n",
      "        num_rows: 7532\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Ottenimento del dataset\n",
    "news_dataset = load_dataset(\"SetFit/20_newsgroups\")\n",
    "print(news_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensioni dei set:\n",
      "Train: 15076\n",
      "Validation: 1885\n",
      "Test: 1885\n",
      "\n",
      "Distribuzione delle etichette:\n",
      "Train: Counter({10: 799, 15: 797, 8: 796, 9: 795, 11: 793, 13: 792, 7: 792, 5: 790, 14: 789, 12: 788, 2: 788, 3: 786, 6: 780, 1: 779, 4: 771, 17: 752, 16: 728, 0: 639, 18: 620, 19: 502})\n",
      "Validation: Counter({10: 100, 8: 100, 9: 100, 15: 100, 14: 99, 13: 99, 7: 99, 11: 99, 5: 99, 3: 98, 12: 98, 2: 98, 6: 97, 1: 97, 4: 96, 17: 94, 16: 91, 0: 80, 18: 78, 19: 63})\n",
      "Test: Counter({8: 100, 10: 100, 15: 100, 11: 99, 9: 99, 7: 99, 13: 99, 14: 99, 5: 99, 2: 99, 6: 98, 3: 98, 12: 98, 1: 97, 4: 96, 17: 94, 16: 91, 0: 80, 18: 77, 19: 63})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "news_train_data = pd.DataFrame(news_dataset[\"train\"])\n",
    "news_test_data = pd.DataFrame(news_dataset[\"test\"])\n",
    "\n",
    "news_data = Dataset.from_pandas(pd.concat([news_train_data, news_test_data], ignore_index=True))\n",
    "news_data = news_data.shuffle(seed=42)\n",
    "\n",
    "news_temp_sentences, news_test_sentences, news_temp_labels, news_test_labels = train_test_split(\n",
    "                                                news_data['text'],\n",
    "                                                news_data['label'], \n",
    "                                                test_size=0.1, \n",
    "                                                random_state=42,\n",
    "                                                stratify=news_data['label'])\n",
    "\n",
    "news_train_sentences, news_val_sentences, news_train_labels, news_val_labels = train_test_split(\n",
    "                                                news_temp_sentences,\n",
    "                                                news_temp_labels,\n",
    "                                                test_size=0.1111,\n",
    "                                                random_state=42,\n",
    "                                                stratify=news_temp_labels)\n",
    "\n",
    "print(\"Dimensioni dei set:\")\n",
    "print(f\"Train: {len(news_train_sentences)}\")\n",
    "print(f\"Validation: {len(news_val_sentences)}\")\n",
    "print(f\"Test: {len(news_test_sentences)}\")\n",
    "\n",
    "# Verifica distribuzione delle etichette\n",
    "print(\"\\nDistribuzione delle etichette:\")\n",
    "print(f\"Train: {Counter(news_train_labels)}\")\n",
    "print(f\"Validation: {Counter(news_val_labels)}\")\n",
    "print(f\"Test: {Counter(news_test_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 128\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Inizializzo il Tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Ottiengo i dataset\n",
    "news_training_data = ClassificationDataset(sentences = news_train_sentences,\n",
    "                           labels = news_train_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)\n",
    "\n",
    "news_validation_data = ClassificationDataset(sentences = news_val_sentences,\n",
    "                           labels = news_val_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)\n",
    "\n",
    "news_test_data = ClassificationDataset(sentences = news_test_sentences,\n",
    "                           labels = news_test_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,769,472 || all params: 126,430,484 || trainable%: 1.3996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): RobertaForSequenceClassification(\n",
       "      (roberta): RobertaModel(\n",
       "        (embeddings): RobertaEmbeddings(\n",
       "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): RobertaEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSdpaSelfAttention(\n",
       "                  (query): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.2, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (key): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.2, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (value): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.2, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (classifier): RobertaClassificationHead(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=20, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Pretrained model\n",
    "lora_model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=20)\n",
    "\n",
    "# LoRA config\n",
    "lora_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=128,\n",
    "    lora_dropout=0.2,\n",
    "    target_modules=[\"query\", \"key\", \"value\"],  \n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "lora_model = get_peft_model(lora_model, lora_config)\n",
    "lora_model.print_trainable_parameters()\n",
    "lora_model.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametri principali\n",
    "learning_rate = 2e-4\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Creo i DataLoader\n",
    "news_train_loader = DataLoader(news_training_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "news_val_loader = DataLoader(news_validation_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "news_test_loader = DataLoader(news_test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "total_steps = len(news_train_loader) * EPOCHS\n",
    "\n",
    "# Ottimizzatore\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, lora_model.parameters()), lr = learning_rate)\n",
    "\n",
    "\n",
    "# Scheduler\n",
    "scheduler = transformers.get_cosine_schedule_with_warmup(optimizer = optimizer,\n",
    "                                                       num_warmup_steps = 0,\n",
    "                                                       num_training_steps = total_steps) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history, total_time, emissions = train_and_evaluate_model(\n",
    "    lora_model,\"news\", news_train_loader, news_val_loader, optimizer, scheduler, device, epochs=EPOCHS \n",
    ") \n",
    "print(f\"\\nBERT with LoRA Training Time: {total_time:.2f} seconds, {total_time/60:.2f} minutes.\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 59/59 [00:08<00:00,  6.69it/s, accuracy=0.714, loss=1.1] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA Fine-Tuning - Test loss: 1.1009, Accuracy: 0.7141, F1 score: 0.6921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lora_model.load_state_dict(torch.load(\"news_best_model_state.bin\"))\n",
    "test_loss, test_acc, test_f1 = eval_model(lora_model, news_test_loader, device)\n",
    "print(f\"LoRA Fine-Tuning - Test loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}, F1 score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Task  Training Time  CO2 Emissions  Test Loss  Accuracy  F1 Score\n",
      "0  sentiment140     528.088084       0.025174   0.343413  0.886719  0.886717\n",
      "1          imdb    2023.450950       0.094632   0.289216  0.911000  0.910982\n",
      "2          news    1268.460714       0.059037   1.100891  0.714058  0.692104\n"
     ]
    }
   ],
   "source": [
    "add_task_results(\n",
    "    task_name=\"news\", \n",
    "    training_time=total_time,\n",
    "    emissions=emissions,\n",
    "    test_loss=test_loss,\n",
    "    test_acc=test_acc,\n",
    "    test_f1=test_f1,\n",
    ")\n",
    "\n",
    "performance = pd.DataFrame(model_performance)\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBpedia 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensioni dei set:\n",
      "Train: 28000\n",
      "Validation: 5000\n",
      "Test: 5000\n",
      "\n",
      "Distribuzione delle etichette:\n",
      "Train: Counter({0: 2000, 1: 2000, 2: 2000, 3: 2000, 4: 2000, 5: 2000, 6: 2000, 7: 2000, 8: 2000, 9: 2000, 10: 2000, 11: 2000, 12: 2000, 13: 2000})\n",
      "Validation: Counter({11: 358, 9: 358, 2: 357, 7: 357, 1: 357, 10: 357, 6: 357, 3: 357, 0: 357, 13: 357, 12: 357, 5: 357, 8: 357, 4: 357})\n",
      "Test: Counter({12: 358, 10: 358, 1: 357, 6: 357, 3: 357, 5: 357, 9: 357, 4: 357, 2: 357, 0: 357, 11: 357, 8: 357, 7: 357, 13: 357})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_125921/3725619038.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  dbpedia_train_dataset = dbpedia_train_dataset.groupby(\"label\").apply(lambda x: x.sample(n=2000, random_state=42))\n"
     ]
    }
   ],
   "source": [
    "# Ottenimento del dataset\n",
    "dbpedia_train_dataset = pd.read_csv('./dataset/dbpedia-ontology-dataset/train.csv')\n",
    "dbpedia_val_test_dataset = pd.read_csv('./dataset/dbpedia-ontology-dataset/test.csv')\n",
    "\n",
    "# Costruisco il training set in modo da avere 2000 esempi per ognuna delle 14 classi\n",
    "dbpedia_train_dataset = dbpedia_train_dataset.groupby(\"label\").apply(lambda x: x.sample(n=2000, random_state=42))\n",
    "dbpedia_train_dataset.reset_index(drop=True, inplace=True)\n",
    "\n",
    "dbpedia_train_sentences, dbpedia_train_labels = dbpedia_train_dataset['content'], dbpedia_train_dataset['label']\n",
    "\n",
    "# Divido i dati di test in test e val set\n",
    "dbpedia_val_sentences, dbpedia_test_sentences, dbpedia_val_labels, dbpedia_test_labels = train_test_split(\n",
    "                                                dbpedia_val_test_dataset['content'], \n",
    "                                                dbpedia_val_test_dataset['label'], \n",
    "                                                train_size=5000,\n",
    "                                                test_size=5000,\n",
    "                                                random_state=42,\n",
    "                                                stratify=dbpedia_val_test_dataset['label']\n",
    "                                            )\n",
    "\n",
    "dbpedia_val_sentences = dbpedia_val_sentences.reset_index(drop=True)\n",
    "dbpedia_val_labels = dbpedia_val_labels.reset_index(drop=True)\n",
    "\n",
    "dbpedia_test_sentences = dbpedia_test_sentences.reset_index(drop=True)\n",
    "dbpedia_test_labels = dbpedia_test_labels.reset_index(drop=True)\n",
    "\n",
    "print(\"Dimensioni dei set:\")\n",
    "print(f\"Train: {len(dbpedia_train_sentences)}\")\n",
    "print(f\"Validation: {len(dbpedia_val_sentences)}\")\n",
    "print(f\"Test: {len(dbpedia_test_sentences)}\")\n",
    "\n",
    "print(\"\\nDistribuzione delle etichette:\")\n",
    "print(f\"Train: {Counter(dbpedia_train_labels.tolist())}\")\n",
    "print(f\"Validation: {Counter(dbpedia_val_labels.tolist())}\")\n",
    "print(f\"Test: {Counter(dbpedia_test_labels.tolist())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 512\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Inizializzo il Tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Ottiengo i dataset\n",
    "dbpedia_training_data = ClassificationDataset(sentences = dbpedia_train_sentences,\n",
    "                           labels = dbpedia_train_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)\n",
    "\n",
    "dbpedia_validation_data = ClassificationDataset(sentences = dbpedia_val_sentences,\n",
    "                           labels = dbpedia_val_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)\n",
    "\n",
    "dbpedia_test_data = ClassificationDataset(sentences = dbpedia_test_sentences,\n",
    "                           labels = dbpedia_test_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Pretrained model\n",
    "lora_model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=14)\n",
    "\n",
    "# LoRA config\n",
    "lora_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=128,\n",
    "    lora_dropout=0.2,\n",
    "    target_modules=[\"query\", \"key\", \"value\"],  \n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "lora_model = get_peft_model(lora_model, lora_config)\n",
    "lora_model.print_trainable_parameters()\n",
    "lora_model.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.classifier.dense.weight: requires_grad = True\n",
      "base_model.model.classifier.dense.bias: requires_grad = True\n",
      "base_model.model.classifier.out_proj.weight: requires_grad = True\n",
      "base_model.model.classifier.out_proj.bias: requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "for name, param in lora_model.named_parameters():\n",
    "    if \"classifier\" in name:\n",
    "        param.requires_grad = True\n",
    "\n",
    "for name, param in lora_model.named_parameters():\n",
    "    if \"classifier\" in name:\n",
    "        print(f\"{name}: requires_grad = {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametri principali\n",
    "learning_rate = 2e-4\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Creo i DataLoader\n",
    "dbpedia_train_loader = DataLoader(dbpedia_training_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dbpedia_val_loader = DataLoader(dbpedia_validation_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "dbpedia_test_loader = DataLoader(dbpedia_test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "total_steps = len(dbpedia_train_loader) * EPOCHS\n",
    "\n",
    "# Ottimizzatore\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, lora_model.parameters()), lr = learning_rate)\n",
    "\n",
    "\n",
    "# Scheduler\n",
    "scheduler = transformers.get_cosine_schedule_with_warmup(optimizer = optimizer,\n",
    "                                                       num_warmup_steps = 0,\n",
    "                                                       num_training_steps = total_steps) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history, total_time, emissions = train_and_evaluate_model(\n",
    "    lora_model,\"dbpedia\", dbpedia_train_loader, dbpedia_val_loader, optimizer, scheduler, device, epochs=EPOCHS \n",
    ")\n",
    "print(f\"\\nBERT with LoRA Training Time: {total_time:.2f} seconds, {total_time/60:.2f} minutes.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 157/157 [01:03<00:00,  2.49it/s, accuracy=0.991, loss=0.0529]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA Fine-Tuning - Test loss: 0.0529, Accuracy: 0.9910, F1 score: 0.9910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lora_model.load_state_dict(torch.load(\"dbpedia_best_model_state.bin\"))\n",
    "test_loss, test_acc, test_f1 = eval_model(lora_model, dbpedia_test_loader, device)\n",
    "print(f\"LoRA Fine-Tuning - Test loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}, F1 score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Task  Training Time  CO2 Emissions  Test Loss  Accuracy  F1 Score\n",
      "0  sentiment140     528.088084       0.025174   0.343413  0.886719  0.886717\n",
      "1          imdb    2023.450950       0.094632   0.289216  0.911000  0.910982\n",
      "2          news    1268.460714       0.059037   1.100891  0.714058  0.692104\n",
      "3       dbpedia    3242.169252       0.156761   0.052926  0.991000  0.990991\n"
     ]
    }
   ],
   "source": [
    "add_task_results(\n",
    "    task_name=\"dbpedia\", \n",
    "    training_time=total_time,\n",
    "    emissions=emissions,\n",
    "    test_loss=test_loss,\n",
    "    test_acc=test_acc,\n",
    "    test_f1=test_f1,\n",
    ")\n",
    "\n",
    "performance = pd.DataFrame(model_performance)\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotion Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 16000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Ottenimento del dataset\n",
    "emotion_dataset = load_dataset(\"dair-ai/emotion\")\n",
    "print(emotion_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensioni dei set:\n",
      "Train: 16000\n",
      "Validation: 2000\n",
      "Test: 2000\n",
      "\n",
      "Distribuzione delle etichette:\n",
      "Train: Counter({1: 5362, 0: 4666, 3: 2159, 4: 1937, 2: 1304, 5: 572})\n",
      "Validation: Counter({1: 704, 0: 550, 3: 275, 4: 212, 2: 178, 5: 81})\n",
      "Test: Counter({1: 695, 0: 581, 3: 275, 4: 224, 2: 159, 5: 66})\n"
     ]
    }
   ],
   "source": [
    "#Divido i dati in training, validation e test set\n",
    "emotion_train_data = emotion_dataset[\"train\"].shuffle(seed=42)\n",
    "emotion_val_data = emotion_dataset[\"validation\"].shuffle(seed=42)\n",
    "emotion_test_data = emotion_dataset[\"test\"].shuffle(seed=42)\n",
    "\n",
    "emotion_train_sentences, emotion_train_labels = emotion_train_data['text'],emotion_train_data['label']\n",
    "emotion_val_sentences, emotion_val_labels = emotion_val_data['text'],emotion_val_data['label']\n",
    "emotion_test_sentences, emotion_test_labels = emotion_test_data['text'],emotion_test_data['label']\n",
    "\n",
    "print(\"Dimensioni dei set:\")\n",
    "print(f\"Train: {len(emotion_train_sentences)}\")\n",
    "print(f\"Validation: {len(emotion_val_sentences)}\")\n",
    "print(f\"Test: {len(emotion_test_sentences)}\")\n",
    "\n",
    "# Verifica distribuzione delle etichette\n",
    "print(\"\\nDistribuzione delle etichette:\")\n",
    "print(f\"Train: {Counter(emotion_train_labels)}\")\n",
    "print(f\"Validation: {Counter(emotion_val_labels)}\")\n",
    "print(f\"Test: {Counter(emotion_test_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 128\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Inizializzo il Tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Ottiengo i dataset\n",
    "emotion_training_data = ClassificationDataset(\n",
    "                            sentences = emotion_train_sentences,\n",
    "                            labels = emotion_train_labels,\n",
    "                            tokenizer = tokenizer,\n",
    "                            max_len = MAX_SEQ_LEN)\n",
    "\n",
    "emotion_validation_data = ClassificationDataset(\n",
    "                            sentences = emotion_val_sentences,\n",
    "                            labels = emotion_val_labels,\n",
    "                            tokenizer = tokenizer,\n",
    "                            max_len = MAX_SEQ_LEN)\n",
    "\n",
    "emotion_test_data = ClassificationDataset(\n",
    "                            sentences = emotion_test_sentences,\n",
    "                            labels = emotion_test_labels,\n",
    "                            tokenizer = tokenizer,\n",
    "                            max_len = MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 125,534,982 || trainable%: 0.7048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): RobertaForSequenceClassification(\n",
       "      (roberta): RobertaModel(\n",
       "        (embeddings): RobertaEmbeddings(\n",
       "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): RobertaEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSdpaSelfAttention(\n",
       "                  (query): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.3, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (key): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.3, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (value): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.3, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (classifier): RobertaClassificationHead(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=6, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Pretrained model\n",
    "lora_model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=6)\n",
    "\n",
    "# LoRA config\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=128,\n",
    "    lora_dropout=0.3,\n",
    "    target_modules=[\"query\", \"key\", \"value\"],  \n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "lora_model = get_peft_model(lora_model, lora_config)\n",
    "lora_model.print_trainable_parameters()\n",
    "lora_model.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametri principali\n",
    "learning_rate = 2e-4\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Creo i DataLoader\n",
    "emotion_train_loader = DataLoader(emotion_training_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "emotion_val_loader = DataLoader(emotion_validation_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "emotion_test_loader = DataLoader(emotion_test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "total_steps = len(emotion_train_loader) * EPOCHS\n",
    "\n",
    "# Ottimizzatore\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, lora_model.parameters()), lr = learning_rate)\n",
    "\n",
    "\n",
    "# Scheduler\n",
    "scheduler = transformers.get_cosine_schedule_with_warmup(optimizer = optimizer,\n",
    "                                                       num_warmup_steps = 0,\n",
    "                                                       num_training_steps = total_steps) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in lora_model.named_parameters():\n",
    "    if \"classifier\" in name:\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history, total_time, emissions = train_and_evaluate_model(\n",
    "    lora_model,\"emotion\", emotion_train_loader, emotion_val_loader, optimizer, scheduler, device, epochs=EPOCHS \n",
    ") \n",
    "print(f\"\\nBERT with LoRA Training Time: {total_time:.2f} seconds, {total_time/60:.2f} minutes.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 63/63 [00:06<00:00,  9.80it/s, accuracy=0.933, loss=0.171]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA Fine-Tuning - Test loss: 0.1712, Accuracy: 0.9335, F1 score: 0.8896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lora_model.load_state_dict(torch.load(\"emotion_best_model_state.bin\"))\n",
    " \n",
    "test_loss, test_acc, test_f1 = eval_model(lora_model, emotion_test_loader, device)\n",
    "print(f\"LoRA Fine-Tuning - Test loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}, F1 score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Task  Training Time  CO2 Emissions  Test Loss  Accuracy  F1 Score\n",
      "0  sentiment140     528.088084       0.025174   0.343413  0.886719  0.886717\n",
      "1          imdb    2023.450950       0.094632   0.289216  0.911000  0.910982\n",
      "2          news    1268.460714       0.059037   1.100891  0.714058  0.692104\n",
      "3       dbpedia    3242.169252       0.156761   0.052926  0.991000  0.990991\n",
      "4       emotion    3242.169252       0.156761   0.052926  0.991000  0.990991\n",
      "5       emotion    1087.735802       0.051928   0.171180  0.933500  0.889633\n"
     ]
    }
   ],
   "source": [
    "add_task_results(\n",
    "    task_name=\"emotion\", \n",
    "    training_time=total_time,\n",
    "    emissions=emissions,\n",
    "    test_loss=test_loss,\n",
    "    test_acc=test_acc,\n",
    "    test_f1=test_f1,\n",
    ")\n",
    "\n",
    "performance = pd.DataFrame(model_performance)\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 2490\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 277\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 3000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Ottenimento del dataset\n",
    "rte_dataset = load_dataset(\"glue\", \"rte\")\n",
    "print(rte_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 2213\n",
      "Validation: 277\n",
      "Test: 277\n",
      "\n",
      "Distribuzione delle etichette:\n",
      "Train: Counter({0: 1115, 1: 1098})\n",
      "Validation: Counter({0: 140, 1: 137})\n",
      "Test: Counter({0: 140, 1: 137})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "rte_train_data = pd.DataFrame(rte_dataset[\"train\"])\n",
    "rte_val_data = pd.DataFrame(rte_dataset[\"validation\"])\n",
    "\n",
    "rte_data = Dataset.from_pandas(pd.concat([rte_train_data, rte_val_data], ignore_index=True))\n",
    "rte_data = rte_data.shuffle(seed=42)\n",
    "\n",
    "rte_temp_sentences1, rte_test_sentences1, rte_temp_sentences2, rte_test_sentences2,  rte_temp_labels, rte_test_labels = train_test_split(\n",
    "                                                rte_data['sentence1'],\n",
    "                                                rte_data['sentence2'],\n",
    "                                                rte_data['label'], \n",
    "                                                test_size=0.1, \n",
    "                                                random_state=42,\n",
    "                                                stratify=rte_data['label'])\n",
    "\n",
    "rte_train_sentences1, rte_val_sentences1, rte_train_sentences2, rte_val_sentences2, rte_train_labels, rte_val_labels = train_test_split(\n",
    "                                                rte_temp_sentences1,\n",
    "                                                rte_temp_sentences2,\n",
    "                                                rte_temp_labels,\n",
    "                                                test_size=0.1111,\n",
    "                                                random_state=42,\n",
    "                                                stratify=rte_temp_labels)\n",
    "\n",
    "print(f\"Train: {len(rte_train_sentences1)}\")\n",
    "print(f\"Validation: {len(rte_val_sentences1)}\")\n",
    "print(f\"Test: {len(rte_test_sentences1)}\")\n",
    "\n",
    "# Verifica distribuzione delle etichette\n",
    "print(\"\\nDistribuzione delle etichette:\")\n",
    "print(f\"Train: {Counter(rte_train_labels)}\")\n",
    "print(f\"Validation: {Counter(rte_val_labels)}\")\n",
    "print(f\"Test: {Counter(rte_test_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class NLIDataset(Dataset):\n",
    "\n",
    "    def __init__(self, sentences1, sentences2 , labels, tokenizer, max_len):\n",
    "        self.sentences1 = sentences1\n",
    "        self.sentences2 = sentences2\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentences1)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        sentence1 = self.sentences1[index]\n",
    "        sentence2 = self.sentences2[index]\n",
    "        label = self.labels[index]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            sentence1,\n",
    "            sentence2,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True,\n",
    "            padding=\"max_length\",\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt')\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'token_type_ids': encoding[\"token_type_ids\"].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 256\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Inizializzo il Tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Ottiengo i dataset\n",
    "rte_training_data = NLIDataset(\n",
    "                           sentences1 = rte_train_sentences1,\n",
    "                           sentences2 = rte_train_sentences2,\n",
    "                           labels = rte_train_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)\n",
    "\n",
    "rte_validation_data = NLIDataset(\n",
    "                           sentences1 = rte_val_sentences1,\n",
    "                           sentences2 = rte_val_sentences2,\n",
    "                           labels = rte_val_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)\n",
    "\n",
    "rte_test_data = NLIDataset(\n",
    "                           sentences1 = rte_test_sentences1,\n",
    "                           sentences2 = rte_test_sentences2,\n",
    "                           labels = rte_test_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,769,472 || all params: 126,416,642 || trainable%: 1.3997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): RobertaForSequenceClassification(\n",
       "      (roberta): RobertaModel(\n",
       "        (embeddings): RobertaEmbeddings(\n",
       "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): RobertaEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSdpaSelfAttention(\n",
       "                  (query): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.3, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (key): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.3, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (value): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.3, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=32, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=32, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (classifier): RobertaClassificationHead(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Pretrained model\n",
    "lora_model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2)\n",
    "\n",
    "# LoRA config\n",
    "lora_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=256,\n",
    "    lora_dropout=0.3,\n",
    "    target_modules=[\"query\", \"key\", \"value\"],  \n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "lora_model = get_peft_model(lora_model, lora_config)\n",
    "lora_model.print_trainable_parameters()\n",
    "lora_model.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in lora_model.named_parameters():\n",
    "    if \"classifier\" in name:\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametri principali\n",
    "learning_rate = 1e-4\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Creo i DataLoader\n",
    "rte_train_loader = DataLoader(rte_training_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "rte_val_loader = DataLoader(rte_validation_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "rte_test_loader = DataLoader(rte_test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "total_steps = len(rte_train_loader) * EPOCHS\n",
    "\n",
    "# Ottimizzatore\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, lora_model.parameters()), lr = learning_rate)\n",
    "\n",
    "\n",
    "# Scheduler\n",
    "scheduler = transformers.get_cosine_schedule_with_warmup(optimizer = optimizer,\n",
    "                                                       num_warmup_steps = 0,\n",
    "                                                       num_training_steps = total_steps) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history, total_time, emission = train_and_evaluate_model(\n",
    "    lora_model,\"rte\", rte_train_loader, rte_val_loader, optimizer, scheduler, device, epochs= EPOCHS\n",
    ") \n",
    "print(f\"\\nBERT with LoRA Training Time: {total_time:.2f} seconds, {total_time/60:.2f} minutes.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 9/9 [00:01<00:00,  5.15it/s, accuracy=0.718, loss=0.579]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA Fine-Tuning - Test loss: 0.5786, Accuracy: 0.7184, F1 score: 0.7153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lora_model.load_state_dict(torch.load(\"rte_best_model_state.bin\"))\n",
    "test_loss, test_acc, test_f1 = eval_model(lora_model, rte_test_loader, device)\n",
    "print(f\"LoRA Fine-Tuning - Test loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}, F1 score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Task  Training Time  CO2 Emissions  Test Loss  Accuracy  F1 Score\n",
      "0  rte      297.86347       0.014207    0.57864  0.718412  0.715291\n"
     ]
    }
   ],
   "source": [
    "add_task_results(\n",
    "    task_name=\"rte\", \n",
    "    training_time=total_time,\n",
    "    emissions=emission,\n",
    "    test_loss=test_loss,\n",
    "    test_acc=test_acc,\n",
    "    test_f1=test_f1,\n",
    ")\n",
    "\n",
    "performance = pd.DataFrame(model_performance)\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QQP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question1', 'question2', 'label', 'idx'],\n",
      "        num_rows: 363846\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['question1', 'question2', 'label', 'idx'],\n",
      "        num_rows: 40430\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['question1', 'question2', 'label', 'idx'],\n",
      "        num_rows: 390965\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Ottenimento del dataset\n",
    "qqp_dataset = load_dataset(\"glue\", \"qqp\")\n",
    "print(qqp_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensioni dei set:\n",
      "Train: 20000\n",
      "Validation: 5000\n",
      "Test: 5000\n",
      "\n",
      "Distribuzione delle etichette:\n",
      "Train: Counter({1: 10000, 0: 10000})\n",
      "Validation: Counter({0: 2500, 1: 2500})\n",
      "Test: Counter({0: 2500, 1: 2500})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "from collections import Counter\n",
    "from datasets import Dataset\n",
    "\n",
    "def balance_dataset(dataset, num_example):\n",
    "    class_0 = [example for example in dataset if example[\"label\"] == 0][:num_example]\n",
    "    class_1 = [example for example in dataset if example[\"label\"] == 1][:num_example]\n",
    "\n",
    "    balanced_data = class_0 + class_1\n",
    "\n",
    "    balanced_dataset = Dataset.from_list(balanced_data)\n",
    "    balanced_dataset = balanced_dataset.shuffle(seed=42)\n",
    "\n",
    "    return balanced_dataset \n",
    " \n",
    "\n",
    "\n",
    "def get_val_test_set(dataset, val_size, test_size):\n",
    "    class_0 = [example for example in dataset if example[\"label\"] == 0]\n",
    "    class_1 = [example for example in dataset if example[\"label\"] == 1]    \n",
    "\n",
    "    val_set = class_0[:val_size//2] + class_1[:val_size//2]\n",
    "    test_set = class_0[val_size//2:val_size//2 + test_size//2] + class_1[val_size//2:val_size//2 + test_size//2]\n",
    "\n",
    "    val_set = Dataset.from_dict({k: [example[k] for example in val_set] for k in val_set[0]})\n",
    "    test_set = Dataset.from_dict({k: [example[k] for example in test_set] for k in test_set[0]})\n",
    "    \n",
    "    val_set = val_set.shuffle(seed=42)\n",
    "    test_set = test_set.shuffle(seed=42)\n",
    "\n",
    "    return val_set, test_set\n",
    "\n",
    "\n",
    "qqp_train_data = qqp_dataset[\"train\"]\n",
    "qqp_val_test_data = qqp_dataset[\"validation\"]\n",
    "\n",
    "qqp_train_data = balance_dataset(qqp_train_data,10000)\n",
    "qqp_val_data, qqp_test_data  =  get_val_test_set(qqp_val_test_data, 5000, 5000)\n",
    "\n",
    "qqp_train_questions1, qqp_train_questions2, qqp_train_labels = qqp_train_data['question1'],  qqp_train_data['question2'], qqp_train_data['label']\n",
    "qqp_val_questions1, qqp_val_questions2, qqp_val_labels = qqp_val_data['question1'],  qqp_val_data['question2'], qqp_val_data['label']\n",
    "qqp_test_questions1, qqp_test_questions2, qqp_test_labels = qqp_test_data['question1'],  qqp_test_data['question2'], qqp_test_data['label']\n",
    "\n",
    "\n",
    "print(\"Dimensioni dei set:\")\n",
    "print(f\"Train: {len(qqp_train_questions1)}\")\n",
    "print(f\"Validation: {len(qqp_val_questions1)}\")\n",
    "print(f\"Test: {len(qqp_test_questions1)}\")\n",
    "\n",
    "print(\"\\nDistribuzione delle etichette:\")\n",
    "print(f\"Train: {Counter(qqp_train_labels)}\")\n",
    "print(f\"Validation: {Counter(qqp_val_labels)}\")\n",
    "print(f\"Test: {Counter(qqp_test_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 256\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Inizializzo il Tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Ottiengo i dataset\n",
    "qqp_training_data = NLIDataset(\n",
    "                           sentences1 = qqp_train_questions1,\n",
    "                           sentences2 = qqp_train_questions2,\n",
    "                           labels = qqp_train_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)\n",
    "\n",
    "qqp_validation_data = NLIDataset(\n",
    "                           sentences1 = qqp_val_questions1,\n",
    "                           sentences2 = qqp_val_questions2,\n",
    "                           labels = qqp_val_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)\n",
    "\n",
    "qqp_test_data = NLIDataset(\n",
    "                           sentences1 = qqp_test_questions1,\n",
    "                           sentences2 = qqp_test_questions2,\n",
    "                           labels = qqp_test_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 125,531,906 || trainable%: 0.7048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): RobertaForSequenceClassification(\n",
       "      (roberta): RobertaModel(\n",
       "        (embeddings): RobertaEmbeddings(\n",
       "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): RobertaEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSdpaSelfAttention(\n",
       "                  (query): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.3, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (key): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.3, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (value): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.3, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (classifier): RobertaClassificationHead(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Pretrained model\n",
    "lora_model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2)\n",
    "\n",
    "# LoRA config\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=128,\n",
    "    lora_dropout=0.3,\n",
    "    target_modules=[\"query\", \"key\", \"value\"],  \n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "lora_model = get_peft_model(lora_model, lora_config)\n",
    "lora_model.print_trainable_parameters()\n",
    "lora_model.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in lora_model.named_parameters():\n",
    "    if \"classifier\" in name:\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametri principali\n",
    "learning_rate = 1e-4\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Creo i DataLoader\n",
    "qqp_train_loader = DataLoader(qqp_training_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "qqp_val_loader = DataLoader(qqp_validation_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "qqp_test_loader = DataLoader(qqp_test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "total_steps = len(qqp_train_loader) * EPOCHS\n",
    "\n",
    "# Ottimizzatore\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, lora_model.parameters()), lr = learning_rate)\n",
    "\n",
    "\n",
    "# Scheduler\n",
    "scheduler = transformers.get_cosine_schedule_with_warmup(optimizer = optimizer,\n",
    "                                                       num_warmup_steps = 0,\n",
    "                                                       num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 12:53:00] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 12:53:00] [setup] CPU Tracking...\n",
      "[codecarbon INFO @ 12:53:00] Tracking Intel CPU via RAPL interface\n",
      "[codecarbon INFO @ 12:53:01] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 12:53:01] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 12:53:01] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:53:01] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:53:01] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:53:01] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:53:01] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:53:01] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:53:01] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon WARNING @ 12:53:01] You have 8 GPUs but we will monitor only 1 of them. Check your configuration.\n",
      "[codecarbon INFO @ 12:53:01] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 12:53:01]   Platform system: Linux-6.8.0-56-generic-x86_64-with-glibc2.39\n",
      "[codecarbon INFO @ 12:53:01]   Python version: 3.12.3\n",
      "[codecarbon INFO @ 12:53:01]   CodeCarbon version: 2.8.3\n",
      "[codecarbon INFO @ 12:53:01]   Available RAM : 754.342 GB\n",
      "[codecarbon INFO @ 12:53:01]   CPU count: 96\n",
      "[codecarbon INFO @ 12:53:01]   CPU model: Intel(R) Xeon(R) Gold 6248R CPU @ 3.00GHz\n",
      "[codecarbon INFO @ 12:53:01]   GPU count: 1\n",
      "[codecarbon INFO @ 12:53:01]   GPU model: 8 x NVIDIA A30 BUT only tracking these GPU ids : [6]\n",
      "[codecarbon INFO @ 12:53:05] Saving emissions data to file /home/notebook/riccardo_cantini/tesisti/Dagostino/carbon_emissions/emissions.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :   6%|▌         | 38/625 [00:14<03:49,  2.56it/s, accuracy=0.55, loss=0.689][codecarbon INFO @ 12:53:20] Energy consumed for RAM : 0.001182 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 12:53:20] Energy consumed for all CPUs : 0.000348 kWh. Total CPU Power : 83.27014937700642 W\n",
      "[codecarbon INFO @ 12:53:20] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:53:20] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:53:20] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:53:20] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:53:20] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:53:20] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:53:20] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:53:20] Energy consumed for all GPUs : 0.000623 kWh. Total GPU Power : 149.11945732113983 W\n",
      "[codecarbon INFO @ 12:53:20] 0.002153 kWh of electricity used since the beginning.\n",
      "Training  :  12%|█▏        | 76/625 [00:29<03:34,  2.56it/s, accuracy=0.628, loss=0.641][codecarbon INFO @ 12:53:35] Energy consumed for RAM : 0.002356 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 12:53:35] Energy consumed for all CPUs : 0.000697 kWh. Total CPU Power : 83.96254291751609 W\n",
      "[codecarbon INFO @ 12:53:35] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:53:35] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:53:35] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:53:35] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:53:35] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:53:35] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:53:35] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:53:35] Energy consumed for all GPUs : 0.001247 kWh. Total GPU Power : 150.2331316610153 W\n",
      "[codecarbon INFO @ 12:53:35] 0.004300 kWh of electricity used since the beginning.\n",
      "Training  :  18%|█▊        | 114/625 [00:44<03:19,  2.56it/s, accuracy=0.667, loss=0.6][codecarbon INFO @ 12:53:50] Energy consumed for RAM : 0.003531 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 12:53:50] Energy consumed for all CPUs : 0.001047 kWh. Total CPU Power : 84.26057064505802 W\n",
      "[codecarbon INFO @ 12:53:50] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:53:50] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:53:50] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:53:50] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:53:50] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:53:50] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:53:50] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:53:50] Energy consumed for all GPUs : 0.001870 kWh. Total GPU Power : 150.03491298388585 W\n",
      "[codecarbon INFO @ 12:53:50] 0.006448 kWh of electricity used since the beginning.\n",
      "Training  :  24%|██▍       | 153/625 [00:59<03:05,  2.55it/s, accuracy=0.696, loss=0.57][codecarbon INFO @ 12:54:05] Energy consumed for RAM : 0.004706 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 12:54:05] Energy consumed for all CPUs : 0.001397 kWh. Total CPU Power : 84.29838081742969 W\n",
      "[codecarbon INFO @ 12:54:05] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:54:05] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:54:05] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:54:05] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:54:05] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:54:05] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:54:05] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:54:05] Energy consumed for all GPUs : 0.002501 kWh. Total GPU Power : 151.7466635794834 W\n",
      "[codecarbon INFO @ 12:54:05] 0.008604 kWh of electricity used since the beginning.\n",
      "Training  :  31%|███       | 191/625 [01:14<02:50,  2.54it/s, accuracy=0.717, loss=0.545][codecarbon INFO @ 12:54:20] Energy consumed for RAM : 0.005881 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 12:54:20] Energy consumed for all CPUs : 0.001747 kWh. Total CPU Power : 84.20530274213121 W\n",
      "[codecarbon INFO @ 12:54:20] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:54:20] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:54:20] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:54:20] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:54:20] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:54:20] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:54:20] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:54:20] Energy consumed for all GPUs : 0.003131 kWh. Total GPU Power : 151.58766884326693 W\n",
      "[codecarbon INFO @ 12:54:20] 0.010758 kWh of electricity used since the beginning.\n",
      "Training  :  37%|███▋      | 229/625 [01:29<02:35,  2.54it/s, accuracy=0.727, loss=0.532][codecarbon INFO @ 12:54:35] Energy consumed for RAM : 0.007056 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 12:54:35] Energy consumed for all CPUs : 0.002096 kWh. Total CPU Power : 84.23491815919678 W\n",
      "[codecarbon INFO @ 12:54:35] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:54:35] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:54:35] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:54:35] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:54:35] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:54:35] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:54:35] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:54:35] Energy consumed for all GPUs : 0.003758 kWh. Total GPU Power : 151.03876591034037 W\n",
      "[codecarbon INFO @ 12:54:35] 0.012910 kWh of electricity used since the beginning.\n",
      "Training  :  43%|████▎     | 267/625 [01:44<02:21,  2.54it/s, accuracy=0.736, loss=0.521][codecarbon INFO @ 12:54:50] Energy consumed for RAM : 0.008231 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 12:54:50] Energy consumed for all CPUs : 0.002445 kWh. Total CPU Power : 83.86723888635649 W\n",
      "[codecarbon INFO @ 12:54:50] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:54:50] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:54:50] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:54:50] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:54:50] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:54:50] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:54:50] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:54:50] Energy consumed for all GPUs : 0.004394 kWh. Total GPU Power : 153.18697594207012 W\n",
      "[codecarbon INFO @ 12:54:50] 0.015070 kWh of electricity used since the beginning.\n",
      "Training  :  49%|████▉     | 305/625 [01:59<02:06,  2.53it/s, accuracy=0.744, loss=0.509][codecarbon INFO @ 12:55:05] Energy consumed for RAM : 0.009406 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 12:55:05] Energy consumed for all CPUs : 0.002795 kWh. Total CPU Power : 84.39999409439292 W\n",
      "[codecarbon INFO @ 12:55:05] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:55:05] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:55:05] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:55:05] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:55:05] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:55:05] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:55:05] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:55:05] Energy consumed for all GPUs : 0.005035 kWh. Total GPU Power : 154.31608943619173 W\n",
      "[codecarbon INFO @ 12:55:05] 0.017237 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 12:55:05] 0.047467 g.CO2eq/s mean an estimation of 1,496.9164159618538 kg.CO2eq/year\n",
      "Training  :  55%|█████▍    | 343/625 [02:14<01:51,  2.53it/s, accuracy=0.751, loss=0.501][codecarbon INFO @ 12:55:20] Energy consumed for RAM : 0.010581 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 12:55:20] Energy consumed for all CPUs : 0.003144 kWh. Total CPU Power : 83.95568425520682 W\n",
      "[codecarbon INFO @ 12:55:20] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:55:20] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:55:20] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:55:20] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:55:20] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:55:20] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:55:20] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:55:20] Energy consumed for all GPUs : 0.005675 kWh. Total GPU Power : 153.87447441755177 W\n",
      "[codecarbon INFO @ 12:55:20] 0.019399 kWh of electricity used since the beginning.\n",
      "Training  :  61%|██████    | 381/625 [02:29<01:36,  2.52it/s, accuracy=0.756, loss=0.495][codecarbon INFO @ 12:55:35] Energy consumed for RAM : 0.011755 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 12:55:35] Energy consumed for all CPUs : 0.003496 kWh. Total CPU Power : 84.64623520353516 W\n",
      "[codecarbon INFO @ 12:55:35] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:55:35] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:55:35] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:55:35] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:55:35] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:55:35] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:55:35] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:55:35] Energy consumed for all GPUs : 0.006321 kWh. Total GPU Power : 155.6622571844986 W\n",
      "[codecarbon INFO @ 12:55:35] 0.021572 kWh of electricity used since the beginning.\n",
      "Training  :  62%|██████▏   | 386/625 [02:31<01:34,  2.52it/s, accuracy=0.757, loss=0.495]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training  :  67%|██████▋   | 419/625 [02:44<01:21,  2.52it/s, accuracy=0.761, loss=0.489][codecarbon INFO @ 12:55:50] Energy consumed for RAM : 0.012930 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 12:55:50] Energy consumed for all CPUs : 0.003846 kWh. Total CPU Power : 84.40500810838867 W\n",
      "[codecarbon INFO @ 12:55:50] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:55:50] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:55:50] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:55:50] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:55:50] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:55:50] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:55:50] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:55:50] Energy consumed for all GPUs : 0.006969 kWh. Total GPU Power : 156.09771777075892 W\n",
      "[codecarbon INFO @ 12:55:50] 0.023746 kWh of electricity used since the beginning.\n",
      "Training  :  73%|███████▎  | 456/625 [02:59<01:07,  2.51it/s, accuracy=0.763, loss=0.487][codecarbon INFO @ 12:56:05] Energy consumed for RAM : 0.014104 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 12:56:05] Energy consumed for all CPUs : 0.004196 kWh. Total CPU Power : 84.32643158108843 W\n",
      "[codecarbon INFO @ 12:56:05] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:56:05] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:56:05] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:56:05] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:56:05] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:56:05] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:56:05] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:56:05] Energy consumed for all GPUs : 0.007616 kWh. Total GPU Power : 155.6784073746484 W\n",
      "[codecarbon INFO @ 12:56:05] 0.025916 kWh of electricity used since the beginning.\n",
      "Training  :  79%|███████▉  | 494/625 [03:14<00:52,  2.51it/s, accuracy=0.766, loss=0.484][codecarbon INFO @ 12:56:20] Energy consumed for RAM : 0.015279 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 12:56:20] Energy consumed for all CPUs : 0.004548 kWh. Total CPU Power : 84.68124019673817 W\n",
      "[codecarbon INFO @ 12:56:20] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:56:20] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:56:20] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:56:20] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:56:20] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:56:20] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:56:20] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:56:20] Energy consumed for all GPUs : 0.008268 kWh. Total GPU Power : 156.9581459211218 W\n",
      "[codecarbon INFO @ 12:56:20] 0.028095 kWh of electricity used since the beginning.\n",
      "Training  :  85%|████████▌ | 532/625 [03:29<00:37,  2.50it/s, accuracy=0.77, loss=0.48][codecarbon INFO @ 12:56:35] Energy consumed for RAM : 0.016454 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 12:56:35] Energy consumed for all CPUs : 0.004899 kWh. Total CPU Power : 84.48747555714036 W\n",
      "[codecarbon INFO @ 12:56:35] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:56:35] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:56:35] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:56:35] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:56:35] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:56:35] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:56:35] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:56:35] Energy consumed for all GPUs : 0.008914 kWh. Total GPU Power : 155.64678447863741 W\n",
      "[codecarbon INFO @ 12:56:35] 0.030266 kWh of electricity used since the beginning.\n",
      "Training  :  91%|█████████ | 569/625 [03:44<00:22,  2.50it/s, accuracy=0.772, loss=0.476][codecarbon INFO @ 12:56:50] Energy consumed for RAM : 0.017628 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 12:56:50] Energy consumed for all CPUs : 0.005250 kWh. Total CPU Power : 84.47137098344984 W\n",
      "[codecarbon INFO @ 12:56:50] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:56:50] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:56:50] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:56:50] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:56:50] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:56:50] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:56:50] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:56:50] Energy consumed for all GPUs : 0.009563 kWh. Total GPU Power : 156.40565778104127 W\n",
      "[codecarbon INFO @ 12:56:50] 0.032441 kWh of electricity used since the beginning.\n",
      "Training  :  97%|█████████▋| 607/625 [03:59<00:07,  2.50it/s, accuracy=0.775, loss=0.47][codecarbon INFO @ 12:57:05] Energy consumed for RAM : 0.018803 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 12:57:05] Energy consumed for all CPUs : 0.005600 kWh. Total CPU Power : 84.44453071743156 W\n",
      "[codecarbon INFO @ 12:57:05] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:57:05] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:57:05] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:57:05] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:57:05] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:57:05] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:57:05] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:57:05] Energy consumed for all GPUs : 0.010210 kWh. Total GPU Power : 155.68320248746215 W\n",
      "[codecarbon INFO @ 12:57:05] 0.034614 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 12:57:05] 0.047886 g.CO2eq/s mean an estimation of 1,510.1295854531952 kg.CO2eq/year\n",
      "Training  : 100%|██████████| 625/625 [04:07<00:00,  2.53it/s, accuracy=0.777, loss=0.469]\n",
      "Evaluating:  26%|██▌       | 41/157 [00:07<00:21,  5.29it/s, accuracy=0.825, loss=0.404][codecarbon INFO @ 12:57:20] Energy consumed for RAM : 0.019977 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 12:57:20] Energy consumed for all CPUs : 0.005951 kWh. Total CPU Power : 84.53872071739292 W\n",
      "[codecarbon INFO @ 12:57:20] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:57:20] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:57:20] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:57:20] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:57:20] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:57:20] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:57:20] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:57:20] Energy consumed for all GPUs : 0.010860 kWh. Total GPU Power : 156.58729754198663 W\n",
      "[codecarbon INFO @ 12:57:20] 0.036789 kWh of electricity used since the beginning.\n",
      "Evaluating:  76%|███████▋  | 120/157 [00:22<00:07,  5.26it/s, accuracy=0.83, loss=0.388][codecarbon INFO @ 12:57:35] Energy consumed for RAM : 0.021152 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 12:57:35] Energy consumed for all CPUs : 0.006303 kWh. Total CPU Power : 84.71366904143302 W\n",
      "[codecarbon INFO @ 12:57:35] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:57:35] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:57:35] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:57:35] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:57:35] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:57:35] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:57:35] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:57:35] Energy consumed for all GPUs : 0.011519 kWh. Total GPU Power : 158.49346799313943 W\n",
      "[codecarbon INFO @ 12:57:35] 0.038974 kWh of electricity used since the beginning.\n",
      "Evaluating: 100%|██████████| 157/157 [00:29<00:00,  5.30it/s, accuracy=0.829, loss=0.392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :   3%|▎         | 19/625 [00:07<03:58,  2.54it/s, accuracy=0.826, loss=0.372][codecarbon INFO @ 12:57:50] Energy consumed for RAM : 0.022327 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 12:57:50] Energy consumed for all CPUs : 0.006654 kWh. Total CPU Power : 84.37594000483772 W\n",
      "[codecarbon INFO @ 12:57:50] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:57:50] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:57:50] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:57:50] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:57:50] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:57:50] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:57:50] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:57:50] Energy consumed for all GPUs : 0.012158 kWh. Total GPU Power : 153.91239950547927 W\n",
      "[codecarbon INFO @ 12:57:50] 0.041138 kWh of electricity used since the beginning.\n",
      "Training  :   9%|▉         | 57/625 [00:22<03:43,  2.54it/s, accuracy=0.825, loss=0.404][codecarbon INFO @ 12:58:05] Energy consumed for RAM : 0.023501 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 12:58:05] Energy consumed for all CPUs : 0.007004 kWh. Total CPU Power : 84.3450309564098 W\n",
      "[codecarbon INFO @ 12:58:05] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:58:05] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:58:05] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:58:05] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:58:05] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:58:05] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:58:05] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:58:05] Energy consumed for all GPUs : 0.012815 kWh. Total GPU Power : 158.29283499773345 W\n",
      "[codecarbon INFO @ 12:58:05] 0.043321 kWh of electricity used since the beginning.\n",
      "Training  :  15%|█▌        | 95/625 [00:37<03:28,  2.54it/s, accuracy=0.821, loss=0.407][codecarbon INFO @ 12:58:20] Energy consumed for RAM : 0.024676 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 12:58:20] Energy consumed for all CPUs : 0.007355 kWh. Total CPU Power : 84.4585587439426 W\n",
      "[codecarbon INFO @ 12:58:20] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:58:20] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:58:20] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:58:20] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:58:20] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:58:20] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:58:20] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:58:20] Energy consumed for all GPUs : 0.013474 kWh. Total GPU Power : 158.4909556164251 W\n",
      "[codecarbon INFO @ 12:58:20] 0.045505 kWh of electricity used since the beginning.\n",
      "Training  :  21%|██▏       | 133/625 [00:52<03:14,  2.53it/s, accuracy=0.825, loss=0.404][codecarbon INFO @ 12:58:35] Energy consumed for RAM : 0.025851 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 12:58:35] Energy consumed for all CPUs : 0.007706 kWh. Total CPU Power : 84.52029705183764 W\n",
      "[codecarbon INFO @ 12:58:35] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:58:35] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:58:35] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:58:35] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:58:35] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:58:35] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:58:35] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:58:35] Energy consumed for all GPUs : 0.014129 kWh. Total GPU Power : 157.69691539536723 W\n",
      "[codecarbon INFO @ 12:58:35] 0.047685 kWh of electricity used since the beginning.\n",
      "Training  :  27%|██▋       | 171/625 [01:07<02:59,  2.53it/s, accuracy=0.826, loss=0.402][codecarbon INFO @ 12:58:50] Energy consumed for RAM : 0.027026 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 12:58:50] Energy consumed for all CPUs : 0.008056 kWh. Total CPU Power : 84.24545872307154 W\n",
      "[codecarbon INFO @ 12:58:50] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:58:50] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:58:50] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:58:50] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:58:50] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:58:50] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:58:50] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:58:50] Energy consumed for all GPUs : 0.014787 kWh. Total GPU Power : 158.5635256719665 W\n",
      "[codecarbon INFO @ 12:58:50] 0.049869 kWh of electricity used since the beginning.\n",
      "Training  :  33%|███▎      | 209/625 [01:22<02:44,  2.53it/s, accuracy=0.824, loss=0.407][codecarbon INFO @ 12:59:05] Energy consumed for RAM : 0.028201 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 12:59:05] Energy consumed for all CPUs : 0.008406 kWh. Total CPU Power : 84.30547515191795 W\n",
      "[codecarbon INFO @ 12:59:05] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:59:05] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:59:05] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:59:05] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:59:05] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:59:05] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:59:05] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:59:05] Energy consumed for all GPUs : 0.015441 kWh. Total GPU Power : 157.24976442011445 W\n",
      "[codecarbon INFO @ 12:59:05] 0.052048 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 12:59:05] 0.048051 g.CO2eq/s mean an estimation of 1,515.332864103698 kg.CO2eq/year\n",
      "Training  :  40%|███▉      | 247/625 [01:37<02:29,  2.53it/s, accuracy=0.824, loss=0.406][codecarbon INFO @ 12:59:20] Energy consumed for RAM : 0.029376 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 12:59:20] Energy consumed for all CPUs : 0.008755 kWh. Total CPU Power : 84.14383713356017 W\n",
      "[codecarbon INFO @ 12:59:20] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:59:20] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:59:20] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:59:20] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:59:20] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:59:20] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:59:20] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:59:20] Energy consumed for all GPUs : 0.016098 kWh. Total GPU Power : 158.1580687040572 W\n",
      "[codecarbon INFO @ 12:59:20] 0.054229 kWh of electricity used since the beginning.\n",
      "Training  :  46%|████▌     | 285/625 [01:52<02:14,  2.52it/s, accuracy=0.823, loss=0.402][codecarbon INFO @ 12:59:35] Energy consumed for RAM : 0.030551 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 12:59:35] Energy consumed for all CPUs : 0.009105 kWh. Total CPU Power : 84.12942560784882 W\n",
      "[codecarbon INFO @ 12:59:35] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:59:35] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:59:35] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:59:35] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:59:35] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:59:35] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:59:35] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:59:35] Energy consumed for all GPUs : 0.016752 kWh. Total GPU Power : 157.41373367687373 W\n",
      "[codecarbon INFO @ 12:59:35] 0.056408 kWh of electricity used since the beginning.\n",
      "Training  :  52%|█████▏    | 323/625 [02:07<01:59,  2.52it/s, accuracy=0.824, loss=0.399][codecarbon INFO @ 12:59:50] Energy consumed for RAM : 0.031726 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 12:59:50] Energy consumed for all CPUs : 0.009455 kWh. Total CPU Power : 84.25654071893929 W\n",
      "[codecarbon INFO @ 12:59:50] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:59:50] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:59:50] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:59:50] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:59:50] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:59:50] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:59:50] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 12:59:50] Energy consumed for all GPUs : 0.017409 kWh. Total GPU Power : 158.15328975552504 W\n",
      "[codecarbon INFO @ 12:59:50] 0.058589 kWh of electricity used since the beginning.\n",
      "Training  :  58%|█████▊    | 361/625 [02:22<01:44,  2.52it/s, accuracy=0.825, loss=0.398][codecarbon INFO @ 13:00:05] Energy consumed for RAM : 0.032901 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:00:05] Energy consumed for all CPUs : 0.009805 kWh. Total CPU Power : 84.37024723538812 W\n",
      "[codecarbon INFO @ 13:00:05] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:00:05] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:00:05] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:00:05] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:00:05] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:00:05] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:00:05] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:00:05] Energy consumed for all GPUs : 0.018065 kWh. Total GPU Power : 157.86821403238255 W\n",
      "[codecarbon INFO @ 13:00:05] 0.060771 kWh of electricity used since the beginning.\n",
      "Training  :  62%|██████▏   | 385/625 [02:32<01:35,  2.52it/s, accuracy=0.827, loss=0.396]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training  :  64%|██████▎   | 398/625 [02:37<01:30,  2.51it/s, accuracy=0.826, loss=0.397][codecarbon INFO @ 13:00:20] Energy consumed for RAM : 0.034075 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:00:20] Energy consumed for all CPUs : 0.010157 kWh. Total CPU Power : 84.5676392842183 W\n",
      "[codecarbon INFO @ 13:00:20] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:00:20] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:00:20] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:00:20] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:00:20] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:00:20] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:00:20] GPU number 7 will not be monitored, at your request.\n",
      "Training  :  64%|██████▍   | 399/625 [02:37<01:29,  2.51it/s, accuracy=0.826, loss=0.398][codecarbon INFO @ 13:00:20] Energy consumed for all GPUs : 0.018716 kWh. Total GPU Power : 156.84241086535224 W\n",
      "[codecarbon INFO @ 13:00:20] 0.062948 kWh of electricity used since the beginning.\n",
      "Training  :  70%|██████▉   | 436/625 [02:52<01:15,  2.51it/s, accuracy=0.827, loss=0.396][codecarbon INFO @ 13:00:35] Energy consumed for RAM : 0.035250 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:00:35] Energy consumed for all CPUs : 0.010509 kWh. Total CPU Power : 84.82292005159715 W\n",
      "[codecarbon INFO @ 13:00:35] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:00:35] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:00:35] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:00:35] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:00:35] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:00:35] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:00:35] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:00:35] Energy consumed for all GPUs : 0.019371 kWh. Total GPU Power : 157.57904196052175 W\n",
      "[codecarbon INFO @ 13:00:35] 0.065130 kWh of electricity used since the beginning.\n",
      "Training  :  76%|███████▌  | 474/625 [03:07<01:00,  2.51it/s, accuracy=0.829, loss=0.392][codecarbon INFO @ 13:00:50] Energy consumed for RAM : 0.036425 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:00:50] Energy consumed for all CPUs : 0.010860 kWh. Total CPU Power : 84.47168345739097 W\n",
      "[codecarbon INFO @ 13:00:50] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:00:50] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:00:50] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:00:50] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:00:50] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:00:50] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:00:50] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:00:50] Energy consumed for all GPUs : 0.020020 kWh. Total GPU Power : 156.36779364078456 W\n",
      "[codecarbon INFO @ 13:00:50] 0.067305 kWh of electricity used since the beginning.\n",
      "Training  :  82%|████████▏ | 511/625 [03:22<00:45,  2.51it/s, accuracy=0.83, loss=0.39][codecarbon INFO @ 13:01:05] Energy consumed for RAM : 0.037600 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:01:05] Energy consumed for all CPUs : 0.011212 kWh. Total CPU Power : 84.69437623772274 W\n",
      "[codecarbon INFO @ 13:01:05] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:01:05] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:01:05] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:01:05] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:01:05] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:01:05] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:01:05] GPU number 7 will not be monitored, at your request.\n",
      "Training  :  82%|████████▏ | 512/625 [03:22<00:45,  2.51it/s, accuracy=0.83, loss=0.389][codecarbon INFO @ 13:01:05] Energy consumed for all GPUs : 0.020674 kWh. Total GPU Power : 157.48643988269055 W\n",
      "[codecarbon INFO @ 13:01:05] 0.069486 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 13:01:05] 0.048060 g.CO2eq/s mean an estimation of 1,515.6288854251407 kg.CO2eq/year\n",
      "Training  :  88%|████████▊ | 549/625 [03:37<00:30,  2.51it/s, accuracy=0.83, loss=0.389][codecarbon INFO @ 13:01:20] Energy consumed for RAM : 0.038775 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:01:20] Energy consumed for all CPUs : 0.011564 kWh. Total CPU Power : 84.89886425257016 W\n",
      "[codecarbon INFO @ 13:01:20] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:01:20] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:01:20] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:01:20] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:01:20] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:01:20] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:01:20] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:01:20] Energy consumed for all GPUs : 0.021328 kWh. Total GPU Power : 157.32002946132602 W\n",
      "[codecarbon INFO @ 13:01:20] 0.071668 kWh of electricity used since the beginning.\n",
      "Training  :  94%|█████████▍| 587/625 [03:52<00:15,  2.50it/s, accuracy=0.831, loss=0.388][codecarbon INFO @ 13:01:35] Energy consumed for RAM : 0.039950 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:01:35] Energy consumed for all CPUs : 0.011916 kWh. Total CPU Power : 84.67963900737169 W\n",
      "[codecarbon INFO @ 13:01:35] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:01:35] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:01:35] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:01:35] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:01:35] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:01:35] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:01:35] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:01:35] Energy consumed for all GPUs : 0.021976 kWh. Total GPU Power : 156.05634279484502 W\n",
      "[codecarbon INFO @ 13:01:35] 0.073842 kWh of electricity used since the beginning.\n",
      "Training  : 100%|█████████▉| 624/625 [04:07<00:00,  2.50it/s, accuracy=0.83, loss=0.389][codecarbon INFO @ 13:01:50] Energy consumed for RAM : 0.041124 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:01:50] Energy consumed for all CPUs : 0.012268 kWh. Total CPU Power : 84.68891208704878 W\n",
      "[codecarbon INFO @ 13:01:50] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:01:50] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:01:50] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:01:50] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:01:50] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:01:50] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:01:50] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:01:50] Energy consumed for all GPUs : 0.022630 kWh. Total GPU Power : 157.46951746639257 W\n",
      "[codecarbon INFO @ 13:01:50] 0.076022 kWh of electricity used since the beginning.\n",
      "Training  : 100%|██████████| 625/625 [04:07<00:00,  2.52it/s, accuracy=0.83, loss=0.389]\n",
      "Evaluating:  50%|████▉     | 78/157 [00:14<00:14,  5.30it/s, accuracy=0.836, loss=0.362][codecarbon INFO @ 13:02:05] Energy consumed for RAM : 0.042299 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:02:05] Energy consumed for all CPUs : 0.012620 kWh. Total CPU Power : 84.83915344926004 W\n",
      "[codecarbon INFO @ 13:02:05] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:02:05] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:02:05] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:02:05] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:02:05] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:02:05] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:02:05] GPU number 7 will not be monitored, at your request.\n",
      "Evaluating:  50%|█████     | 79/157 [00:14<00:14,  5.30it/s, accuracy=0.837, loss=0.36][codecarbon INFO @ 13:02:05] Energy consumed for all GPUs : 0.023287 kWh. Total GPU Power : 158.21467142674547 W\n",
      "[codecarbon INFO @ 13:02:05] 0.078205 kWh of electricity used since the beginning.\n",
      "Evaluating: 100%|██████████| 157/157 [00:29<00:00,  5.33it/s, accuracy=0.842, loss=0.356]\n",
      "[codecarbon INFO @ 13:02:20] Energy consumed for RAM : 0.043474 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:02:20] Energy consumed for all CPUs : 0.012971 kWh. Total CPU Power : 84.53470097581611 W\n",
      "[codecarbon INFO @ 13:02:20] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:02:20] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:02:20] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:02:20] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:02:20] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:02:20] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:02:20] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:02:20] Energy consumed for all GPUs : 0.023938 kWh. Total GPU Power : 156.72714775710912 W\n",
      "[codecarbon INFO @ 13:02:20] 0.080383 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :   6%|▌         | 37/625 [00:14<03:51,  2.54it/s, accuracy=0.834, loss=0.368][codecarbon INFO @ 13:02:35] Energy consumed for RAM : 0.044648 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:02:35] Energy consumed for all CPUs : 0.013320 kWh. Total CPU Power : 84.14710901010628 W\n",
      "[codecarbon INFO @ 13:02:35] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:02:35] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:02:35] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:02:35] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:02:35] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:02:35] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:02:35] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:02:35] Energy consumed for all GPUs : 0.024588 kWh. Total GPU Power : 156.419380885046 W\n",
      "[codecarbon INFO @ 13:02:35] 0.082556 kWh of electricity used since the beginning.\n",
      "Training  :  12%|█▏        | 75/625 [00:29<03:36,  2.54it/s, accuracy=0.839, loss=0.367][codecarbon INFO @ 13:02:50] Energy consumed for RAM : 0.045823 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:02:50] Energy consumed for all CPUs : 0.013669 kWh. Total CPU Power : 83.96962349996164 W\n",
      "[codecarbon INFO @ 13:02:50] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:02:50] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:02:50] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:02:50] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:02:50] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:02:50] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:02:50] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:02:50] Energy consumed for all GPUs : 0.025242 kWh. Total GPU Power : 157.5071474451776 W\n",
      "[codecarbon INFO @ 13:02:50] 0.084734 kWh of electricity used since the beginning.\n",
      "Training  :  18%|█▊        | 113/625 [00:44<03:21,  2.54it/s, accuracy=0.842, loss=0.358][codecarbon INFO @ 13:03:05] Energy consumed for RAM : 0.046999 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:03:05] Energy consumed for all CPUs : 0.014019 kWh. Total CPU Power : 84.07303396972893 W\n",
      "[codecarbon INFO @ 13:03:05] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:03:05] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:03:05] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:03:05] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:03:05] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:03:05] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:03:05] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:03:05] Energy consumed for all GPUs : 0.025901 kWh. Total GPU Power : 158.49633730814372 W\n",
      "[codecarbon INFO @ 13:03:05] 0.086918 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 13:03:05] 0.048040 g.CO2eq/s mean an estimation of 1,514.974774733885 kg.CO2eq/year\n",
      "Training  :  24%|██▍       | 151/625 [00:59<03:06,  2.54it/s, accuracy=0.843, loss=0.358][codecarbon INFO @ 13:03:20] Energy consumed for RAM : 0.048174 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:03:20] Energy consumed for all CPUs : 0.014367 kWh. Total CPU Power : 83.78945981594087 W\n",
      "[codecarbon INFO @ 13:03:20] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:03:20] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:03:20] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:03:20] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:03:20] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:03:20] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:03:20] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:03:20] Energy consumed for all GPUs : 0.026555 kWh. Total GPU Power : 157.60655587114152 W\n",
      "[codecarbon INFO @ 13:03:20] 0.089096 kWh of electricity used since the beginning.\n",
      "Training  :  30%|███       | 189/625 [01:14<02:52,  2.53it/s, accuracy=0.843, loss=0.36][codecarbon INFO @ 13:03:35] Energy consumed for RAM : 0.049349 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:03:35] Energy consumed for all CPUs : 0.014716 kWh. Total CPU Power : 83.99723045966172 W\n",
      "[codecarbon INFO @ 13:03:35] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:03:35] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:03:35] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:03:35] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:03:35] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:03:35] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:03:35] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:03:35] Energy consumed for all GPUs : 0.027212 kWh. Total GPU Power : 157.90242243213848 W\n",
      "[codecarbon INFO @ 13:03:35] 0.091276 kWh of electricity used since the beginning.\n",
      "Training  :  36%|███▋      | 227/625 [01:29<02:37,  2.53it/s, accuracy=0.846, loss=0.355][codecarbon INFO @ 13:03:50] Energy consumed for RAM : 0.050524 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:03:50] Energy consumed for all CPUs : 0.015065 kWh. Total CPU Power : 84.01242201599086 W\n",
      "[codecarbon INFO @ 13:03:50] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:03:50] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:03:50] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:03:50] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:03:50] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:03:50] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:03:50] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:03:50] Energy consumed for all GPUs : 0.027868 kWh. Total GPU Power : 158.01623687019165 W\n",
      "[codecarbon INFO @ 13:03:50] 0.093456 kWh of electricity used since the beginning.\n",
      "Training  :  42%|████▏     | 265/625 [01:44<02:22,  2.53it/s, accuracy=0.846, loss=0.352][codecarbon INFO @ 13:04:05] Energy consumed for RAM : 0.051698 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:04:05] Energy consumed for all CPUs : 0.015413 kWh. Total CPU Power : 83.78951115449223 W\n",
      "[codecarbon INFO @ 13:04:05] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:04:05] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:04:05] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:04:05] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:04:05] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:04:05] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:04:05] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:04:05] Energy consumed for all GPUs : 0.028519 kWh. Total GPU Power : 156.76727626056274 W\n",
      "[codecarbon INFO @ 13:04:05] 0.095630 kWh of electricity used since the beginning.\n",
      "Training  :  48%|████▊     | 303/625 [01:59<02:07,  2.52it/s, accuracy=0.847, loss=0.348][codecarbon INFO @ 13:04:20] Energy consumed for RAM : 0.052872 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:04:20] Energy consumed for all CPUs : 0.015761 kWh. Total CPU Power : 83.86189646037587 W\n",
      "[codecarbon INFO @ 13:04:20] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:04:20] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:04:20] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:04:20] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:04:20] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:04:20] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:04:20] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:04:20] Energy consumed for all GPUs : 0.029174 kWh. Total GPU Power : 157.88894131281458 W\n",
      "[codecarbon INFO @ 13:04:20] 0.097808 kWh of electricity used since the beginning.\n",
      "Training  :  55%|█████▍    | 341/625 [02:14<01:52,  2.52it/s, accuracy=0.848, loss=0.349][codecarbon INFO @ 13:04:35] Energy consumed for RAM : 0.054047 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:04:35] Energy consumed for all CPUs : 0.016108 kWh. Total CPU Power : 83.56207464580947 W\n",
      "[codecarbon INFO @ 13:04:35] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:04:35] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:04:35] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:04:35] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:04:35] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:04:35] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:04:35] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:04:35] Energy consumed for all GPUs : 0.029828 kWh. Total GPU Power : 157.37246849874083 W\n",
      "[codecarbon INFO @ 13:04:35] 0.099983 kWh of electricity used since the beginning.\n",
      "Training  :  55%|█████▍    | 342/625 [02:15<01:52,  2.52it/s, accuracy=0.848, loss=0.348]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training  :  60%|██████    | 378/625 [02:29<01:38,  2.52it/s, accuracy=0.849, loss=0.349][codecarbon INFO @ 13:04:50] Energy consumed for RAM : 0.055221 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:04:50] Energy consumed for all CPUs : 0.016454 kWh. Total CPU Power : 83.31081627446392 W\n",
      "[codecarbon INFO @ 13:04:50] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:04:50] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:04:50] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:04:50] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:04:50] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:04:50] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:04:50] GPU number 7 will not be monitored, at your request.\n",
      "Training  :  61%|██████    | 379/625 [02:29<01:37,  2.52it/s, accuracy=0.849, loss=0.349][codecarbon INFO @ 13:04:50] Energy consumed for all GPUs : 0.030478 kWh. Total GPU Power : 156.45361773170072 W\n",
      "[codecarbon INFO @ 13:04:50] 0.102152 kWh of electricity used since the beginning.\n",
      "Training  :  67%|██████▋   | 416/625 [02:44<01:23,  2.51it/s, accuracy=0.848, loss=0.35][codecarbon INFO @ 13:05:05] Energy consumed for RAM : 0.056396 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:05:05] Energy consumed for all CPUs : 0.016797 kWh. Total CPU Power : 82.79339081759201 W\n",
      "[codecarbon INFO @ 13:05:05] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:05:05] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:05:05] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:05:05] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:05:05] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:05:05] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:05:05] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:05:05] Energy consumed for all GPUs : 0.031130 kWh. Total GPU Power : 157.15683730415856 W\n",
      "[codecarbon INFO @ 13:05:05] 0.104324 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 13:05:05] 0.047968 g.CO2eq/s mean an estimation of 1,512.729216877827 kg.CO2eq/year\n",
      "Training  :  73%|███████▎  | 454/625 [02:59<01:08,  2.51it/s, accuracy=0.848, loss=0.351][codecarbon INFO @ 13:05:20] Energy consumed for RAM : 0.057571 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:05:20] Energy consumed for all CPUs : 0.017141 kWh. Total CPU Power : 82.7604562841354 W\n",
      "[codecarbon INFO @ 13:05:20] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:05:20] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:05:20] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:05:20] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:05:20] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:05:20] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:05:20] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:05:20] Energy consumed for all GPUs : 0.031781 kWh. Total GPU Power : 156.62582311233163 W\n",
      "[codecarbon INFO @ 13:05:20] 0.106493 kWh of electricity used since the beginning.\n",
      "Training  :  79%|███████▊  | 492/625 [03:14<00:52,  2.51it/s, accuracy=0.848, loss=0.351][codecarbon INFO @ 13:05:35] Energy consumed for RAM : 0.058746 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:05:35] Energy consumed for all CPUs : 0.017486 kWh. Total CPU Power : 82.91847408746565 W\n",
      "[codecarbon INFO @ 13:05:35] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:05:35] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:05:35] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:05:35] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:05:35] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:05:35] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:05:35] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:05:35] Energy consumed for all GPUs : 0.032433 kWh. Total GPU Power : 157.075264768536 W\n",
      "[codecarbon INFO @ 13:05:35] 0.108665 kWh of electricity used since the beginning.\n",
      "Training  :  85%|████████▍ | 529/625 [03:29<00:38,  2.51it/s, accuracy=0.848, loss=0.35][codecarbon INFO @ 13:05:50] Energy consumed for RAM : 0.059921 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:05:50] Energy consumed for all CPUs : 0.017831 kWh. Total CPU Power : 83.08518118985697 W\n",
      "[codecarbon INFO @ 13:05:50] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:05:50] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:05:50] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:05:50] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:05:50] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:05:50] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:05:50] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:05:50] Energy consumed for all GPUs : 0.033086 kWh. Total GPU Power : 157.17006658393706 W\n",
      "[codecarbon INFO @ 13:05:50] 0.110838 kWh of electricity used since the beginning.\n",
      "Training  :  91%|█████████ | 567/625 [03:44<00:23,  2.51it/s, accuracy=0.847, loss=0.353][codecarbon INFO @ 13:06:05] Energy consumed for RAM : 0.061096 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:06:05] Energy consumed for all CPUs : 0.018176 kWh. Total CPU Power : 83.06524930960362 W\n",
      "[codecarbon INFO @ 13:06:05] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:06:05] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:06:05] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:06:05] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:06:05] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:06:05] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:06:05] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:06:05] Energy consumed for all GPUs : 0.033733 kWh. Total GPU Power : 155.62742996728107 W\n",
      "[codecarbon INFO @ 13:06:05] 0.113005 kWh of electricity used since the beginning.\n",
      "Training  :  97%|█████████▋| 604/625 [03:59<00:08,  2.50it/s, accuracy=0.846, loss=0.354][codecarbon INFO @ 13:06:20] Energy consumed for RAM : 0.062271 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:06:20] Energy consumed for all CPUs : 0.018521 kWh. Total CPU Power : 83.13773317787982 W\n",
      "[codecarbon INFO @ 13:06:20] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:06:20] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:06:20] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:06:20] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:06:20] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:06:20] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:06:20] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:06:20] Energy consumed for all GPUs : 0.034384 kWh. Total GPU Power : 156.7715514630204 W\n",
      "[codecarbon INFO @ 13:06:20] 0.115177 kWh of electricity used since the beginning.\n",
      "Training  : 100%|██████████| 625/625 [04:07<00:00,  2.52it/s, accuracy=0.847, loss=0.353]\n",
      "Evaluating:  23%|██▎       | 36/157 [00:06<00:22,  5.32it/s, accuracy=0.832, loss=0.379][codecarbon INFO @ 13:06:35] Energy consumed for RAM : 0.063446 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:06:35] Energy consumed for all CPUs : 0.018869 kWh. Total CPU Power : 83.7577373034978 W\n",
      "Evaluating:  24%|██▎       | 37/157 [00:06<00:22,  5.32it/s, accuracy=0.833, loss=0.378][codecarbon INFO @ 13:06:35] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:06:35] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:06:35] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:06:35] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:06:35] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:06:35] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:06:35] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:06:35] Energy consumed for all GPUs : 0.035039 kWh. Total GPU Power : 157.65292998211592 W\n",
      "[codecarbon INFO @ 13:06:35] 0.117354 kWh of electricity used since the beginning.\n",
      "Evaluating:  74%|███████▍  | 116/157 [00:21<00:07,  5.29it/s, accuracy=0.846, loss=0.366][codecarbon INFO @ 13:06:50] Energy consumed for RAM : 0.064620 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:06:50] Energy consumed for all CPUs : 0.019220 kWh. Total CPU Power : 84.53375258040226 W\n",
      "[codecarbon INFO @ 13:06:50] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:06:50] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:06:50] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:06:50] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:06:50] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:06:50] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:06:50] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:06:50] Energy consumed for all GPUs : 0.035694 kWh. Total GPU Power : 157.66914242704394 W\n",
      "[codecarbon INFO @ 13:06:50] 0.119534 kWh of electricity used since the beginning.\n",
      "Evaluating: 100%|██████████| 157/157 [00:29<00:00,  5.33it/s, accuracy=0.845, loss=0.372]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La loss sul validation set non è migliorata per 1 epoche.\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :   3%|▎         | 17/625 [00:06<03:58,  2.55it/s, accuracy=0.866, loss=0.315][codecarbon INFO @ 13:07:05] Energy consumed for RAM : 0.065795 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:07:05] Energy consumed for all CPUs : 0.019568 kWh. Total CPU Power : 83.79819075545656 W\n",
      "[codecarbon INFO @ 13:07:05] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:07:05] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:07:05] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:07:05] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:07:05] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:07:05] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:07:05] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:07:05] Energy consumed for all GPUs : 0.036333 kWh. Total GPU Power : 153.955255927929 W\n",
      "[codecarbon INFO @ 13:07:05] 0.121697 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 13:07:05] 0.047877 g.CO2eq/s mean an estimation of 1,509.8465006378879 kg.CO2eq/year\n",
      "Training  :   9%|▉         | 55/625 [00:21<03:44,  2.54it/s, accuracy=0.864, loss=0.308][codecarbon INFO @ 13:07:20] Energy consumed for RAM : 0.066970 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:07:20] Energy consumed for all CPUs : 0.019914 kWh. Total CPU Power : 83.36232318491163 W\n",
      "[codecarbon INFO @ 13:07:20] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:07:20] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:07:20] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:07:20] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:07:20] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:07:20] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:07:20] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:07:20] Energy consumed for all GPUs : 0.036987 kWh. Total GPU Power : 157.3553222273995 W\n",
      "[codecarbon INFO @ 13:07:20] 0.123871 kWh of electricity used since the beginning.\n",
      "Training  :  15%|█▍        | 93/625 [00:36<03:29,  2.54it/s, accuracy=0.855, loss=0.32][codecarbon INFO @ 13:07:35] Energy consumed for RAM : 0.068144 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:07:35] Energy consumed for all CPUs : 0.020260 kWh. Total CPU Power : 83.24780109854578 W\n",
      "[codecarbon INFO @ 13:07:35] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:07:35] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:07:35] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:07:35] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:07:35] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:07:35] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:07:35] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:07:35] Energy consumed for all GPUs : 0.037645 kWh. Total GPU Power : 158.39887758199828 W\n",
      "[codecarbon INFO @ 13:07:35] 0.126049 kWh of electricity used since the beginning.\n",
      "Training  :  21%|██        | 131/625 [00:51<03:14,  2.54it/s, accuracy=0.857, loss=0.325][codecarbon INFO @ 13:07:50] Energy consumed for RAM : 0.069320 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:07:50] Energy consumed for all CPUs : 0.020606 kWh. Total CPU Power : 83.14760655854764 W\n",
      "[codecarbon INFO @ 13:07:50] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:07:50] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:07:50] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:07:50] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:07:50] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:07:50] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:07:50] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:07:50] Energy consumed for all GPUs : 0.038297 kWh. Total GPU Power : 157.07167906553218 W\n",
      "[codecarbon INFO @ 13:07:50] 0.128222 kWh of electricity used since the beginning.\n",
      "Training  :  27%|██▋       | 169/625 [01:06<02:59,  2.53it/s, accuracy=0.858, loss=0.324][codecarbon INFO @ 13:08:05] Energy consumed for RAM : 0.070495 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:08:05] Energy consumed for all CPUs : 0.020952 kWh. Total CPU Power : 83.35566002789287 W\n",
      "[codecarbon INFO @ 13:08:05] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:08:05] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:08:05] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:08:05] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:08:05] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:08:05] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:08:05] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:08:05] Energy consumed for all GPUs : 0.038952 kWh. Total GPU Power : 157.66150125590858 W\n",
      "[codecarbon INFO @ 13:08:05] 0.130399 kWh of electricity used since the beginning.\n",
      "Training  :  33%|███▎      | 207/625 [01:21<02:45,  2.53it/s, accuracy=0.859, loss=0.326][codecarbon INFO @ 13:08:20] Energy consumed for RAM : 0.071669 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:08:20] Energy consumed for all CPUs : 0.021297 kWh. Total CPU Power : 83.05193666449496 W\n",
      "[codecarbon INFO @ 13:08:20] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:08:20] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:08:20] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:08:20] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:08:20] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:08:20] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:08:20] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:08:20] Energy consumed for all GPUs : 0.039608 kWh. Total GPU Power : 157.90843637525927 W\n",
      "[codecarbon INFO @ 13:08:20] 0.132574 kWh of electricity used since the beginning.\n",
      "Training  :  39%|███▉      | 245/625 [01:36<02:30,  2.52it/s, accuracy=0.861, loss=0.322][codecarbon INFO @ 13:08:35] Energy consumed for RAM : 0.072844 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:08:35] Energy consumed for all CPUs : 0.021643 kWh. Total CPU Power : 83.4571849024914 W\n",
      "[codecarbon INFO @ 13:08:35] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:08:35] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:08:35] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:08:35] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:08:35] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:08:35] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:08:35] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:08:35] Energy consumed for all GPUs : 0.040259 kWh. Total GPU Power : 156.65481964183104 W\n",
      "[codecarbon INFO @ 13:08:35] 0.134747 kWh of electricity used since the beginning.\n",
      "Training  :  41%|████      | 257/625 [01:41<02:25,  2.53it/s, accuracy=0.861, loss=0.321]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training  :  45%|████▌     | 283/625 [01:51<02:15,  2.52it/s, accuracy=0.863, loss=0.32][codecarbon INFO @ 13:08:50] Energy consumed for RAM : 0.074019 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:08:50] Energy consumed for all CPUs : 0.021988 kWh. Total CPU Power : 83.03004592756746 W\n",
      "[codecarbon INFO @ 13:08:50] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:08:50] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:08:50] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:08:50] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:08:50] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:08:50] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:08:50] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:08:50] Energy consumed for all GPUs : 0.040915 kWh. Total GPU Power : 157.9465746365465 W\n",
      "[codecarbon INFO @ 13:08:50] 0.136923 kWh of electricity used since the beginning.\n",
      "Training  :  51%|█████▏    | 321/625 [02:06<02:00,  2.52it/s, accuracy=0.864, loss=0.319][codecarbon INFO @ 13:09:05] Energy consumed for RAM : 0.075194 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:09:05] Energy consumed for all CPUs : 0.022333 kWh. Total CPU Power : 82.87774606000846 W\n",
      "[codecarbon INFO @ 13:09:05] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:09:05] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:09:05] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:09:05] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:09:05] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:09:05] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:09:05] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:09:05] Energy consumed for all GPUs : 0.041568 kWh. Total GPU Power : 157.08558998000797 W\n",
      "[codecarbon INFO @ 13:09:05] 0.139095 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 13:09:05] 0.047947 g.CO2eq/s mean an estimation of 1,512.0710589267524 kg.CO2eq/year\n",
      "Training  :  57%|█████▋    | 359/625 [02:21<01:45,  2.52it/s, accuracy=0.863, loss=0.321][codecarbon INFO @ 13:09:20] Energy consumed for RAM : 0.076369 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:09:20] Energy consumed for all CPUs : 0.022677 kWh. Total CPU Power : 82.95719344904694 W\n",
      "[codecarbon INFO @ 13:09:20] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:09:20] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:09:20] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:09:20] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:09:20] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:09:20] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:09:20] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:09:20] Energy consumed for all GPUs : 0.042216 kWh. Total GPU Power : 156.04033331675652 W\n",
      "[codecarbon INFO @ 13:09:20] 0.141262 kWh of electricity used since the beginning.\n",
      "Training  :  64%|██████▎   | 397/625 [02:36<01:30,  2.52it/s, accuracy=0.863, loss=0.321][codecarbon INFO @ 13:09:35] Energy consumed for RAM : 0.077544 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:09:35] Energy consumed for all CPUs : 0.023021 kWh. Total CPU Power : 82.8265147568046 W\n",
      "[codecarbon INFO @ 13:09:35] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:09:35] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:09:35] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:09:35] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:09:35] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:09:35] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:09:35] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:09:35] Energy consumed for all GPUs : 0.042869 kWh. Total GPU Power : 157.14310259213252 W\n",
      "[codecarbon INFO @ 13:09:35] 0.143434 kWh of electricity used since the beginning.\n",
      "Training  :  69%|██████▉   | 434/625 [02:51<01:15,  2.51it/s, accuracy=0.863, loss=0.32][codecarbon INFO @ 13:09:50] Energy consumed for RAM : 0.078718 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:09:50] Energy consumed for all CPUs : 0.023366 kWh. Total CPU Power : 82.93249186423265 W\n",
      "[codecarbon INFO @ 13:09:50] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:09:50] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:09:50] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:09:50] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:09:50] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:09:50] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:09:50] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:09:50] Energy consumed for all GPUs : 0.043519 kWh. Total GPU Power : 156.5312968183359 W\n",
      "[codecarbon INFO @ 13:09:50] 0.145603 kWh of electricity used since the beginning.\n",
      "Training  :  76%|███████▌  | 472/625 [03:06<01:00,  2.51it/s, accuracy=0.863, loss=0.32][codecarbon INFO @ 13:10:05] Energy consumed for RAM : 0.079894 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:10:05] Energy consumed for all CPUs : 0.023708 kWh. Total CPU Power : 82.32090225287224 W\n",
      "[codecarbon INFO @ 13:10:05] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:10:05] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:10:05] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:10:05] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:10:05] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:10:05] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:10:05] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:10:05] Energy consumed for all GPUs : 0.044172 kWh. Total GPU Power : 157.16129620099 W\n",
      "[codecarbon INFO @ 13:10:05] 0.147773 kWh of electricity used since the beginning.\n",
      "Training  :  82%|████████▏ | 510/625 [03:21<00:45,  2.51it/s, accuracy=0.863, loss=0.321][codecarbon INFO @ 13:10:20] Energy consumed for RAM : 0.081068 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:10:20] Energy consumed for all CPUs : 0.024050 kWh. Total CPU Power : 82.5517714078494 W\n",
      "[codecarbon INFO @ 13:10:20] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:10:20] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:10:20] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:10:20] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:10:20] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:10:20] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:10:20] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:10:20] Energy consumed for all GPUs : 0.044823 kWh. Total GPU Power : 156.8818641833793 W\n",
      "[codecarbon INFO @ 13:10:20] 0.149942 kWh of electricity used since the beginning.\n",
      "Training  :  88%|████████▊ | 547/625 [03:36<00:31,  2.51it/s, accuracy=0.863, loss=0.322][codecarbon INFO @ 13:10:35] Energy consumed for RAM : 0.082244 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:10:35] Energy consumed for all CPUs : 0.024394 kWh. Total CPU Power : 82.59608249597288 W\n",
      "[codecarbon INFO @ 13:10:35] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:10:35] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:10:35] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:10:35] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:10:35] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:10:35] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:10:35] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:10:35] Energy consumed for all GPUs : 0.045470 kWh. Total GPU Power : 155.56089080264778 W\n",
      "[codecarbon INFO @ 13:10:35] 0.152107 kWh of electricity used since the beginning.\n",
      "Training  :  94%|█████████▎| 585/625 [03:51<00:15,  2.50it/s, accuracy=0.863, loss=0.323][codecarbon INFO @ 13:10:50] Energy consumed for RAM : 0.083418 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:10:50] Energy consumed for all CPUs : 0.024737 kWh. Total CPU Power : 82.58516410048097 W\n",
      "[codecarbon INFO @ 13:10:50] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:10:50] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:10:50] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:10:50] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:10:50] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:10:50] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:10:50] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:10:50] Energy consumed for all GPUs : 0.046121 kWh. Total GPU Power : 156.84564982623314 W\n",
      "[codecarbon INFO @ 13:10:50] 0.154276 kWh of electricity used since the beginning.\n",
      "Training  : 100%|█████████▉| 622/625 [04:06<00:01,  2.50it/s, accuracy=0.863, loss=0.323][codecarbon INFO @ 13:11:05] Energy consumed for RAM : 0.084593 kWh. RAM Power : 282.878173828125 W\n",
      "Training  : 100%|█████████▉| 623/625 [04:06<00:00,  2.50it/s, accuracy=0.863, loss=0.323][codecarbon INFO @ 13:11:05] Energy consumed for all CPUs : 0.025080 kWh. Total CPU Power : 82.62897524398286 W\n",
      "[codecarbon INFO @ 13:11:05] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:11:05] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:11:05] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:11:05] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:11:05] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:11:05] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:11:05] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:11:05] Energy consumed for all GPUs : 0.046772 kWh. Total GPU Power : 156.62257055822482 W\n",
      "[codecarbon INFO @ 13:11:05] 0.156445 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 13:11:05] 0.047816 g.CO2eq/s mean an estimation of 1,507.9299839249106 kg.CO2eq/year\n",
      "Training  : 100%|██████████| 625/625 [04:07<00:00,  2.52it/s, accuracy=0.863, loss=0.323]\n",
      "Evaluating:  48%|████▊     | 75/157 [00:14<00:15,  5.30it/s, accuracy=0.839, loss=0.381][codecarbon INFO @ 13:11:20] Energy consumed for RAM : 0.085768 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:11:20] Energy consumed for all CPUs : 0.025428 kWh. Total CPU Power : 83.89282010170176 W\n",
      "[codecarbon INFO @ 13:11:20] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:11:20] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:11:20] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:11:20] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:11:20] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:11:20] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:11:20] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:11:20] Energy consumed for all GPUs : 0.047427 kWh. Total GPU Power : 157.6974368735636 W\n",
      "[codecarbon INFO @ 13:11:20] 0.158623 kWh of electricity used since the beginning.\n",
      "Evaluating:  98%|█████████▊| 154/157 [00:29<00:00,  5.28it/s, accuracy=0.848, loss=0.368][codecarbon INFO @ 13:11:35] Energy consumed for RAM : 0.086942 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:11:35] Energy consumed for all CPUs : 0.025774 kWh. Total CPU Power : 83.31359648417072 W\n",
      "[codecarbon INFO @ 13:11:35] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:11:35] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:11:35] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:11:35] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:11:35] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:11:35] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:11:35] GPU number 7 will not be monitored, at your request.\n",
      "Evaluating:  99%|█████████▊| 155/157 [00:29<00:00,  5.28it/s, accuracy=0.848, loss=0.367][codecarbon INFO @ 13:11:35] Energy consumed for all GPUs : 0.048087 kWh. Total GPU Power : 158.8336147667599 W\n",
      "[codecarbon INFO @ 13:11:35] 0.160803 kWh of electricity used since the beginning.\n",
      "Evaluating: 100%|██████████| 157/157 [00:29<00:00,  5.33it/s, accuracy=0.849, loss=0.368]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La loss sul validation set non è migliorata per 2 epoche.\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :   6%|▌         | 35/625 [00:13<03:52,  2.54it/s, accuracy=0.869, loss=0.306][codecarbon INFO @ 13:11:50] Energy consumed for RAM : 0.088117 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:11:50] Energy consumed for all CPUs : 0.026120 kWh. Total CPU Power : 83.20403757262662 W\n",
      "[codecarbon INFO @ 13:11:50] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:11:50] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:11:50] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:11:50] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:11:50] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:11:50] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:11:50] GPU number 7 will not be monitored, at your request.\n",
      "Training  :   6%|▌         | 36/625 [00:14<03:51,  2.54it/s, accuracy=0.869, loss=0.305][codecarbon INFO @ 13:11:50] Energy consumed for all GPUs : 0.048722 kWh. Total GPU Power : 152.99107505852035 W\n",
      "[codecarbon INFO @ 13:11:50] 0.162959 kWh of electricity used since the beginning.\n",
      "Training  :  12%|█▏        | 74/625 [00:29<03:37,  2.54it/s, accuracy=0.876, loss=0.293][codecarbon INFO @ 13:12:05] Energy consumed for RAM : 0.089292 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:12:05] Energy consumed for all CPUs : 0.026465 kWh. Total CPU Power : 83.1886949890179 W\n",
      "[codecarbon INFO @ 13:12:05] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:12:05] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:12:05] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:12:05] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:12:05] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:12:05] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:12:05] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:12:05] Energy consumed for all GPUs : 0.049380 kWh. Total GPU Power : 158.23603214944796 W\n",
      "[codecarbon INFO @ 13:12:05] 0.165137 kWh of electricity used since the beginning.\n",
      "Training  :  18%|█▊        | 112/625 [00:44<03:21,  2.54it/s, accuracy=0.876, loss=0.294][codecarbon INFO @ 13:12:20] Energy consumed for RAM : 0.090467 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:12:20] Energy consumed for all CPUs : 0.026809 kWh. Total CPU Power : 82.80498559605016 W\n",
      "[codecarbon INFO @ 13:12:20] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:12:20] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:12:20] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:12:20] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:12:20] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:12:20] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:12:20] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:12:20] Energy consumed for all GPUs : 0.050032 kWh. Total GPU Power : 157.1177029168099 W\n",
      "[codecarbon INFO @ 13:12:20] 0.167308 kWh of electricity used since the beginning.\n",
      "Training  :  23%|██▎       | 146/625 [00:57<03:08,  2.54it/s, accuracy=0.876, loss=0.294]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training  :  24%|██▍       | 150/625 [00:59<03:07,  2.54it/s, accuracy=0.876, loss=0.293][codecarbon INFO @ 13:12:35] Energy consumed for RAM : 0.091642 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:12:35] Energy consumed for all CPUs : 0.027153 kWh. Total CPU Power : 82.69383715619071 W\n",
      "[codecarbon INFO @ 13:12:35] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:12:35] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:12:35] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:12:35] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:12:35] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:12:35] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:12:35] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:12:35] Energy consumed for all GPUs : 0.050688 kWh. Total GPU Power : 157.9292380207075 W\n",
      "[codecarbon INFO @ 13:12:35] 0.169483 kWh of electricity used since the beginning.\n",
      "Training  :  30%|███       | 188/625 [01:14<02:52,  2.53it/s, accuracy=0.877, loss=0.295][codecarbon INFO @ 13:12:50] Energy consumed for RAM : 0.092817 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:12:50] Energy consumed for all CPUs : 0.027498 kWh. Total CPU Power : 83.05437459032692 W\n",
      "[codecarbon INFO @ 13:12:50] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:12:50] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:12:50] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:12:50] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:12:50] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:12:50] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:12:50] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:12:50] Energy consumed for all GPUs : 0.051344 kWh. Total GPU Power : 157.93282298943495 W\n",
      "[codecarbon INFO @ 13:12:50] 0.171658 kWh of electricity used since the beginning.\n",
      "Training  :  36%|███▌      | 226/625 [01:29<02:37,  2.53it/s, accuracy=0.874, loss=0.297][codecarbon INFO @ 13:13:05] Energy consumed for RAM : 0.093992 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:13:05] Energy consumed for all CPUs : 0.027843 kWh. Total CPU Power : 83.21451037947402 W\n",
      "[codecarbon INFO @ 13:13:05] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:13:05] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:13:05] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:13:05] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:13:05] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:13:05] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:13:05] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:13:05] Energy consumed for all GPUs : 0.051995 kWh. Total GPU Power : 156.78822574159065 W\n",
      "[codecarbon INFO @ 13:13:05] 0.173831 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 13:13:05] 0.047917 g.CO2eq/s mean an estimation of 1,511.1037670115522 kg.CO2eq/year\n",
      "Training  :  42%|████▏     | 264/625 [01:44<02:22,  2.53it/s, accuracy=0.871, loss=0.303][codecarbon INFO @ 13:13:20] Energy consumed for RAM : 0.095167 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:13:20] Energy consumed for all CPUs : 0.028190 kWh. Total CPU Power : 83.29277029479965 W\n",
      "[codecarbon INFO @ 13:13:20] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:13:20] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:13:20] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:13:20] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:13:20] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:13:20] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:13:20] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:13:20] Energy consumed for all GPUs : 0.052650 kWh. Total GPU Power : 157.54483935330808 W\n",
      "[codecarbon INFO @ 13:13:20] 0.176007 kWh of electricity used since the beginning.\n",
      "Training  :  48%|████▊     | 302/625 [01:59<02:07,  2.53it/s, accuracy=0.874, loss=0.299][codecarbon INFO @ 13:13:35] Energy consumed for RAM : 0.096342 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:13:35] Energy consumed for all CPUs : 0.028535 kWh. Total CPU Power : 83.18168356647752 W\n",
      "[codecarbon INFO @ 13:13:35] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:13:35] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:13:35] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:13:35] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:13:35] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:13:35] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:13:35] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:13:35] Energy consumed for all GPUs : 0.053300 kWh. Total GPU Power : 156.46145358850333 W\n",
      "[codecarbon INFO @ 13:13:35] 0.178177 kWh of electricity used since the beginning.\n",
      "Training  :  54%|█████▍    | 339/625 [02:13<01:53,  2.52it/s, accuracy=0.872, loss=0.302][codecarbon INFO @ 13:13:50] Energy consumed for RAM : 0.097516 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:13:50] Energy consumed for all CPUs : 0.028879 kWh. Total CPU Power : 82.87223954573213 W\n",
      "[codecarbon INFO @ 13:13:50] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:13:50] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:13:50] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:13:50] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:13:50] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:13:50] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:13:50] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:13:50] Energy consumed for all GPUs : 0.053953 kWh. Total GPU Power : 157.29819392967994 W\n",
      "[codecarbon INFO @ 13:13:50] 0.180349 kWh of electricity used since the beginning.\n",
      "Training  :  60%|██████    | 377/625 [02:28<01:38,  2.52it/s, accuracy=0.874, loss=0.301][codecarbon INFO @ 13:14:05] Energy consumed for RAM : 0.098691 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:14:05] Energy consumed for all CPUs : 0.029222 kWh. Total CPU Power : 82.5126331004319 W\n",
      "[codecarbon INFO @ 13:14:05] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:14:05] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:14:05] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:14:05] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:14:05] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:14:05] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:14:05] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:14:05] Energy consumed for all GPUs : 0.054606 kWh. Total GPU Power : 157.23226597183566 W\n",
      "[codecarbon INFO @ 13:14:05] 0.182519 kWh of electricity used since the beginning.\n",
      "Training  :  66%|██████▋   | 415/625 [02:43<01:23,  2.52it/s, accuracy=0.874, loss=0.301][codecarbon INFO @ 13:14:20] Energy consumed for RAM : 0.099866 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:14:20] Energy consumed for all CPUs : 0.029566 kWh. Total CPU Power : 82.89725152365946 W\n",
      "[codecarbon INFO @ 13:14:20] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:14:20] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:14:20] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:14:20] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:14:20] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:14:20] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:14:20] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:14:20] Energy consumed for all GPUs : 0.055256 kWh. Total GPU Power : 156.39190109768694 W\n",
      "[codecarbon INFO @ 13:14:20] 0.184689 kWh of electricity used since the beginning.\n",
      "Training  :  72%|███████▏  | 453/625 [02:59<01:08,  2.51it/s, accuracy=0.875, loss=0.301][codecarbon INFO @ 13:14:35] Energy consumed for RAM : 0.101041 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:14:35] Energy consumed for all CPUs : 0.029910 kWh. Total CPU Power : 82.84634081463324 W\n",
      "[codecarbon INFO @ 13:14:35] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:14:35] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:14:35] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:14:35] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:14:35] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:14:35] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:14:35] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:14:35] Energy consumed for all GPUs : 0.055909 kWh. Total GPU Power : 157.17644458122382 W\n",
      "[codecarbon INFO @ 13:14:35] 0.186861 kWh of electricity used since the beginning.\n",
      "Training  :  78%|███████▊  | 490/625 [03:13<00:53,  2.51it/s, accuracy=0.874, loss=0.302][codecarbon INFO @ 13:14:50] Energy consumed for RAM : 0.102216 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:14:50] Energy consumed for all CPUs : 0.030254 kWh. Total CPU Power : 82.7241907191647 W\n",
      "[codecarbon INFO @ 13:14:50] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:14:50] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:14:50] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:14:50] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:14:50] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:14:50] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:14:50] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:14:50] Energy consumed for all GPUs : 0.056562 kWh. Total GPU Power : 157.11427054329587 W\n",
      "[codecarbon INFO @ 13:14:50] 0.189032 kWh of electricity used since the beginning.\n",
      "Training  :  84%|████████▍ | 528/625 [03:28<00:38,  2.51it/s, accuracy=0.874, loss=0.302][codecarbon INFO @ 13:15:05] Energy consumed for RAM : 0.103391 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:15:05] Energy consumed for all CPUs : 0.030599 kWh. Total CPU Power : 82.9087889720503 W\n",
      "[codecarbon INFO @ 13:15:05] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:15:05] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:15:05] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:15:05] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:15:05] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:15:05] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:15:05] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:15:05] Energy consumed for all GPUs : 0.057209 kWh. Total GPU Power : 155.79674063746253 W\n",
      "[codecarbon INFO @ 13:15:05] 0.191199 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 13:15:05] 0.047859 g.CO2eq/s mean an estimation of 1,509.2921788029073 kg.CO2eq/year\n",
      "Training  :  91%|█████████ | 566/625 [03:44<00:23,  2.51it/s, accuracy=0.875, loss=0.301][codecarbon INFO @ 13:15:20] Energy consumed for RAM : 0.104565 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:15:20] Energy consumed for all CPUs : 0.030943 kWh. Total CPU Power : 82.97278036947164 W\n",
      "[codecarbon INFO @ 13:15:20] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:15:20] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:15:20] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:15:20] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:15:20] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:15:20] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:15:20] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:15:20] Energy consumed for all GPUs : 0.057861 kWh. Total GPU Power : 157.08707126550038 W\n",
      "[codecarbon INFO @ 13:15:20] 0.193369 kWh of electricity used since the beginning.\n",
      "Training  :  96%|█████████▋| 603/625 [03:58<00:08,  2.50it/s, accuracy=0.875, loss=0.301][codecarbon INFO @ 13:15:35] Energy consumed for RAM : 0.105740 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:15:35] Energy consumed for all CPUs : 0.031287 kWh. Total CPU Power : 82.76632932996017 W\n",
      "[codecarbon INFO @ 13:15:35] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:15:35] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:15:35] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:15:35] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:15:35] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:15:35] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:15:35] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:15:35] Energy consumed for all GPUs : 0.058509 kWh. Total GPU Power : 155.90259100854158 W\n",
      "[codecarbon INFO @ 13:15:35] 0.195535 kWh of electricity used since the beginning.\n",
      "Training  : 100%|██████████| 625/625 [04:07<00:00,  2.52it/s, accuracy=0.874, loss=0.302]\n",
      "Evaluating:  22%|██▏       | 34/157 [00:06<00:23,  5.33it/s, accuracy=0.846, loss=0.346][codecarbon INFO @ 13:15:50] Energy consumed for RAM : 0.106915 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:15:50] Energy consumed for all CPUs : 0.031632 kWh. Total CPU Power : 83.08222099684512 W\n",
      "[codecarbon INFO @ 13:15:50] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:15:50] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:15:50] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:15:50] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:15:50] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:15:50] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:15:50] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:15:50] Energy consumed for all GPUs : 0.059164 kWh. Total GPU Power : 157.68730512664706 W\n",
      "[codecarbon INFO @ 13:15:50] 0.197711 kWh of electricity used since the beginning.\n",
      "Evaluating:  73%|███████▎  | 114/157 [00:21<00:08,  5.30it/s, accuracy=0.848, loss=0.354][codecarbon INFO @ 13:16:05] Energy consumed for RAM : 0.108090 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:16:05] Energy consumed for all CPUs : 0.031980 kWh. Total CPU Power : 83.86916878294244 W\n",
      "[codecarbon INFO @ 13:16:05] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:16:05] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:16:05] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:16:05] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:16:05] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:16:05] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:16:05] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:16:05] Energy consumed for all GPUs : 0.059824 kWh. Total GPU Power : 158.85603450862595 W\n",
      "[codecarbon INFO @ 13:16:05] 0.199894 kWh of electricity used since the beginning.\n",
      "Evaluating: 100%|██████████| 157/157 [00:29<00:00,  5.33it/s, accuracy=0.85, loss=0.355] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :   3%|▎         | 16/625 [00:06<03:59,  2.55it/s, accuracy=0.875, loss=0.291][codecarbon INFO @ 13:16:20] Energy consumed for RAM : 0.109264 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:16:20] Energy consumed for all CPUs : 0.032329 kWh. Total CPU Power : 83.98806595660713 W\n",
      "[codecarbon INFO @ 13:16:20] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:16:20] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:16:20] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:16:20] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:16:20] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:16:20] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:16:20] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:16:20] Energy consumed for all GPUs : 0.060462 kWh. Total GPU Power : 153.8475658522092 W\n",
      "[codecarbon INFO @ 13:16:20] 0.202055 kWh of electricity used since the beginning.\n",
      "Training  :   9%|▊         | 54/625 [00:21<03:44,  2.54it/s, accuracy=0.873, loss=0.284][codecarbon INFO @ 13:16:35] Energy consumed for RAM : 0.110439 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:16:35] Energy consumed for all CPUs : 0.032675 kWh. Total CPU Power : 83.31321836303039 W\n",
      "[codecarbon INFO @ 13:16:35] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:16:35] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:16:35] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:16:35] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:16:35] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:16:35] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:16:35] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:16:35] Energy consumed for all GPUs : 0.061120 kWh. Total GPU Power : 158.2839161676735 W\n",
      "[codecarbon INFO @ 13:16:35] 0.204234 kWh of electricity used since the beginning.\n",
      "Training  :  15%|█▍        | 92/625 [00:36<03:29,  2.54it/s, accuracy=0.879, loss=0.281][codecarbon INFO @ 13:16:50] Energy consumed for RAM : 0.111614 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:16:50] Energy consumed for all CPUs : 0.033022 kWh. Total CPU Power : 83.49268153470202 W\n",
      "[codecarbon INFO @ 13:16:50] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:16:50] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:16:50] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:16:50] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:16:50] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:16:50] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:16:50] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:16:50] Energy consumed for all GPUs : 0.061773 kWh. Total GPU Power : 157.26881230280281 W\n",
      "[codecarbon INFO @ 13:16:50] 0.206408 kWh of electricity used since the beginning.\n",
      "Training  :  21%|██        | 130/625 [00:51<03:14,  2.54it/s, accuracy=0.878, loss=0.28][codecarbon INFO @ 13:17:05] Energy consumed for RAM : 0.112789 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:17:05] Energy consumed for all CPUs : 0.033369 kWh. Total CPU Power : 83.56000593736917 W\n",
      "[codecarbon INFO @ 13:17:05] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:17:05] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:17:05] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:17:05] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:17:05] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:17:05] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:17:05] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:17:05] Energy consumed for all GPUs : 0.062429 kWh. Total GPU Power : 157.87994062535634 W\n",
      "[codecarbon INFO @ 13:17:05] 0.208587 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 13:17:05] 0.047924 g.CO2eq/s mean an estimation of 1,511.3421173894508 kg.CO2eq/year\n",
      "Training  :  27%|██▋       | 168/625 [01:06<03:00,  2.54it/s, accuracy=0.88, loss=0.276][codecarbon INFO @ 13:17:20] Energy consumed for RAM : 0.113964 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:17:20] Energy consumed for all CPUs : 0.033716 kWh. Total CPU Power : 83.52076795735653 W\n",
      "[codecarbon INFO @ 13:17:20] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:17:20] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:17:20] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:17:20] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:17:20] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:17:20] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:17:20] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:17:20] Energy consumed for all GPUs : 0.063085 kWh. Total GPU Power : 157.80095712369146 W\n",
      "[codecarbon INFO @ 13:17:20] 0.210764 kWh of electricity used since the beginning.\n",
      "Training  :  33%|███▎      | 206/625 [01:21<02:45,  2.53it/s, accuracy=0.88, loss=0.279][codecarbon INFO @ 13:17:35] Energy consumed for RAM : 0.115139 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:17:35] Energy consumed for all CPUs : 0.034062 kWh. Total CPU Power : 83.31912199838524 W\n",
      "[codecarbon INFO @ 13:17:35] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:17:35] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:17:35] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:17:35] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:17:35] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:17:35] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:17:35] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:17:35] Energy consumed for all GPUs : 0.063736 kWh. Total GPU Power : 156.89328918415796 W\n",
      "[codecarbon INFO @ 13:17:35] 0.212937 kWh of electricity used since the beginning.\n",
      "Training  :  39%|███▉      | 244/625 [01:36<02:30,  2.53it/s, accuracy=0.88, loss=0.281][codecarbon INFO @ 13:17:50] Energy consumed for RAM : 0.116313 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:17:50] Energy consumed for all CPUs : 0.034408 kWh. Total CPU Power : 83.2560222193973 W\n",
      "[codecarbon INFO @ 13:17:50] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:17:50] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:17:50] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:17:50] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:17:50] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:17:50] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:17:50] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:17:50] Energy consumed for all GPUs : 0.064391 kWh. Total GPU Power : 157.7484125784932 W\n",
      "[codecarbon INFO @ 13:17:50] 0.215112 kWh of electricity used since the beginning.\n",
      "Training  :  45%|████▌     | 282/625 [01:51<02:15,  2.53it/s, accuracy=0.88, loss=0.282][codecarbon INFO @ 13:18:05] Energy consumed for RAM : 0.117488 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:18:05] Energy consumed for all CPUs : 0.034753 kWh. Total CPU Power : 83.08079291199002 W\n",
      "[codecarbon INFO @ 13:18:05] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:18:05] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:18:05] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:18:05] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:18:05] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:18:05] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:18:05] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:18:05] Energy consumed for all GPUs : 0.065042 kWh. Total GPU Power : 156.62908138549247 W\n",
      "[codecarbon INFO @ 13:18:05] 0.217283 kWh of electricity used since the beginning.\n",
      "Training  :  51%|█████     | 320/625 [02:06<02:00,  2.52it/s, accuracy=0.879, loss=0.283][codecarbon INFO @ 13:18:20] Energy consumed for RAM : 0.118664 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:18:20] Energy consumed for all CPUs : 0.035098 kWh. Total CPU Power : 82.99089607144913 W\n",
      "[codecarbon INFO @ 13:18:20] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:18:20] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:18:20] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:18:20] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:18:20] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:18:20] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:18:20] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:18:20] Energy consumed for all GPUs : 0.065696 kWh. Total GPU Power : 157.31008494150146 W\n",
      "[codecarbon INFO @ 13:18:20] 0.219457 kWh of electricity used since the beginning.\n",
      "Training  :  54%|█████▍    | 339/625 [02:13<01:53,  2.52it/s, accuracy=0.879, loss=0.282]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training  :  57%|█████▋    | 358/625 [02:21<01:45,  2.52it/s, accuracy=0.878, loss=0.284][codecarbon INFO @ 13:18:35] Energy consumed for RAM : 0.119838 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:18:35] Energy consumed for all CPUs : 0.035444 kWh. Total CPU Power : 83.33908714887357 W\n",
      "[codecarbon INFO @ 13:18:35] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:18:35] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:18:35] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:18:35] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:18:35] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:18:35] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:18:35] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:18:35] Energy consumed for all GPUs : 0.066350 kWh. Total GPU Power : 157.4533454842836 W\n",
      "[codecarbon INFO @ 13:18:35] 0.221632 kWh of electricity used since the beginning.\n",
      "Training  :  63%|██████▎   | 396/625 [02:36<01:30,  2.52it/s, accuracy=0.88, loss=0.28][codecarbon INFO @ 13:18:50] Energy consumed for RAM : 0.121013 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:18:50] Energy consumed for all CPUs : 0.035789 kWh. Total CPU Power : 83.15763598109578 W\n",
      "[codecarbon INFO @ 13:18:50] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:18:50] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:18:50] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:18:50] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:18:50] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:18:50] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:18:50] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:18:50] Energy consumed for all GPUs : 0.067000 kWh. Total GPU Power : 156.40491966740424 W\n",
      "[codecarbon INFO @ 13:18:50] 0.223802 kWh of electricity used since the beginning.\n",
      "Training  :  69%|██████▉   | 433/625 [02:51<01:16,  2.51it/s, accuracy=0.881, loss=0.278][codecarbon INFO @ 13:19:05] Energy consumed for RAM : 0.122188 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:19:05] Energy consumed for all CPUs : 0.036134 kWh. Total CPU Power : 83.13168696142357 W\n",
      "[codecarbon INFO @ 13:19:05] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:19:05] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:19:05] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:19:05] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:19:05] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:19:05] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:19:05] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:19:05] Energy consumed for all GPUs : 0.067655 kWh. Total GPU Power : 157.66039731516966 W\n",
      "[codecarbon INFO @ 13:19:05] 0.225977 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 13:19:05] 0.047925 g.CO2eq/s mean an estimation of 1,511.351508628063 kg.CO2eq/year\n",
      "Training  :  75%|███████▌  | 471/625 [03:06<01:01,  2.51it/s, accuracy=0.882, loss=0.279][codecarbon INFO @ 13:19:20] Energy consumed for RAM : 0.123363 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:19:20] Energy consumed for all CPUs : 0.036479 kWh. Total CPU Power : 82.99997415620183 W\n",
      "[codecarbon INFO @ 13:19:20] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:19:20] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:19:20] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:19:20] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:19:20] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:19:20] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:19:20] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:19:20] Energy consumed for all GPUs : 0.068302 kWh. Total GPU Power : 156.00056122174013 W\n",
      "[codecarbon INFO @ 13:19:20] 0.228144 kWh of electricity used since the beginning.\n",
      "Training  :  81%|████████▏ | 509/625 [03:21<00:46,  2.51it/s, accuracy=0.882, loss=0.279][codecarbon INFO @ 13:19:35] Energy consumed for RAM : 0.124538 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:19:35] Energy consumed for all CPUs : 0.036824 kWh. Total CPU Power : 83.08335800801478 W\n",
      "[codecarbon INFO @ 13:19:35] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:19:35] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:19:35] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:19:35] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:19:35] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:19:35] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:19:35] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:19:35] Energy consumed for all GPUs : 0.068954 kWh. Total GPU Power : 156.93655453460786 W\n",
      "[codecarbon INFO @ 13:19:35] 0.230317 kWh of electricity used since the beginning.\n",
      "Training  :  87%|████████▋ | 546/625 [03:36<00:31,  2.51it/s, accuracy=0.883, loss=0.279][codecarbon INFO @ 13:19:50] Energy consumed for RAM : 0.125713 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:19:50] Energy consumed for all CPUs : 0.037170 kWh. Total CPU Power : 83.31806671195514 W\n",
      "[codecarbon INFO @ 13:19:50] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:19:50] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:19:50] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:19:50] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:19:50] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:19:50] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:19:50] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:19:50] Energy consumed for all GPUs : 0.069603 kWh. Total GPU Power : 156.10941423591987 W\n",
      "[codecarbon INFO @ 13:19:50] 0.232486 kWh of electricity used since the beginning.\n",
      "Training  :  93%|█████████▎| 584/625 [03:51<00:16,  2.50it/s, accuracy=0.883, loss=0.278][codecarbon INFO @ 13:20:05] Energy consumed for RAM : 0.126888 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:20:05] Energy consumed for all CPUs : 0.037516 kWh. Total CPU Power : 83.14244062083688 W\n",
      "[codecarbon INFO @ 13:20:05] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:20:05] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:20:05] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:20:05] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:20:05] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:20:05] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:20:05] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:20:05] Energy consumed for all GPUs : 0.070255 kWh. Total GPU Power : 156.85667303005593 W\n",
      "[codecarbon INFO @ 13:20:05] 0.234658 kWh of electricity used since the beginning.\n",
      "Training  :  99%|█████████▉| 621/625 [04:06<00:01,  2.50it/s, accuracy=0.883, loss=0.279][codecarbon INFO @ 13:20:20] Energy consumed for RAM : 0.128063 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:20:20] Energy consumed for all CPUs : 0.037861 kWh. Total CPU Power : 83.199213017431 W\n",
      "[codecarbon INFO @ 13:20:20] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:20:20] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:20:20] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:20:20] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:20:20] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:20:20] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:20:20] GPU number 7 will not be monitored, at your request.\n",
      "Training  : 100%|█████████▉| 622/625 [04:06<00:01,  2.50it/s, accuracy=0.883, loss=0.279][codecarbon INFO @ 13:20:20] Energy consumed for all GPUs : 0.070905 kWh. Total GPU Power : 156.62313111447534 W\n",
      "[codecarbon INFO @ 13:20:20] 0.236830 kWh of electricity used since the beginning.\n",
      "Training  : 100%|██████████| 625/625 [04:07<00:00,  2.52it/s, accuracy=0.883, loss=0.279]\n",
      "Evaluating:  46%|████▋     | 73/157 [00:13<00:15,  5.30it/s, accuracy=0.845, loss=0.377][codecarbon INFO @ 13:20:35] Energy consumed for RAM : 0.129238 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:20:35] Energy consumed for all CPUs : 0.038212 kWh. Total CPU Power : 84.48014376357362 W\n",
      "[codecarbon INFO @ 13:20:35] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:20:35] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:20:35] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:20:35] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:20:35] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:20:35] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:20:35] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:20:35] Energy consumed for all GPUs : 0.071561 kWh. Total GPU Power : 157.8042669840509 W\n",
      "[codecarbon INFO @ 13:20:35] 0.239011 kWh of electricity used since the beginning.\n",
      "Evaluating:  97%|█████████▋| 152/157 [00:28<00:00,  5.27it/s, accuracy=0.851, loss=0.361][codecarbon INFO @ 13:20:50] Energy consumed for RAM : 0.130413 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:20:50] Energy consumed for all CPUs : 0.038563 kWh. Total CPU Power : 84.32991956003632 W\n",
      "[codecarbon INFO @ 13:20:50] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:20:50] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:20:50] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:20:50] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:20:50] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:20:50] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:20:50] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:20:50] Energy consumed for all GPUs : 0.072221 kWh. Total GPU Power : 158.84526827700583 W\n",
      "[codecarbon INFO @ 13:20:50] 0.241196 kWh of electricity used since the beginning.\n",
      "Evaluating: 100%|██████████| 157/157 [00:29<00:00,  5.33it/s, accuracy=0.851, loss=0.362]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La loss sul validation set non è migliorata per 1 epoche.\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :   1%|          | 6/625 [00:02<04:03,  2.54it/s, accuracy=0.911, loss=0.211]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training  :   5%|▌         | 34/625 [00:13<03:51,  2.55it/s, accuracy=0.887, loss=0.277][codecarbon INFO @ 13:21:05] Energy consumed for RAM : 0.131588 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:21:05] Energy consumed for all CPUs : 0.038910 kWh. Total CPU Power : 83.5425192865308 W\n",
      "[codecarbon INFO @ 13:21:05] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:21:05] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:21:05] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:21:05] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:21:05] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:21:05] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:21:05] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:21:05] Energy consumed for all GPUs : 0.072858 kWh. Total GPU Power : 153.39674638698676 W\n",
      "[codecarbon INFO @ 13:21:05] 0.243355 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 13:21:05] 0.047896 g.CO2eq/s mean an estimation of 1,510.4586841786806 kg.CO2eq/year\n",
      "Training  :  12%|█▏        | 73/625 [00:28<03:37,  2.54it/s, accuracy=0.894, loss=0.251][codecarbon INFO @ 13:21:20] Energy consumed for RAM : 0.132763 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:21:20] Energy consumed for all CPUs : 0.039256 kWh. Total CPU Power : 83.349721479963 W\n",
      "[codecarbon INFO @ 13:21:20] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:21:20] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:21:20] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:21:20] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:21:20] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:21:20] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:21:20] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:21:20] Energy consumed for all GPUs : 0.073516 kWh. Total GPU Power : 158.31389409480278 W\n",
      "[codecarbon INFO @ 13:21:20] 0.245535 kWh of electricity used since the beginning.\n",
      "Training  :  18%|█▊        | 111/625 [00:43<03:22,  2.54it/s, accuracy=0.889, loss=0.266][codecarbon INFO @ 13:21:35] Energy consumed for RAM : 0.133938 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:21:35] Energy consumed for all CPUs : 0.039602 kWh. Total CPU Power : 83.4093894574173 W\n",
      "[codecarbon INFO @ 13:21:35] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:21:35] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:21:35] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:21:35] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:21:35] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:21:35] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:21:35] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:21:35] Energy consumed for all GPUs : 0.074172 kWh. Total GPU Power : 157.92706848642496 W\n",
      "[codecarbon INFO @ 13:21:35] 0.247712 kWh of electricity used since the beginning.\n",
      "Training  :  24%|██▍       | 149/625 [00:58<03:07,  2.54it/s, accuracy=0.889, loss=0.268][codecarbon INFO @ 13:21:50] Energy consumed for RAM : 0.135112 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:21:50] Energy consumed for all CPUs : 0.039949 kWh. Total CPU Power : 83.43680713713267 W\n",
      "[codecarbon INFO @ 13:21:50] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:21:50] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:21:50] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:21:50] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:21:50] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:21:50] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:21:50] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:21:50] Energy consumed for all GPUs : 0.074824 kWh. Total GPU Power : 157.08995799974718 W\n",
      "[codecarbon INFO @ 13:21:50] 0.249885 kWh of electricity used since the beginning.\n",
      "Training  :  30%|██▉       | 187/625 [01:13<02:52,  2.53it/s, accuracy=0.891, loss=0.261][codecarbon INFO @ 13:22:05] Energy consumed for RAM : 0.136287 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:22:05] Energy consumed for all CPUs : 0.040295 kWh. Total CPU Power : 83.47986000602829 W\n",
      "[codecarbon INFO @ 13:22:05] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:22:05] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:22:05] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:22:05] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:22:05] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:22:05] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:22:05] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:22:05] Energy consumed for all GPUs : 0.075481 kWh. Total GPU Power : 158.2344587216796 W\n",
      "[codecarbon INFO @ 13:22:05] 0.252064 kWh of electricity used since the beginning.\n",
      "Training  :  36%|███▌      | 225/625 [01:28<02:37,  2.53it/s, accuracy=0.889, loss=0.265][codecarbon INFO @ 13:22:20] Energy consumed for RAM : 0.137462 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:22:20] Energy consumed for all CPUs : 0.040640 kWh. Total CPU Power : 82.99847922892715 W\n",
      "[codecarbon INFO @ 13:22:20] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:22:20] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:22:20] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:22:20] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:22:20] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:22:20] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:22:20] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:22:20] Energy consumed for all GPUs : 0.076133 kWh. Total GPU Power : 156.9262769641865 W\n",
      "[codecarbon INFO @ 13:22:20] 0.254235 kWh of electricity used since the beginning.\n",
      "Training  :  42%|████▏     | 263/625 [01:43<02:23,  2.53it/s, accuracy=0.888, loss=0.262][codecarbon INFO @ 13:22:35] Energy consumed for RAM : 0.138637 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:22:35] Energy consumed for all CPUs : 0.040986 kWh. Total CPU Power : 83.11895298323346 W\n",
      "[codecarbon INFO @ 13:22:35] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:22:35] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:22:35] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:22:35] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:22:35] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:22:35] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:22:35] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:22:35] Energy consumed for all GPUs : 0.076788 kWh. Total GPU Power : 157.57021374821338 W\n",
      "[codecarbon INFO @ 13:22:35] 0.256410 kWh of electricity used since the beginning.\n",
      "Training  :  48%|████▊     | 300/625 [01:58<02:08,  2.52it/s, accuracy=0.888, loss=0.265][codecarbon INFO @ 13:22:50] Energy consumed for RAM : 0.139812 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:22:50] Energy consumed for all CPUs : 0.041330 kWh. Total CPU Power : 82.96680868699228 W\n",
      "[codecarbon INFO @ 13:22:50] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:22:50] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:22:50] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:22:50] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:22:50] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:22:50] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:22:50] GPU number 7 will not be monitored, at your request.\n",
      "Training  :  48%|████▊     | 301/625 [01:58<02:08,  2.52it/s, accuracy=0.887, loss=0.265][codecarbon INFO @ 13:22:50] Energy consumed for all GPUs : 0.077442 kWh. Total GPU Power : 157.37456401939542 W\n",
      "[codecarbon INFO @ 13:22:50] 0.258584 kWh of electricity used since the beginning.\n",
      "Training  :  54%|█████▍    | 338/625 [02:13<01:53,  2.52it/s, accuracy=0.887, loss=0.266][codecarbon INFO @ 13:23:05] Energy consumed for RAM : 0.140987 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:23:05] Energy consumed for all CPUs : 0.041676 kWh. Total CPU Power : 83.22466860562356 W\n",
      "[codecarbon INFO @ 13:23:05] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:23:05] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:23:05] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:23:05] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:23:05] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:23:05] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:23:05] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:23:05] Energy consumed for all GPUs : 0.078092 kWh. Total GPU Power : 156.45166924832068 W\n",
      "[codecarbon INFO @ 13:23:05] 0.260754 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 13:23:05] 0.047947 g.CO2eq/s mean an estimation of 1,512.0607813718557 kg.CO2eq/year\n",
      "Training  :  60%|██████    | 376/625 [02:28<01:38,  2.52it/s, accuracy=0.888, loss=0.266][codecarbon INFO @ 13:23:20] Energy consumed for RAM : 0.142161 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:23:20] Energy consumed for all CPUs : 0.042022 kWh. Total CPU Power : 83.32218938614088 W\n",
      "[codecarbon INFO @ 13:23:20] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:23:20] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:23:20] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:23:20] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:23:20] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:23:20] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:23:20] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:23:20] Energy consumed for all GPUs : 0.078747 kWh. Total GPU Power : 157.73653830442646 W\n",
      "[codecarbon INFO @ 13:23:20] 0.262930 kWh of electricity used since the beginning.\n",
      "Training  :  66%|██████▌   | 414/625 [02:43<01:23,  2.52it/s, accuracy=0.888, loss=0.266][codecarbon INFO @ 13:23:35] Energy consumed for RAM : 0.143336 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:23:35] Energy consumed for all CPUs : 0.042366 kWh. Total CPU Power : 82.95011641903105 W\n",
      "[codecarbon INFO @ 13:23:35] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:23:35] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:23:35] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:23:35] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:23:35] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:23:35] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:23:35] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:23:35] Energy consumed for all GPUs : 0.079396 kWh. Total GPU Power : 156.22706441950893 W\n",
      "[codecarbon INFO @ 13:23:35] 0.265099 kWh of electricity used since the beginning.\n",
      "Training  :  72%|███████▏  | 452/625 [02:58<01:08,  2.51it/s, accuracy=0.889, loss=0.265][codecarbon INFO @ 13:23:50] Energy consumed for RAM : 0.144511 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:23:50] Energy consumed for all CPUs : 0.042713 kWh. Total CPU Power : 83.44576682306801 W\n",
      "[codecarbon INFO @ 13:23:50] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:23:50] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:23:50] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:23:50] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:23:50] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:23:50] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:23:50] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:23:50] Energy consumed for all GPUs : 0.080048 kWh. Total GPU Power : 157.1012672004363 W\n",
      "[codecarbon INFO @ 13:23:50] 0.267272 kWh of electricity used since the beginning.\n",
      "Training  :  78%|███████▊  | 489/625 [03:13<00:54,  2.51it/s, accuracy=0.889, loss=0.266][codecarbon INFO @ 13:24:05] Energy consumed for RAM : 0.145686 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:24:05] Energy consumed for all CPUs : 0.043059 kWh. Total CPU Power : 83.40826135113177 W\n",
      "[codecarbon INFO @ 13:24:05] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:24:05] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:24:05] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:24:05] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:24:05] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:24:05] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:24:05] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:24:05] Energy consumed for all GPUs : 0.080702 kWh. Total GPU Power : 157.37986629941858 W\n",
      "[codecarbon INFO @ 13:24:05] 0.269447 kWh of electricity used since the beginning.\n",
      "Training  :  84%|████████▍ | 527/625 [03:28<00:39,  2.51it/s, accuracy=0.888, loss=0.268][codecarbon INFO @ 13:24:20] Energy consumed for RAM : 0.146860 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:24:20] Energy consumed for all CPUs : 0.043405 kWh. Total CPU Power : 83.2643194585829 W\n",
      "[codecarbon INFO @ 13:24:20] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:24:20] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:24:20] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:24:20] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:24:20] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:24:20] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:24:20] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:24:20] Energy consumed for all GPUs : 0.081350 kWh. Total GPU Power : 156.12407695648164 W\n",
      "[codecarbon INFO @ 13:24:20] 0.271616 kWh of electricity used since the beginning.\n",
      "Training  :  90%|█████████ | 565/625 [03:43<00:23,  2.50it/s, accuracy=0.889, loss=0.267][codecarbon INFO @ 13:24:35] Energy consumed for RAM : 0.148035 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:24:35] Energy consumed for all CPUs : 0.043752 kWh. Total CPU Power : 83.54686633071806 W\n",
      "[codecarbon INFO @ 13:24:35] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:24:35] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:24:35] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:24:35] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:24:35] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:24:35] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:24:35] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:24:35] Energy consumed for all GPUs : 0.082001 kWh. Total GPU Power : 156.799665032188 W\n",
      "[codecarbon INFO @ 13:24:35] 0.273789 kWh of electricity used since the beginning.\n",
      "Training  :  96%|█████████▋| 602/625 [03:58<00:09,  2.50it/s, accuracy=0.889, loss=0.266][codecarbon INFO @ 13:24:50] Energy consumed for RAM : 0.149210 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:24:50] Energy consumed for all CPUs : 0.044099 kWh. Total CPU Power : 83.43256538182837 W\n",
      "[codecarbon INFO @ 13:24:50] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:24:50] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:24:50] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:24:50] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:24:50] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:24:50] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:24:50] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:24:50] Energy consumed for all GPUs : 0.082653 kWh. Total GPU Power : 156.92790591581738 W\n",
      "[codecarbon INFO @ 13:24:50] 0.275961 kWh of electricity used since the beginning.\n",
      "Training  : 100%|██████████| 625/625 [04:07<00:00,  2.52it/s, accuracy=0.889, loss=0.266]\n",
      "Evaluating:  20%|██        | 32/157 [00:06<00:23,  5.32it/s, accuracy=0.849, loss=0.372][codecarbon INFO @ 13:25:05] Energy consumed for RAM : 0.150384 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:25:05] Energy consumed for all CPUs : 0.044446 kWh. Total CPU Power : 83.55920902942279 W\n",
      "[codecarbon INFO @ 13:25:05] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:25:05] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:25:05] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:25:05] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:25:05] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:25:05] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:25:05] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:25:05] Energy consumed for all GPUs : 0.083303 kWh. Total GPU Power : 156.51823933597993 W\n",
      "[codecarbon INFO @ 13:25:05] 0.278133 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 13:25:05] 0.047890 g.CO2eq/s mean an estimation of 1,510.2633935607432 kg.CO2eq/year\n",
      "Evaluating:  71%|███████   | 111/157 [00:20<00:08,  5.30it/s, accuracy=0.857, loss=0.369][codecarbon INFO @ 13:25:20] Energy consumed for RAM : 0.151558 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:25:20] Energy consumed for all CPUs : 0.044797 kWh. Total CPU Power : 84.65059795615998 W\n",
      "[codecarbon INFO @ 13:25:20] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:25:20] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:25:20] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:25:20] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:25:20] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:25:20] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:25:20] GPU number 7 will not be monitored, at your request.\n",
      "Evaluating:  71%|███████▏  | 112/157 [00:21<00:08,  5.29it/s, accuracy=0.858, loss=0.367][codecarbon INFO @ 13:25:20] Energy consumed for all GPUs : 0.083964 kWh. Total GPU Power : 159.33028050378024 W\n",
      "[codecarbon INFO @ 13:25:20] 0.280319 kWh of electricity used since the beginning.\n",
      "Evaluating: 100%|██████████| 157/157 [00:29<00:00,  5.33it/s, accuracy=0.856, loss=0.369]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La loss sul validation set non è migliorata per 2 epoche.\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :   2%|▏         | 15/625 [00:05<03:59,  2.55it/s, accuracy=0.912, loss=0.221][codecarbon INFO @ 13:25:35] Energy consumed for RAM : 0.152733 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:25:35] Energy consumed for all CPUs : 0.045148 kWh. Total CPU Power : 84.4580375688146 W\n",
      "[codecarbon INFO @ 13:25:35] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:25:35] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:25:35] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:25:35] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:25:35] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:25:35] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:25:35] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:25:35] Energy consumed for all GPUs : 0.084602 kWh. Total GPU Power : 153.533412274929 W\n",
      "[codecarbon INFO @ 13:25:35] 0.282483 kWh of electricity used since the beginning.\n",
      "Training  :   8%|▊         | 53/625 [00:20<03:44,  2.54it/s, accuracy=0.899, loss=0.246][codecarbon INFO @ 13:25:50] Energy consumed for RAM : 0.153908 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:25:50] Energy consumed for all CPUs : 0.045495 kWh. Total CPU Power : 83.50253786654946 W\n",
      "[codecarbon INFO @ 13:25:50] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:25:50] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:25:50] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:25:50] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:25:50] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:25:50] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:25:50] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:25:50] Energy consumed for all GPUs : 0.085261 kWh. Total GPU Power : 158.58723596003966 W\n",
      "[codecarbon INFO @ 13:25:50] 0.284663 kWh of electricity used since the beginning.\n",
      "Training  :  15%|█▍        | 91/625 [00:35<03:30,  2.54it/s, accuracy=0.894, loss=0.256][codecarbon INFO @ 13:26:05] Energy consumed for RAM : 0.155082 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:26:05] Energy consumed for all CPUs : 0.045841 kWh. Total CPU Power : 83.31903760602714 W\n",
      "[codecarbon INFO @ 13:26:05] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:26:05] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:26:05] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:26:05] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:26:05] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:26:05] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:26:05] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:26:05] Energy consumed for all GPUs : 0.085917 kWh. Total GPU Power : 158.05230049983933 W\n",
      "[codecarbon INFO @ 13:26:05] 0.286840 kWh of electricity used since the beginning.\n",
      "Training  :  17%|█▋        | 109/625 [00:42<03:23,  2.54it/s, accuracy=0.896, loss=0.254]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training  :  21%|██        | 129/625 [00:50<03:15,  2.54it/s, accuracy=0.895, loss=0.258][codecarbon INFO @ 13:26:20] Energy consumed for RAM : 0.156257 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:26:20] Energy consumed for all CPUs : 0.046187 kWh. Total CPU Power : 83.32202573109076 W\n",
      "[codecarbon INFO @ 13:26:20] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:26:20] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:26:20] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:26:20] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:26:20] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:26:20] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:26:20] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:26:20] Energy consumed for all GPUs : 0.086569 kWh. Total GPU Power : 157.03141336420256 W\n",
      "[codecarbon INFO @ 13:26:20] 0.289013 kWh of electricity used since the beginning.\n",
      "Training  :  27%|██▋       | 167/625 [01:05<03:00,  2.53it/s, accuracy=0.894, loss=0.257][codecarbon INFO @ 13:26:35] Energy consumed for RAM : 0.157432 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:26:35] Energy consumed for all CPUs : 0.046534 kWh. Total CPU Power : 83.55957316629998 W\n",
      "[codecarbon INFO @ 13:26:35] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:26:35] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:26:35] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:26:35] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:26:35] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:26:35] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:26:35] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:26:35] Energy consumed for all GPUs : 0.087227 kWh. Total GPU Power : 158.12527941797444 W\n",
      "[codecarbon INFO @ 13:26:35] 0.291193 kWh of electricity used since the beginning.\n",
      "Training  :  33%|███▎      | 205/625 [01:20<02:46,  2.53it/s, accuracy=0.895, loss=0.257][codecarbon INFO @ 13:26:50] Energy consumed for RAM : 0.158608 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:26:50] Energy consumed for all CPUs : 0.046880 kWh. Total CPU Power : 83.24139969372328 W\n",
      "[codecarbon INFO @ 13:26:50] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:26:50] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:26:50] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:26:50] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:26:50] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:26:50] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:26:50] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:26:50] Energy consumed for all GPUs : 0.087879 kWh. Total GPU Power : 156.91415603958853 W\n",
      "[codecarbon INFO @ 13:26:50] 0.293366 kWh of electricity used since the beginning.\n",
      "Training  :  39%|███▉      | 243/625 [01:35<02:31,  2.53it/s, accuracy=0.896, loss=0.254][codecarbon INFO @ 13:27:05] Energy consumed for RAM : 0.159782 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:27:05] Energy consumed for all CPUs : 0.047225 kWh. Total CPU Power : 83.20005721004584 W\n",
      "[codecarbon INFO @ 13:27:05] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:27:05] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:27:05] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:27:05] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:27:05] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:27:05] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:27:05] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:27:05] Energy consumed for all GPUs : 0.088534 kWh. Total GPU Power : 157.6944426236192 W\n",
      "[codecarbon INFO @ 13:27:05] 0.295541 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 13:27:05] 0.047983 g.CO2eq/s mean an estimation of 1,513.1971073436987 kg.CO2eq/year\n",
      "Training  :  45%|████▍     | 281/625 [01:50<02:16,  2.52it/s, accuracy=0.897, loss=0.254][codecarbon INFO @ 13:27:20] Energy consumed for RAM : 0.160958 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:27:20] Energy consumed for all CPUs : 0.047571 kWh. Total CPU Power : 83.19864283813378 W\n",
      "[codecarbon INFO @ 13:27:20] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:27:20] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:27:20] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:27:20] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:27:20] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:27:20] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:27:20] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:27:20] Energy consumed for all GPUs : 0.089188 kWh. Total GPU Power : 157.59394946845688 W\n",
      "[codecarbon INFO @ 13:27:20] 0.297717 kWh of electricity used since the beginning.\n",
      "Training  :  51%|█████     | 319/625 [02:05<02:01,  2.52it/s, accuracy=0.894, loss=0.256][codecarbon INFO @ 13:27:35] Energy consumed for RAM : 0.162132 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:27:35] Energy consumed for all CPUs : 0.047917 kWh. Total CPU Power : 83.46833073443321 W\n",
      "[codecarbon INFO @ 13:27:35] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:27:35] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:27:35] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:27:35] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:27:35] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:27:35] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:27:35] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:27:35] Energy consumed for all GPUs : 0.089838 kWh. Total GPU Power : 156.4212704759787 W\n",
      "[codecarbon INFO @ 13:27:35] 0.299888 kWh of electricity used since the beginning.\n",
      "Training  :  57%|█████▋    | 357/625 [02:20<01:46,  2.52it/s, accuracy=0.895, loss=0.254][codecarbon INFO @ 13:27:50] Energy consumed for RAM : 0.163307 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:27:50] Energy consumed for all CPUs : 0.048264 kWh. Total CPU Power : 83.51091234555972 W\n",
      "[codecarbon INFO @ 13:27:50] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:27:50] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:27:50] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:27:50] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:27:50] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:27:50] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:27:50] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:27:50] Energy consumed for all GPUs : 0.090493 kWh. Total GPU Power : 157.63964076685326 W\n",
      "[codecarbon INFO @ 13:27:50] 0.302063 kWh of electricity used since the beginning.\n",
      "Training  :  63%|██████▎   | 394/625 [02:35<01:31,  2.52it/s, accuracy=0.895, loss=0.254][codecarbon INFO @ 13:28:05] Energy consumed for RAM : 0.164481 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:28:05] Energy consumed for all CPUs : 0.048612 kWh. Total CPU Power : 83.64937069273073 W\n",
      "[codecarbon INFO @ 13:28:05] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:28:05] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:28:05] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:28:05] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:28:05] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:28:05] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:28:05] GPU number 7 will not be monitored, at your request.\n",
      "Training  :  63%|██████▎   | 395/625 [02:36<01:31,  2.52it/s, accuracy=0.895, loss=0.254][codecarbon INFO @ 13:28:05] Energy consumed for all GPUs : 0.091142 kWh. Total GPU Power : 156.35107137290746 W\n",
      "[codecarbon INFO @ 13:28:05] 0.304235 kWh of electricity used since the beginning.\n",
      "Training  :  69%|██████▉   | 432/625 [02:50<01:16,  2.52it/s, accuracy=0.894, loss=0.255][codecarbon INFO @ 13:28:20] Energy consumed for RAM : 0.165656 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:28:20] Energy consumed for all CPUs : 0.048959 kWh. Total CPU Power : 83.63778719773542 W\n",
      "[codecarbon INFO @ 13:28:20] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:28:20] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:28:20] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:28:20] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:28:20] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:28:20] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:28:20] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:28:20] Energy consumed for all GPUs : 0.091795 kWh. Total GPU Power : 157.25181580333987 W\n",
      "[codecarbon INFO @ 13:28:20] 0.306411 kWh of electricity used since the beginning.\n",
      "Training  :  75%|███████▌  | 470/625 [03:05<01:01,  2.51it/s, accuracy=0.895, loss=0.253][codecarbon INFO @ 13:28:35] Energy consumed for RAM : 0.166831 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:28:35] Energy consumed for all CPUs : 0.049305 kWh. Total CPU Power : 83.3637505770317 W\n",
      "[codecarbon INFO @ 13:28:35] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:28:35] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:28:35] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:28:35] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:28:35] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:28:35] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:28:35] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:28:35] Energy consumed for all GPUs : 0.092448 kWh. Total GPU Power : 157.2171193643499 W\n",
      "[codecarbon INFO @ 13:28:35] 0.308585 kWh of electricity used since the beginning.\n",
      "Training  :  81%|████████▏ | 508/625 [03:20<00:46,  2.51it/s, accuracy=0.894, loss=0.257][codecarbon INFO @ 13:28:50] Energy consumed for RAM : 0.168006 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:28:50] Energy consumed for all CPUs : 0.049652 kWh. Total CPU Power : 83.41352695616061 W\n",
      "[codecarbon INFO @ 13:28:50] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:28:50] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:28:50] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:28:50] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:28:50] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:28:50] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:28:50] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:28:50] Energy consumed for all GPUs : 0.093097 kWh. Total GPU Power : 156.19293958242474 W\n",
      "[codecarbon INFO @ 13:28:50] 0.310755 kWh of electricity used since the beginning.\n",
      "Training  :  87%|████████▋ | 545/625 [03:35<00:31,  2.51it/s, accuracy=0.895, loss=0.255][codecarbon INFO @ 13:29:05] Energy consumed for RAM : 0.169181 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:29:05] Energy consumed for all CPUs : 0.049999 kWh. Total CPU Power : 83.6555568769777 W\n",
      "[codecarbon INFO @ 13:29:05] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:29:05] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:29:05] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:29:05] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:29:05] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:29:05] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:29:05] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:29:05] Energy consumed for all GPUs : 0.093751 kWh. Total GPU Power : 157.37645708240402 W\n",
      "[codecarbon INFO @ 13:29:05] 0.312931 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 13:29:05] 0.047921 g.CO2eq/s mean an estimation of 1,511.237664298803 kg.CO2eq/year\n",
      "Training  :  93%|█████████▎| 583/625 [03:50<00:16,  2.50it/s, accuracy=0.895, loss=0.254][codecarbon INFO @ 13:29:20] Energy consumed for RAM : 0.170355 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:29:20] Energy consumed for all CPUs : 0.050346 kWh. Total CPU Power : 83.45403753354567 W\n",
      "[codecarbon INFO @ 13:29:20] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:29:20] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:29:20] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:29:20] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:29:20] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:29:20] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:29:20] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:29:20] Energy consumed for all GPUs : 0.094396 kWh. Total GPU Power : 155.47749700391253 W\n",
      "[codecarbon INFO @ 13:29:20] 0.315098 kWh of electricity used since the beginning.\n",
      "Training  :  99%|█████████▉| 620/625 [04:05<00:01,  2.50it/s, accuracy=0.896, loss=0.254][codecarbon INFO @ 13:29:35] Energy consumed for RAM : 0.171530 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:29:35] Energy consumed for all CPUs : 0.050691 kWh. Total CPU Power : 83.04300334074875 W\n",
      "[codecarbon INFO @ 13:29:35] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:29:35] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:29:35] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:29:35] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:29:35] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:29:35] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:29:35] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:29:35] Energy consumed for all GPUs : 0.095048 kWh. Total GPU Power : 156.8811833876148 W\n",
      "[codecarbon INFO @ 13:29:35] 0.317269 kWh of electricity used since the beginning.\n",
      "Training  : 100%|██████████| 625/625 [04:07<00:00,  2.52it/s, accuracy=0.895, loss=0.254]\n",
      "Evaluating:  45%|████▍     | 70/157 [00:13<00:16,  5.31it/s, accuracy=0.852, loss=0.398][codecarbon INFO @ 13:29:50] Energy consumed for RAM : 0.172706 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:29:50] Energy consumed for all CPUs : 0.051041 kWh. Total CPU Power : 84.37688260151685 W\n",
      "[codecarbon INFO @ 13:29:50] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:29:50] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:29:50] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:29:50] GPU number 3 will not be monitored, at your request.\n",
      "Evaluating:  45%|████▍     | 70/157 [00:13<00:16,  5.31it/s, accuracy=0.85, loss=0.4]   [codecarbon INFO @ 13:29:50] GPU number 4 will not be monitored, at your request.\n",
      "Evaluating:  45%|████▌     | 71/157 [00:13<00:16,  5.29it/s, accuracy=0.85, loss=0.4][codecarbon INFO @ 13:29:50] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:29:50] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:29:50] Energy consumed for all GPUs : 0.095708 kWh. Total GPU Power : 158.69307920018753 W\n",
      "[codecarbon INFO @ 13:29:50] 0.319455 kWh of electricity used since the beginning.\n",
      "Evaluating:  96%|█████████▌| 150/157 [00:28<00:01,  5.28it/s, accuracy=0.852, loss=0.381][codecarbon INFO @ 13:30:05] Energy consumed for RAM : 0.173880 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:30:05] Energy consumed for all CPUs : 0.051392 kWh. Total CPU Power : 84.34121681375568 W\n",
      "[codecarbon INFO @ 13:30:05] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:30:05] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:30:05] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:30:05] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:30:05] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:30:05] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:30:05] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:30:05] Energy consumed for all GPUs : 0.096363 kWh. Total GPU Power : 157.82214177856957 W\n",
      "[codecarbon INFO @ 13:30:05] 0.321635 kWh of electricity used since the beginning.\n",
      "Evaluating: 100%|██████████| 157/157 [00:29<00:00,  5.33it/s, accuracy=0.853, loss=0.379]\n",
      "[codecarbon INFO @ 13:30:06] Energy consumed for RAM : 0.173966 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 13:30:06] Energy consumed for all CPUs : 0.051418 kWh. Total CPU Power : 87.83881427949409 W\n",
      "[codecarbon INFO @ 13:30:06] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:30:06] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:30:06] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:30:06] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:30:06] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:30:06] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:30:06] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 13:30:06] Energy consumed for all GPUs : 0.096412 kWh. Total GPU Power : 159.93540017278445 W\n",
      "[codecarbon INFO @ 13:30:06] 0.321797 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La loss sul validation set non è migliorata per 3 epoche.\n",
      "Early stopping attivato dopo 3 epoche senza miglioramenti\n",
      "\n",
      "Emissioni CO₂ totali: 0.1064 kg\n",
      "\n",
      "BERT with LoRA Training Time: 2221.19 seconds, 37.02 minutes.\n"
     ]
    }
   ],
   "source": [
    "history, total_time, emissions = train_and_evaluate_model(\n",
    "    lora_model,\"qqp\", qqp_train_loader, qqp_val_loader, optimizer, scheduler, device, epochs=EPOCHS \n",
    ") \n",
    "print(f\"\\nBERT with LoRA Training Time: {total_time:.2f} seconds, {total_time/60:.2f} minutes.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 157/157 [00:29<00:00,  5.31it/s, accuracy=0.869, loss=0.341]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA Fine-Tuning - Test loss: 0.3412, Accuracy: 0.8688, F1 score: 0.8686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lora_model.load_state_dict(torch.load(\"qqp_best_model_state.bin\"))\n",
    "test_loss, test_acc, test_f1 = eval_model(lora_model, qqp_test_loader, device)\n",
    "print(f\"LoRA Fine-Tuning - Test loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}, F1 score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Task  Training Time  CO2 Emissions  Test Loss  Accuracy  F1 Score\n",
      "0  rte     297.863470       0.014207   0.578640  0.718412  0.715291\n",
      "1  qqp    2221.192307       0.106424   0.341209  0.868800  0.868641\n"
     ]
    }
   ],
   "source": [
    "add_task_results(\n",
    "    task_name=\"qqp\", \n",
    "    training_time=total_time,\n",
    "    emissions=emissions,\n",
    "    test_loss=test_loss,\n",
    "    test_acc=test_acc,\n",
    "    test_f1=test_f1,\n",
    ")\n",
    "\n",
    "performance = pd.DataFrame(model_performance)\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 8551\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 1043\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 1063\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Ottenimento del dataset\n",
    "cola_dataset = load_dataset(\"glue\", \"cola\")\n",
    "print(cola_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensioni dei set:\n",
      "Train: 7674\n",
      "Validation: 960\n",
      "Test: 960\n",
      "\n",
      "Distribuzione delle etichette:\n",
      "Train: Counter({1: 5394, 0: 2280})\n",
      "Validation: Counter({1: 675, 0: 285})\n",
      "Test: Counter({1: 675, 0: 285})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "cola_train_data = pd.DataFrame(cola_dataset[\"train\"])\n",
    "cola_val_data = pd.DataFrame(cola_dataset[\"validation\"])\n",
    "\n",
    "cola_data = Dataset.from_pandas(pd.concat([cola_train_data, cola_val_data], ignore_index=True))\n",
    "cola_data = cola_data.shuffle(seed=42)\n",
    "\n",
    "cola_temp_sentences, cola_test_sentences, cola_temp_labels, cola_test_labels = train_test_split(\n",
    "                                                cola_data['sentence'],\n",
    "                                                cola_data['label'], \n",
    "                                                test_size=0.1, \n",
    "                                                random_state=42,\n",
    "                                                stratify=cola_data['label'])\n",
    "\n",
    "cola_train_sentences, cola_val_sentences, cola_train_labels, cola_val_labels = train_test_split(\n",
    "                                                cola_temp_sentences, \n",
    "                                                cola_temp_labels,\n",
    "                                                test_size=0.1111,\n",
    "                                                random_state=42,\n",
    "                                                stratify=cola_temp_labels)\n",
    "\n",
    "print(\"Dimensioni dei set:\")\n",
    "print(f\"Train: {len(cola_train_sentences)}\")\n",
    "print(f\"Validation: {len(cola_val_sentences)}\")\n",
    "print(f\"Test: {len(cola_test_sentences)}\")\n",
    "\n",
    "# Verifica distribuzione delle etichette\n",
    "print(\"\\nDistribuzione delle etichette:\")\n",
    "print(f\"Train: {Counter(cola_train_labels)}\")\n",
    "print(f\"Validation: {Counter(cola_val_labels)}\")\n",
    "print(f\"Test: {Counter(cola_test_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 128\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Inizializzo il Tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Ottiengo i dataset\n",
    "cola_training_data = ClassificationDataset(sentences = cola_train_sentences,\n",
    "                           labels = cola_train_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)\n",
    "\n",
    "cola_validation_data = ClassificationDataset(sentences = cola_val_sentences,\n",
    "                           labels = cola_val_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)\n",
    "\n",
    "cola_test_data = ClassificationDataset(sentences = cola_test_sentences,\n",
    "                           labels = cola_test_labels,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 125,531,906 || trainable%: 0.7048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): RobertaForSequenceClassification(\n",
       "      (roberta): RobertaModel(\n",
       "        (embeddings): RobertaEmbeddings(\n",
       "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): RobertaEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSdpaSelfAttention(\n",
       "                  (query): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.3, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (key): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.3, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (value): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.3, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (classifier): RobertaClassificationHead(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Pretrained model\n",
    "lora_model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2)\n",
    "\n",
    "# LoRA config\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=128,\n",
    "    lora_dropout=0.3,\n",
    "    target_modules=[\"query\", \"key\", \"value\"],  \n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "lora_model = get_peft_model(lora_model, lora_config)\n",
    "lora_model.print_trainable_parameters()\n",
    "lora_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametri principali\n",
    "learning_rate = 1e-4\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Creo i DataLoader\n",
    "cola_train_loader = DataLoader( cola_training_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "cola_val_loader = DataLoader( cola_validation_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "cola_test_loader = DataLoader( cola_test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "total_steps = len( cola_train_loader) * EPOCHS\n",
    "\n",
    "# Ottimizzatore\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, lora_model.parameters()), lr = learning_rate)\n",
    "\n",
    "\n",
    "# Scheduler\n",
    "scheduler = transformers.get_cosine_schedule_with_warmup(optimizer = optimizer,\n",
    "                                                       num_warmup_steps = 0,\n",
    "                                                       num_training_steps = total_steps) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 16:03:54] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 16:03:54] [setup] CPU Tracking...\n",
      "[codecarbon INFO @ 16:03:54] Tracking Intel CPU via RAPL interface\n",
      "[codecarbon INFO @ 16:03:56] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 16:03:56] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 16:03:56] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:03:56] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:03:56] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:03:56] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:03:56] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:03:56] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:03:56] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon WARNING @ 16:03:56] You have 8 GPUs but we will monitor only 1 of them. Check your configuration.\n",
      "[codecarbon INFO @ 16:03:56] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 16:03:56]   Platform system: Linux-6.8.0-56-generic-x86_64-with-glibc2.39\n",
      "[codecarbon INFO @ 16:03:56]   Python version: 3.12.3\n",
      "[codecarbon INFO @ 16:03:56]   CodeCarbon version: 2.8.3\n",
      "[codecarbon INFO @ 16:03:56]   Available RAM : 754.342 GB\n",
      "[codecarbon INFO @ 16:03:56]   CPU count: 96\n",
      "[codecarbon INFO @ 16:03:56]   CPU model: Intel(R) Xeon(R) Gold 6248R CPU @ 3.00GHz\n",
      "[codecarbon INFO @ 16:03:56]   GPU count: 1\n",
      "[codecarbon INFO @ 16:03:56]   GPU model: 8 x NVIDIA A30 BUT only tracking these GPU ids : [6]\n",
      "[codecarbon INFO @ 16:03:59] Saving emissions data to file /home/notebook/riccardo_cantini/tesisti/Dagostino/carbon_emissions/emissions.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :  30%|███       | 73/240 [00:14<00:32,  5.07it/s, accuracy=0.643, loss=0.638][codecarbon INFO @ 16:04:14] Energy consumed for RAM : 0.001182 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 16:04:14] Energy consumed for all CPUs : 0.000349 kWh. Total CPU Power : 83.48923747060185 W\n",
      "[codecarbon INFO @ 16:04:14] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:04:14] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:04:14] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:04:14] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:04:14] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:04:14] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:04:14] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:04:14] Energy consumed for all GPUs : 0.000609 kWh. Total GPU Power : 145.76014200847553 W\n",
      "[codecarbon INFO @ 16:04:14] 0.002140 kWh of electricity used since the beginning.\n",
      "Training  :  62%|██████▏   | 149/240 [00:29<00:18,  5.03it/s, accuracy=0.68, loss=0.582][codecarbon INFO @ 16:04:29] Energy consumed for RAM : 0.002357 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 16:04:29] Energy consumed for all CPUs : 0.000694 kWh. Total CPU Power : 83.15864441144042 W\n",
      "[codecarbon INFO @ 16:04:29] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:04:29] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:04:29] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:04:29] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:04:29] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:04:29] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:04:29] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:04:29] Energy consumed for all GPUs : 0.001227 kWh. Total GPU Power : 148.7938906081495 W\n",
      "[codecarbon INFO @ 16:04:29] 0.004278 kWh of electricity used since the beginning.\n",
      "Training  :  92%|█████████▎| 222/240 [00:44<00:03,  5.01it/s, accuracy=0.707, loss=0.555][codecarbon INFO @ 16:04:44] Energy consumed for RAM : 0.003532 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 16:04:44] Energy consumed for all CPUs : 0.001040 kWh. Total CPU Power : 83.22704879301754 W\n",
      "[codecarbon INFO @ 16:04:44] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:04:44] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:04:44] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:04:44] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:04:44] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:04:44] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:04:44] GPU number 7 will not be monitored, at your request.\n",
      "Training  :  93%|█████████▎| 223/240 [00:45<00:03,  5.01it/s, accuracy=0.707, loss=0.556][codecarbon INFO @ 16:04:44] Energy consumed for all GPUs : 0.001834 kWh. Total GPU Power : 146.07913448748172 W\n",
      "[codecarbon INFO @ 16:04:44] 0.006406 kWh of electricity used since the beginning.\n",
      "Training  : 100%|██████████| 240/240 [00:48<00:00,  4.96it/s, accuracy=0.711, loss=0.552]\n",
      "Evaluating: 100%|██████████| 30/30 [00:02<00:00, 10.21it/s, accuracy=0.807, loss=0.479]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :  17%|█▋        | 41/240 [00:08<00:39,  5.06it/s, accuracy=0.776, loss=0.474][codecarbon INFO @ 16:04:59] Energy consumed for RAM : 0.004707 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 16:04:59] Energy consumed for all CPUs : 0.001388 kWh. Total CPU Power : 83.74108921921771 W\n",
      "[codecarbon INFO @ 16:04:59] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:04:59] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:04:59] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:04:59] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:04:59] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:04:59] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:04:59] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:04:59] Energy consumed for all GPUs : 0.002453 kWh. Total GPU Power : 148.96488129152468 W\n",
      "[codecarbon INFO @ 16:04:59] 0.008548 kWh of electricity used since the beginning.\n",
      "Training  :  49%|████▉     | 117/240 [00:23<00:24,  5.04it/s, accuracy=0.781, loss=0.464][codecarbon INFO @ 16:05:14] Energy consumed for RAM : 0.005881 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 16:05:14] Energy consumed for all CPUs : 0.001734 kWh. Total CPU Power : 83.35721401743169 W\n",
      "[codecarbon INFO @ 16:05:14] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:05:14] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:05:14] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:05:14] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:05:14] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:05:14] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:05:14] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:05:14] Energy consumed for all GPUs : 0.003079 kWh. Total GPU Power : 150.6886936858373 W\n",
      "[codecarbon INFO @ 16:05:14] 0.010694 kWh of electricity used since the beginning.\n",
      "Training  :  80%|████████  | 192/240 [00:38<00:09,  5.02it/s, accuracy=0.789, loss=0.454][codecarbon INFO @ 16:05:29] Energy consumed for RAM : 0.007056 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 16:05:29] Energy consumed for all CPUs : 0.002080 kWh. Total CPU Power : 83.33862221925544 W\n",
      "[codecarbon INFO @ 16:05:29] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:05:29] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:05:29] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:05:29] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:05:29] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:05:29] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:05:29] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:05:29] Energy consumed for all GPUs : 0.003704 kWh. Total GPU Power : 150.68281115498394 W\n",
      "[codecarbon INFO @ 16:05:29] 0.012840 kWh of electricity used since the beginning.\n",
      "Training  : 100%|██████████| 240/240 [00:47<00:00,  5.04it/s, accuracy=0.794, loss=0.45] \n",
      "Evaluating: 100%|██████████| 30/30 [00:02<00:00, 10.21it/s, accuracy=0.807, loss=0.48] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La loss sul validation set non è migliorata per 1 epoche.\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :   5%|▌         | 13/240 [00:02<00:44,  5.07it/s, accuracy=0.841, loss=0.354][codecarbon INFO @ 16:05:44] Energy consumed for RAM : 0.008231 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 16:05:44] Energy consumed for all CPUs : 0.002427 kWh. Total CPU Power : 83.56697842564606 W\n",
      "[codecarbon INFO @ 16:05:44] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:05:44] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:05:44] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:05:44] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:05:44] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:05:44] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:05:44] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:05:44] Energy consumed for all GPUs : 0.004343 kWh. Total GPU Power : 153.6702141784767 W\n",
      "[codecarbon INFO @ 16:05:44] 0.015001 kWh of electricity used since the beginning.\n",
      "Training  :  37%|███▋      | 88/240 [00:17<00:30,  5.03it/s, accuracy=0.831, loss=0.392][codecarbon INFO @ 16:05:59] Energy consumed for RAM : 0.009405 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 16:05:59] Energy consumed for all CPUs : 0.002777 kWh. Total CPU Power : 84.10811456576772 W\n",
      "[codecarbon INFO @ 16:05:59] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:05:59] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:05:59] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:05:59] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:05:59] GPU number 4 will not be monitored, at your request.\n",
      "Training  :  37%|███▋      | 88/240 [00:17<00:30,  5.03it/s, accuracy=0.83, loss=0.394] [codecarbon INFO @ 16:05:59] GPU number 5 will not be monitored, at your request.\n",
      "Training  :  37%|███▋      | 89/240 [00:17<00:30,  5.02it/s, accuracy=0.83, loss=0.394][codecarbon INFO @ 16:05:59] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:05:59] Energy consumed for all GPUs : 0.004977 kWh. Total GPU Power : 152.69014771115428 W\n",
      "[codecarbon INFO @ 16:05:59] 0.017159 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 16:05:59] 0.047250 g.CO2eq/s mean an estimation of 1,490.0852983271168 kg.CO2eq/year\n",
      "Training  :  68%|██████▊   | 164/240 [00:32<00:15,  5.00it/s, accuracy=0.824, loss=0.402][codecarbon INFO @ 16:06:14] Energy consumed for RAM : 0.010580 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 16:06:14] Energy consumed for all CPUs : 0.003127 kWh. Total CPU Power : 84.30403811920314 W\n",
      "[codecarbon INFO @ 16:06:14] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:06:14] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:06:14] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:06:14] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:06:14] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:06:14] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:06:14] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:06:14] Energy consumed for all GPUs : 0.005616 kWh. Total GPU Power : 153.87866772267165 W\n",
      "[codecarbon INFO @ 16:06:14] 0.019322 kWh of electricity used since the beginning.\n",
      "Training  : 100%|█████████▉| 239/240 [00:47<00:00,  4.98it/s, accuracy=0.821, loss=0.404][codecarbon INFO @ 16:06:29] Energy consumed for RAM : 0.011755 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 16:06:29] Energy consumed for all CPUs : 0.003477 kWh. Total CPU Power : 84.27243971081376 W\n",
      "[codecarbon INFO @ 16:06:29] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:06:29] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:06:29] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:06:29] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:06:29] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:06:29] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:06:29] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:06:29] Energy consumed for all GPUs : 0.006251 kWh. Total GPU Power : 152.8962773446042 W\n",
      "[codecarbon INFO @ 16:06:29] 0.021482 kWh of electricity used since the beginning.\n",
      "Training  : 100%|██████████| 240/240 [00:47<00:00,  5.02it/s, accuracy=0.821, loss=0.404]\n",
      "Evaluating: 100%|██████████| 30/30 [00:02<00:00, 10.16it/s, accuracy=0.832, loss=0.425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :  24%|██▍       | 57/240 [00:11<00:36,  5.02it/s, accuracy=0.847, loss=0.371][codecarbon INFO @ 16:06:44] Energy consumed for RAM : 0.012929 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 16:06:44] Energy consumed for all CPUs : 0.003827 kWh. Total CPU Power : 84.44884301760244 W\n",
      "[codecarbon INFO @ 16:06:44] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:06:44] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:06:44] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:06:44] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:06:44] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:06:44] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:06:44] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:06:44] Energy consumed for all GPUs : 0.006882 kWh. Total GPU Power : 151.78283926410847 W\n",
      "[codecarbon INFO @ 16:06:44] 0.023638 kWh of electricity used since the beginning.\n",
      "Training  :  55%|█████▌    | 132/240 [00:26<00:21,  5.00it/s, accuracy=0.833, loss=0.391][codecarbon INFO @ 16:06:59] Energy consumed for RAM : 0.014103 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 16:06:59] Energy consumed for all CPUs : 0.004176 kWh. Total CPU Power : 83.92388534294334 W\n",
      "[codecarbon INFO @ 16:06:59] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:06:59] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:06:59] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:06:59] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:06:59] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:06:59] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:06:59] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:06:59] Energy consumed for all GPUs : 0.007527 kWh. Total GPU Power : 155.5722339697601 W\n",
      "[codecarbon INFO @ 16:06:59] 0.025807 kWh of electricity used since the beginning.\n",
      "Training  :  86%|████████▌ | 206/240 [00:41<00:06,  4.97it/s, accuracy=0.84, loss=0.379][codecarbon INFO @ 16:07:14] Energy consumed for RAM : 0.015279 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 16:07:14] Energy consumed for all CPUs : 0.004525 kWh. Total CPU Power : 84.04009754940611 W\n",
      "[codecarbon INFO @ 16:07:14] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:07:14] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:07:14] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:07:14] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:07:14] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:07:14] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:07:14] GPU number 7 will not be monitored, at your request.\n",
      "Training  :  86%|████████▋ | 207/240 [00:41<00:06,  4.97it/s, accuracy=0.841, loss=0.378][codecarbon INFO @ 16:07:14] Energy consumed for all GPUs : 0.008167 kWh. Total GPU Power : 153.815789737495 W\n",
      "[codecarbon INFO @ 16:07:14] 0.027970 kWh of electricity used since the beginning.\n",
      "Training  : 100%|██████████| 240/240 [00:47<00:00,  5.00it/s, accuracy=0.842, loss=0.375]\n",
      "Evaluating: 100%|██████████| 30/30 [00:02<00:00, 10.11it/s, accuracy=0.831, loss=0.455]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La loss sul validation set non è migliorata per 1 epoche.\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :  11%|█         | 26/240 [00:05<00:42,  5.02it/s, accuracy=0.853, loss=0.351][codecarbon INFO @ 16:07:29] Energy consumed for RAM : 0.016454 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 16:07:29] Energy consumed for all CPUs : 0.004875 kWh. Total CPU Power : 84.30310264237264 W\n",
      "[codecarbon INFO @ 16:07:29] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:07:29] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:07:29] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:07:29] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:07:29] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:07:29] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:07:29] GPU number 7 will not be monitored, at your request.\n",
      "Training  :  11%|█▏        | 27/240 [00:05<00:42,  5.03it/s, accuracy=0.856, loss=0.347][codecarbon INFO @ 16:07:29] Energy consumed for all GPUs : 0.008815 kWh. Total GPU Power : 156.1777881942408 W\n",
      "[codecarbon INFO @ 16:07:29] 0.030144 kWh of electricity used since the beginning.\n",
      "Training  :  42%|████▎     | 102/240 [00:20<00:27,  5.00it/s, accuracy=0.861, loss=0.332][codecarbon INFO @ 16:07:44] Energy consumed for RAM : 0.017629 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 16:07:44] Energy consumed for all CPUs : 0.005225 kWh. Total CPU Power : 84.28958518884221 W\n",
      "[codecarbon INFO @ 16:07:44] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:07:44] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:07:44] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:07:44] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:07:44] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:07:44] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:07:44] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:07:44] Energy consumed for all GPUs : 0.009464 kWh. Total GPU Power : 156.19507715353186 W\n",
      "[codecarbon INFO @ 16:07:44] 0.032318 kWh of electricity used since the beginning.\n",
      "Training  :  73%|███████▎  | 176/240 [00:35<00:12,  4.97it/s, accuracy=0.861, loss=0.336][codecarbon INFO @ 16:07:59] Energy consumed for RAM : 0.018803 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 16:07:59] Energy consumed for all CPUs : 0.005573 kWh. Total CPU Power : 83.90538268368275 W\n",
      "[codecarbon INFO @ 16:07:59] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:07:59] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:07:59] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:07:59] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:07:59] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:07:59] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:07:59] GPU number 7 will not be monitored, at your request.\n",
      "Training  :  74%|███████▍  | 177/240 [00:35<00:12,  4.97it/s, accuracy=0.861, loss=0.336][codecarbon INFO @ 16:07:59] Energy consumed for all GPUs : 0.010107 kWh. Total GPU Power : 154.85366327419945 W\n",
      "[codecarbon INFO @ 16:07:59] 0.034483 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 16:07:59] 0.047749 g.CO2eq/s mean an estimation of 1,505.8170707383126 kg.CO2eq/year\n",
      "Training  : 100%|██████████| 240/240 [00:48<00:00,  4.99it/s, accuracy=0.859, loss=0.339]\n",
      "Evaluating:  73%|███████▎  | 22/30 [00:02<00:00, 10.10it/s, accuracy=0.846, loss=0.392][codecarbon INFO @ 16:08:14] Energy consumed for RAM : 0.019978 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 16:08:14] Energy consumed for all CPUs : 0.005922 kWh. Total CPU Power : 83.98935828979326 W\n",
      "[codecarbon INFO @ 16:08:14] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:08:14] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:08:14] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:08:14] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:08:14] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:08:14] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:08:14] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:08:14] Energy consumed for all GPUs : 0.010754 kWh. Total GPU Power : 155.66898684656636 W\n",
      "[codecarbon INFO @ 16:08:14] 0.036655 kWh of electricity used since the beginning.\n",
      "Evaluating: 100%|██████████| 30/30 [00:02<00:00, 10.10it/s, accuracy=0.843, loss=0.414]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :  28%|██▊       | 68/240 [00:13<00:34,  5.01it/s, accuracy=0.876, loss=0.31][codecarbon INFO @ 16:08:29] Energy consumed for RAM : 0.021153 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 16:08:29] Energy consumed for all CPUs : 0.006273 kWh. Total CPU Power : 84.42256538493629 W\n",
      "[codecarbon INFO @ 16:08:29] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:08:29] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:08:29] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:08:29] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:08:29] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:08:29] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:08:29] GPU number 7 will not be monitored, at your request.\n",
      "Training  :  29%|██▉       | 69/240 [00:13<00:34,  5.00it/s, accuracy=0.876, loss=0.31][codecarbon INFO @ 16:08:29] Energy consumed for all GPUs : 0.011384 kWh. Total GPU Power : 151.73741399794588 W\n",
      "[codecarbon INFO @ 16:08:29] 0.038810 kWh of electricity used since the beginning.\n",
      "Training  :  60%|█████▉    | 143/240 [00:28<00:19,  4.99it/s, accuracy=0.869, loss=0.316][codecarbon INFO @ 16:08:44] Energy consumed for RAM : 0.022327 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 16:08:44] Energy consumed for all CPUs : 0.006622 kWh. Total CPU Power : 83.98826879996439 W\n",
      "[codecarbon INFO @ 16:08:44] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:08:44] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:08:44] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:08:44] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:08:44] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:08:44] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:08:44] GPU number 7 will not be monitored, at your request.\n",
      "Training  :  60%|██████    | 144/240 [00:28<00:19,  4.99it/s, accuracy=0.869, loss=0.316][codecarbon INFO @ 16:08:44] Energy consumed for all GPUs : 0.012029 kWh. Total GPU Power : 155.24457863017727 W\n",
      "[codecarbon INFO @ 16:08:44] 0.040978 kWh of electricity used since the beginning.\n",
      "Training  :  91%|█████████ | 218/240 [00:43<00:04,  4.96it/s, accuracy=0.866, loss=0.319][codecarbon INFO @ 16:08:59] Energy consumed for RAM : 0.023502 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 16:08:59] Energy consumed for all CPUs : 0.006971 kWh. Total CPU Power : 84.0483392135702 W\n",
      "[codecarbon INFO @ 16:08:59] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:08:59] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:08:59] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:08:59] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:08:59] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:08:59] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:08:59] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:08:59] Energy consumed for all GPUs : 0.012679 kWh. Total GPU Power : 156.528597632 W\n",
      "[codecarbon INFO @ 16:08:59] 0.043151 kWh of electricity used since the beginning.\n",
      "Training  : 100%|██████████| 240/240 [00:48<00:00,  4.99it/s, accuracy=0.866, loss=0.32] \n",
      "Evaluating: 100%|██████████| 30/30 [00:02<00:00, 10.10it/s, accuracy=0.838, loss=0.448]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La loss sul validation set non è migliorata per 1 epoche.\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :  16%|█▌        | 38/240 [00:07<00:40,  5.02it/s, accuracy=0.877, loss=0.304][codecarbon INFO @ 16:09:14] Energy consumed for RAM : 0.024677 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 16:09:14] Energy consumed for all CPUs : 0.007321 kWh. Total CPU Power : 84.35950472893319 W\n",
      "[codecarbon INFO @ 16:09:14] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:09:14] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:09:14] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:09:14] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:09:14] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:09:14] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:09:14] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:09:14] Energy consumed for all GPUs : 0.013324 kWh. Total GPU Power : 155.42573648824484 W\n",
      "[codecarbon INFO @ 16:09:14] 0.045322 kWh of electricity used since the beginning.\n",
      "Training  :  47%|████▋     | 113/240 [00:22<00:25,  4.99it/s, accuracy=0.882, loss=0.298][codecarbon INFO @ 16:09:29] Energy consumed for RAM : 0.025852 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 16:09:29] Energy consumed for all CPUs : 0.007669 kWh. Total CPU Power : 83.63393916394986 W\n",
      "[codecarbon INFO @ 16:09:29] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:09:29] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:09:29] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:09:29] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:09:29] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:09:29] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:09:29] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:09:29] Energy consumed for all GPUs : 0.013972 kWh. Total GPU Power : 155.74565194037265 W\n",
      "[codecarbon INFO @ 16:09:29] 0.047492 kWh of electricity used since the beginning.\n",
      "Training  :  78%|███████▊  | 188/240 [00:37<00:10,  4.96it/s, accuracy=0.876, loss=0.3][codecarbon INFO @ 16:09:44] Energy consumed for RAM : 0.027027 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 16:09:44] Energy consumed for all CPUs : 0.008017 kWh. Total CPU Power : 83.78272656899317 W\n",
      "[codecarbon INFO @ 16:09:44] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:09:44] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:09:44] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:09:44] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:09:44] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:09:44] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:09:44] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:09:44] Energy consumed for all GPUs : 0.014617 kWh. Total GPU Power : 155.4017358914099 W\n",
      "[codecarbon INFO @ 16:09:44] 0.049660 kWh of electricity used since the beginning.\n",
      "Training  : 100%|██████████| 240/240 [00:48<00:00,  4.99it/s, accuracy=0.874, loss=0.305]\n",
      "Evaluating: 100%|██████████| 30/30 [00:02<00:00, 10.10it/s, accuracy=0.836, loss=0.455]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La loss sul validation set non è migliorata per 2 epoche.\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  :   3%|▎         | 8/240 [00:01<00:46,  5.02it/s, accuracy=0.879, loss=0.309][codecarbon INFO @ 16:09:59] Energy consumed for RAM : 0.028201 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 16:09:59] Energy consumed for all CPUs : 0.008366 kWh. Total CPU Power : 84.2008595632613 W\n",
      "[codecarbon INFO @ 16:09:59] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:09:59] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:09:59] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:09:59] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:09:59] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:09:59] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:09:59] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:09:59] Energy consumed for all GPUs : 0.015267 kWh. Total GPU Power : 156.3621305089876 W\n",
      "[codecarbon INFO @ 16:09:59] 0.051834 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 16:09:59] 0.047817 g.CO2eq/s mean an estimation of 1,507.944352945938 kg.CO2eq/year\n",
      "Training  :  35%|███▍      | 83/240 [00:16<00:31,  5.00it/s, accuracy=0.888, loss=0.282][codecarbon INFO @ 16:10:14] Energy consumed for RAM : 0.029376 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 16:10:14] Energy consumed for all CPUs : 0.008713 kWh. Total CPU Power : 83.34164086700508 W\n",
      "[codecarbon INFO @ 16:10:14] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:10:14] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:10:14] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:10:14] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:10:14] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:10:14] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:10:14] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:10:14] Energy consumed for all GPUs : 0.015915 kWh. Total GPU Power : 156.12367448253295 W\n",
      "[codecarbon INFO @ 16:10:14] 0.054004 kWh of electricity used since the beginning.\n",
      "Training  :  66%|██████▌   | 158/240 [00:31<00:16,  4.97it/s, accuracy=0.885, loss=0.286][codecarbon INFO @ 16:10:29] Energy consumed for RAM : 0.030551 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 16:10:29] Energy consumed for all CPUs : 0.009060 kWh. Total CPU Power : 83.63588524353172 W\n",
      "[codecarbon INFO @ 16:10:29] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:10:29] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:10:29] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:10:29] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:10:29] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:10:29] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:10:29] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:10:29] Energy consumed for all GPUs : 0.016559 kWh. Total GPU Power : 155.0177722456842 W\n",
      "[codecarbon INFO @ 16:10:29] 0.056170 kWh of electricity used since the beginning.\n",
      "Training  :  97%|█████████▋| 232/240 [00:46<00:01,  4.95it/s, accuracy=0.883, loss=0.292][codecarbon INFO @ 16:10:44] Energy consumed for RAM : 0.031726 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 16:10:44] Energy consumed for all CPUs : 0.009407 kWh. Total CPU Power : 83.54963179215059 W\n",
      "[codecarbon INFO @ 16:10:44] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:10:44] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:10:44] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:10:44] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:10:44] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:10:44] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:10:44] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:10:44] Energy consumed for all GPUs : 0.017201 kWh. Total GPU Power : 154.68864453938426 W\n",
      "[codecarbon INFO @ 16:10:44] 0.058334 kWh of electricity used since the beginning.\n",
      "Training  : 100%|██████████| 240/240 [00:48<00:00,  4.99it/s, accuracy=0.882, loss=0.293]\n",
      "Evaluating: 100%|██████████| 30/30 [00:02<00:00, 10.10it/s, accuracy=0.847, loss=0.451]\n",
      "[codecarbon INFO @ 16:10:49] Energy consumed for RAM : 0.032118 kWh. RAM Power : 282.878173828125 W\n",
      "[codecarbon INFO @ 16:10:49] Energy consumed for all CPUs : 0.009524 kWh. Total CPU Power : 84.43275935672511 W\n",
      "[codecarbon INFO @ 16:10:49] GPU number 0 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:10:49] GPU number 1 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:10:49] GPU number 2 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:10:49] GPU number 3 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:10:49] GPU number 4 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:10:49] GPU number 5 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:10:49] GPU number 7 will not be monitored, at your request.\n",
      "[codecarbon INFO @ 16:10:49] Energy consumed for all GPUs : 0.017409 kWh. Total GPU Power : 149.95440341081778 W\n",
      "[codecarbon INFO @ 16:10:49] 0.059051 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La loss sul validation set non è migliorata per 3 epoche.\n",
      "Early stopping attivato dopo 3 epoche senza miglioramenti\n",
      "\n",
      "Emissioni CO₂ totali: 0.0195 kg\n",
      "\n",
      "BERT with LoRA Training Time: 410.06 seconds, 6.83 minutes.\n"
     ]
    }
   ],
   "source": [
    "history, total_time, emissions = train_and_evaluate_model(\n",
    "    lora_model,\" cola\",  cola_train_loader,  cola_val_loader, optimizer, scheduler, device, epochs=EPOCHS \n",
    ") \n",
    "print(f\"\\nBERT with LoRA Training Time: {total_time:.2f} seconds, {total_time/60:.2f} minutes.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 30/30 [00:02<00:00, 10.06it/s, accuracy=0.84, loss=0.461] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA Fine-Tuning - Test loss: 0.4453, Accuracy: 0.8396, F1 score: 0.7896\n"
     ]
    }
   ],
   "source": [
    "lora_model.load_state_dict(torch.load(\" cola_best_model_state.bin\"))\n",
    "test_loss, test_acc, test_f1 = eval_model(lora_model,  cola_test_loader, device)\n",
    "print(f\"LoRA Fine-Tuning - Test loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}, F1 score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Task  Training Time  CO2 Emissions  Test Loss  Accuracy  F1 Score\n",
      "0  cola     410.057021       0.019529   0.445322  0.839583  0.789574\n"
     ]
    }
   ],
   "source": [
    "add_task_results(\n",
    "    task_name=\"cola\", \n",
    "    training_time=total_time,\n",
    "    emissions=emissions,\n",
    "    test_loss=test_loss,\n",
    "    test_acc=test_acc,\n",
    "    test_f1=test_f1,\n",
    ")\n",
    "\n",
    "performance = pd.DataFrame(model_performance)\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4095790,
     "sourceId": 7104655,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6601208,
     "sourceId": 10784419,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python tesisti_RC (GPU 6)",
   "language": "python",
   "name": "tesisti_rc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
