{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11a102c4",
   "metadata": {
    "papermill": {
     "duration": 0.009734,
     "end_time": "2025-01-19T22:47:41.747135",
     "exception": false,
     "start_time": "2025-01-19T22:47:41.737401",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Contronto tra il fine-tuning completo e il fine-tuning con  LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8aed22b",
   "metadata": {
    "papermill": {
     "duration": 0.008793,
     "end_time": "2025-01-19T22:47:41.764945",
     "exception": false,
     "start_time": "2025-01-19T22:47:41.756152",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Configurazioni"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434d3f24",
   "metadata": {
    "papermill": {
     "duration": 0.008476,
     "end_time": "2025-01-19T22:47:41.782006",
     "exception": false,
     "start_time": "2025-01-19T22:47:41.773530",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Installazione della libreria `loralib` per implementare la Low-Rank Adaptation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a06ade3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T22:47:41.801897Z",
     "iopub.status.busy": "2025-01-19T22:47:41.801673Z",
     "iopub.status.idle": "2025-01-19T22:47:46.437414Z",
     "shell.execute_reply": "2025-01-19T22:47:46.436489Z"
    },
    "papermill": {
     "duration": 4.646504,
     "end_time": "2025-01-19T22:47:46.438960",
     "exception": false,
     "start_time": "2025-01-19T22:47:41.792456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting loralib\r\n",
      "  Downloading loralib-0.1.2-py3-none-any.whl.metadata (15 kB)\r\n",
      "Downloading loralib-0.1.2-py3-none-any.whl (10 kB)\r\n",
      "Installing collected packages: loralib\r\n",
      "Successfully installed loralib-0.1.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install loralib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effdeca6",
   "metadata": {
    "papermill": {
     "duration": 0.008846,
     "end_time": "2025-01-19T22:47:46.457612",
     "exception": false,
     "start_time": "2025-01-19T22:47:46.448766",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Carico i file `lora_utilis.py` e `models.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6c40a3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T22:47:46.476393Z",
     "iopub.status.busy": "2025-01-19T22:47:46.476118Z",
     "iopub.status.idle": "2025-01-19T22:47:46.479433Z",
     "shell.execute_reply": "2025-01-19T22:47:46.478785Z"
    },
    "papermill": {
     "duration": 0.014101,
     "end_time": "2025-01-19T22:47:46.480716",
     "exception": false,
     "start_time": "2025-01-19T22:47:46.466615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/kaggle/input/lora-utils/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4843484d",
   "metadata": {
    "papermill": {
     "duration": 0.0089,
     "end_time": "2025-01-19T22:47:46.498571",
     "exception": false,
     "start_time": "2025-01-19T22:47:46.489671",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Importo i moduli necessari."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d072240",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T22:47:46.517237Z",
     "iopub.status.busy": "2025-01-19T22:47:46.517028Z",
     "iopub.status.idle": "2025-01-19T22:47:50.703693Z",
     "shell.execute_reply": "2025-01-19T22:47:50.702140Z"
    },
    "papermill": {
     "duration": 4.198795,
     "end_time": "2025-01-19T22:47:50.706366",
     "exception": false,
     "start_time": "2025-01-19T22:47:46.507571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "import lora_utils, models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9b81da",
   "metadata": {
    "papermill": {
     "duration": 0.010183,
     "end_time": "2025-01-19T22:47:50.730407",
     "exception": false,
     "start_time": "2025-01-19T22:47:50.720224",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Impostazione del seme casuale per la riproducibilità."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e96e99b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T22:47:50.763978Z",
     "iopub.status.busy": "2025-01-19T22:47:50.763602Z",
     "iopub.status.idle": "2025-01-19T22:47:50.824842Z",
     "shell.execute_reply": "2025-01-19T22:47:50.824062Z"
    },
    "papermill": {
     "duration": 0.078784,
     "end_time": "2025-01-19T22:47:50.826373",
     "exception": false,
     "start_time": "2025-01-19T22:47:50.747589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed_value = 42\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "torch.manual_seed(seed_value)\n",
    "\n",
    "# Imposto il seme casuale anche per i calcoli CUDA\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)  \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca0b31a",
   "metadata": {
    "papermill": {
     "duration": 0.008917,
     "end_time": "2025-01-19T22:47:50.845614",
     "exception": false,
     "start_time": "2025-01-19T22:47:50.836697",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Sentiment Analisys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaa42b8",
   "metadata": {
    "papermill": {
     "duration": 0.009035,
     "end_time": "2025-01-19T22:47:50.863623",
     "exception": false,
     "start_time": "2025-01-19T22:47:50.854588",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1. Ottenimento dei dati e preprocessing\n",
    "\n",
    "Confronto il fine-tuning completo e quello basato su LoRA sul task di Sentiment Analysis utilizzando il dataset IMDB Reviews.  \n",
    "\n",
    "Il dataset IMDB è costituito da 50.000 recensioni di film, etichettate con **positive** se la recensione è positiva o **negative**, altrimenti.  \n",
    "\n",
    "Utilizzo la libreria `kagglehub` per scaricare il dataset da Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "930c6b2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T22:47:50.894734Z",
     "iopub.status.busy": "2025-01-19T22:47:50.894475Z",
     "iopub.status.idle": "2025-01-19T22:47:52.667797Z",
     "shell.execute_reply": "2025-01-19T22:47:52.666826Z"
    },
    "papermill": {
     "duration": 1.791558,
     "end_time": "2025-01-19T22:47:52.669104",
     "exception": false,
     "start_time": "2025-01-19T22:47:50.877546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "review       0\n",
      "sentiment    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Scarico l'ultima versione del dataset\n",
    "path = kagglehub.dataset_download(\"lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\")\n",
    "\n",
    "dataset_path = path + \"/IMDB Dataset.csv\"\n",
    "dataset = pd.read_csv(dataset_path)\n",
    "\n",
    "# Stampa di verifica\n",
    "print(dataset.loc[0:4])\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2f6021",
   "metadata": {
    "papermill": {
     "duration": 0.00908,
     "end_time": "2025-01-19T22:47:52.687744",
     "exception": false,
     "start_time": "2025-01-19T22:47:52.678664",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Definisco una funzione per l'ottenimento dei dati e la loro divisione in training, validation e test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42b81c97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T22:47:52.707015Z",
     "iopub.status.busy": "2025-01-19T22:47:52.706763Z",
     "iopub.status.idle": "2025-01-19T22:47:52.710094Z",
     "shell.execute_reply": "2025-01-19T22:47:52.709432Z"
    },
    "papermill": {
     "duration": 0.014045,
     "end_time": "2025-01-19T22:47:52.711186",
     "exception": false,
     "start_time": "2025-01-19T22:47:52.697141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LABELS = {\"negative\": 0, \"positive\": 1}\n",
    "classes = list(LABELS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ec5608a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T22:47:52.729966Z",
     "iopub.status.busy": "2025-01-19T22:47:52.729742Z",
     "iopub.status.idle": "2025-01-19T22:47:52.737968Z",
     "shell.execute_reply": "2025-01-19T22:47:52.737322Z"
    },
    "papermill": {
     "duration": 0.018977,
     "end_time": "2025-01-19T22:47:52.739112",
     "exception": false,
     "start_time": "2025-01-19T22:47:52.720135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data(dataset_path, n_train=5000, n_val=500, n_test=512): \n",
    "\n",
    "    # Leggo il dataset\n",
    "    dataset = pd.read_csv(dataset_path)\n",
    "\n",
    "    # Converto le etichette in numeri\n",
    "    dataset['sentiment'] = dataset[\"sentiment\"].map(LABELS)\n",
    "\n",
    "    # Divido gli esempi in negativi e positivi\n",
    "    neg = dataset[ dataset['sentiment'] == LABELS['negative'] ]\n",
    "    pos = dataset[ dataset['sentiment'] == LABELS['positive'] ]\n",
    "\n",
    "    # Verifico che ci siano abbastanza esempi\n",
    "    if len(neg) < n_train + n_val + n_test or len(pos) < n_train + n_val + n_test:\n",
    "        raise ValueError(\"Non ci sono abbastanza esempi per le dimensioni del train, validation e test set specificate.\")\n",
    "    \n",
    "    # Creo una permutazione degli esempi negativi e positivi\n",
    "    neg = neg.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    pos = pos.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    # Seleziono gli elementi da inserire nei set\n",
    "    neg_train, pos_train = neg[:n_train], pos[:n_train]\n",
    "    neg_val, pos_val = neg[n_train:n_train+n_val], pos[n_train:n_train+n_val]\n",
    "    neg_test, pos_test = neg[n_train+n_val:n_train+n_val+n_test], pos[n_train+n_val:n_train+n_val+n_test]\n",
    "\n",
    "    # Concateno gli esempi negativi e positivi per formare un solo insieme\n",
    "    train_data = pd.concat([neg_train, pos_train])\n",
    "    val_data = pd.concat([neg_val, pos_val])\n",
    "    test_data = pd.concat([neg_test, pos_test])\n",
    "\n",
    "    # Mescolo i dati negli insiemi\n",
    "    train_data = train_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    val_data = val_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    test_data = test_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    # Ottengo le features e le labels\n",
    "    sentences_train, labels_train = train_data['review'] , train_data['sentiment']\n",
    "    sentences_val, labels_val = val_data['review'] , val_data['sentiment']\n",
    "    sentences_test, labels_test = test_data['review'] , test_data['sentiment']\n",
    "\n",
    "    return sentences_train, labels_train, sentences_val, labels_val, sentences_test, labels_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dc3ff6",
   "metadata": {
    "papermill": {
     "duration": 0.008888,
     "end_time": "2025-01-19T22:47:52.756950",
     "exception": false,
     "start_time": "2025-01-19T22:47:52.748062",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Creo una classe Dataset personalizzata in cui viene effettuata la tokenizzaione delle recensioni e la conversione dei dati in tensori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21ab79df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T22:47:52.775707Z",
     "iopub.status.busy": "2025-01-19T22:47:52.775491Z",
     "iopub.status.idle": "2025-01-19T22:47:52.780421Z",
     "shell.execute_reply": "2025-01-19T22:47:52.779762Z"
    },
    "papermill": {
     "duration": 0.015712,
     "end_time": "2025-01-19T22:47:52.781611",
     "exception": false,
     "start_time": "2025-01-19T22:47:52.765899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class IMDBDataset(Dataset):\n",
    "\n",
    "    def __init__(self, sentences, labels, tokenizer, max_len):\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        sentence = self.sentences[index]\n",
    "        label = self.labels[index]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            sentence,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True,\n",
    "            padding=\"max_length\",\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt')\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'token_type_ids': encoding[\"token_type_ids\"].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.float)         # usa torch.tensor visto che label è uno scalare \n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c2cf7f",
   "metadata": {
    "papermill": {
     "duration": 0.008817,
     "end_time": "2025-01-19T22:47:52.799375",
     "exception": false,
     "start_time": "2025-01-19T22:47:52.790558",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Ottengo i dati grezzi, li divido in training, validation e test set con la funzione `get_data()`. Inizializzo il Tokenizer BERT per tokenizzare le frasi e creo i dataset personalizzati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "994cc1de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T22:47:52.819084Z",
     "iopub.status.busy": "2025-01-19T22:47:52.818883Z",
     "iopub.status.idle": "2025-01-19T22:47:55.240535Z",
     "shell.execute_reply": "2025-01-19T22:47:55.239572Z"
    },
    "papermill": {
     "duration": 2.433826,
     "end_time": "2025-01-19T22:47:55.242062",
     "exception": false,
     "start_time": "2025-01-19T22:47:52.808236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6502cf67fe64b268abc84bd11c3a020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "600eb3ae763f4b2494569e6a4dc242b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61029a4ed71e4e53ba0a6efa9dfa8c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a82e08f287e4e7e894139502759c7d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "MAX_SEQ_LEN = 128\n",
    "\n",
    "# Ottieni i dati grezzi\n",
    "sentences_train, labels_train, sentences_val, labels_val, sentences_test, labels_test = get_data(dataset_path)\n",
    "\n",
    "# Inizializza il Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "#Ottieni i dataset\n",
    "training_data = IMDBDataset(sentences = sentences_train,\n",
    "                           labels = labels_train,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)\n",
    "\n",
    "validation_data = IMDBDataset(sentences = sentences_val.values,\n",
    "                           labels = labels_val.values,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)\n",
    "\n",
    "test_data = IMDBDataset(sentences = sentences_test.values,\n",
    "                           labels = labels_test.values,\n",
    "                           tokenizer = tokenizer,\n",
    "                           max_len = MAX_SEQ_LEN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502b585a",
   "metadata": {
    "papermill": {
     "duration": 0.009481,
     "end_time": "2025-01-19T22:47:55.261515",
     "exception": false,
     "start_time": "2025-01-19T22:47:55.252034",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 2. Configurazione dei modelli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcb67ed",
   "metadata": {
    "papermill": {
     "duration": 0.009592,
     "end_time": "2025-01-19T22:47:55.280551",
     "exception": false,
     "start_time": "2025-01-19T22:47:55.270959",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Definisco un classificatore basato su BERT. Utilizzo il modello BERT pre-addestrato e aggiungo un livello di pooling e un layer lineare con un solo neurone di output per la classificazione binaria. Se il parametro lora è attivo, integra LoRA nel modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "922cf505",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T22:47:55.300916Z",
     "iopub.status.busy": "2025-01-19T22:47:55.300637Z",
     "iopub.status.idle": "2025-01-19T22:47:56.324055Z",
     "shell.execute_reply": "2025-01-19T22:47:56.323076Z"
    },
    "papermill": {
     "duration": 1.035487,
     "end_time": "2025-01-19T22:47:56.325718",
     "exception": false,
     "start_time": "2025-01-19T22:47:55.290231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "class BERTClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, lora: bool = False, r: int = 16):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.avg_pooling = nn.AdaptiveAvgPool1d(1) \n",
    "        self.linear = nn.Linear(self.bert.config.hidden_size, 1)\n",
    "\n",
    "        if lora:\n",
    "            print(\"Adding LoRA to BERT\")\n",
    "            lora_utils.add_lora_to_bert(self.bert, r=r)\n",
    "            lora_utils.mark_only_lora_as_trainable(self.bert)\n",
    "\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output_bert = self.bert(\n",
    "            input_ids, \n",
    "            attention_mask=attention_mask, \n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        last_hidden_state = output_bert.last_hidden_state  \n",
    "        avg_pooled = self.avg_pooling(last_hidden_state.transpose(1, 2)).squeeze(-1)\n",
    "        logits = self.linear(avg_pooled)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "443c3e0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T22:47:56.347320Z",
     "iopub.status.busy": "2025-01-19T22:47:56.346907Z",
     "iopub.status.idle": "2025-01-19T22:47:56.350474Z",
     "shell.execute_reply": "2025-01-19T22:47:56.349696Z"
    },
    "papermill": {
     "duration": 0.015912,
     "end_time": "2025-01-19T22:47:56.351683",
     "exception": false,
     "start_time": "2025-01-19T22:47:56.335771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7945bfae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T22:47:56.371236Z",
     "iopub.status.busy": "2025-01-19T22:47:56.371006Z",
     "iopub.status.idle": "2025-01-19T22:47:59.051924Z",
     "shell.execute_reply": "2025-01-19T22:47:59.051014Z"
    },
    "papermill": {
     "duration": 2.692196,
     "end_time": "2025-01-19T22:47:59.053244",
     "exception": false,
     "start_time": "2025-01-19T22:47:56.361048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a006fcb76c4648b81242d2c960eac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BERTClassifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (avg_pooling): AdaptiveAvgPool1d(output_size=1)\n",
       "  (linear): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODELLO BERT \n",
    "full_model = BERTClassifier(lora=False)\n",
    "full_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ce8931f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T22:47:59.073874Z",
     "iopub.status.busy": "2025-01-19T22:47:59.073608Z",
     "iopub.status.idle": "2025-01-19T22:47:59.816094Z",
     "shell.execute_reply": "2025-01-19T22:47:59.815186Z"
    },
    "papermill": {
     "duration": 0.75406,
     "end_time": "2025-01-19T22:47:59.817472",
     "exception": false,
     "start_time": "2025-01-19T22:47:59.063412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding LoRA to BERT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BERTClassifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (avg_pooling): AdaptiveAvgPool1d(output_size=1)\n",
       "  (linear): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODELLO CON LORA\n",
    "lora_model = BERTClassifier(lora=True, r=16)\n",
    "lora_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11e5742",
   "metadata": {
    "papermill": {
     "duration": 0.010989,
     "end_time": "2025-01-19T22:47:59.838728",
     "exception": false,
     "start_time": "2025-01-19T22:47:59.827739",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3. Addestramento dei modelli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225d5627",
   "metadata": {
    "papermill": {
     "duration": 0.009524,
     "end_time": "2025-01-19T22:47:59.857919",
     "exception": false,
     "start_time": "2025-01-19T22:47:59.848395",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Definisco una serie di funzioni per l'addestramento e la valutazione di un modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0af52f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T22:47:59.878611Z",
     "iopub.status.busy": "2025-01-19T22:47:59.878345Z",
     "iopub.status.idle": "2025-01-19T22:48:00.903102Z",
     "shell.execute_reply": "2025-01-19T22:48:00.902376Z"
    },
    "papermill": {
     "duration": 1.036687,
     "end_time": "2025-01-19T22:48:00.904701",
     "exception": false,
     "start_time": "2025-01-19T22:47:59.868014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "# Funzione di training e valutazione\n",
    "def train_and_evaluate_model(model, model_name, train_loader, val_loader, criterion, optimizer, scheduler, device, epochs=4):\n",
    "    \n",
    "    history = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "    best_accuracy = 0\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "    \n",
    "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Training\n",
    "        train_loss, train_acc = train_model(model, train_loader, criterion, optimizer, scheduler, device)\n",
    "        print(f\"Train loss: {train_loss:.4f}, Train accuracy: {train_acc:.4f}\")\n",
    " \n",
    "        # Valutazione sul validation set\n",
    "        val_loss, val_acc, val_f1, val_auc = eval_model(model, val_loader, criterion, device)\n",
    "        print(f\"Validation loss: {val_loss:.4f}, Validation accuracy: {val_acc:.4f}\")\n",
    " \n",
    "        # Salvataggio del modello migliore\n",
    "        if val_acc > best_accuracy:\n",
    "            torch.save(model.state_dict(), f\"imbd_best_{model_name}_state.bin\")\n",
    "            best_accuracy = val_acc\n",
    "\n",
    "        # Salvo le metriche\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    total_training_time = end_time - start_time\n",
    "    \n",
    "    return history, total_training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caa6f0c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T22:48:00.925832Z",
     "iopub.status.busy": "2025-01-19T22:48:00.925413Z",
     "iopub.status.idle": "2025-01-19T22:48:00.931518Z",
     "shell.execute_reply": "2025-01-19T22:48:00.930851Z"
    },
    "papermill": {
     "duration": 0.017797,
     "end_time": "2025-01-19T22:48:00.932655",
     "exception": false,
     "start_time": "2025-01-19T22:48:00.914858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Funzione di training \n",
    "def train_model(model, data_loader, criterion, optimizer, scheduler, device):\n",
    "  \n",
    "    model = model.train() # imposto il modello in modalità di aggiornamento\n",
    "    \n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch in data_loader:\n",
    "        \n",
    "        # Sposto i dati sul device\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        labels = batch[\"labels\"].unsqueeze(1).to(device)\n",
    "\n",
    "        #  --- Forward pass ---\n",
    "        \n",
    "        # Azzero il gradiente\n",
    "        optimizer.zero_grad()\n",
    " \n",
    "        # Effettuo la previsione per il batch corrente\n",
    "        outputs = model(\n",
    "            input_ids = input_ids,\n",
    "            attention_mask = attention_mask,\n",
    "            token_type_ids = token_type_ids\n",
    "        )# output contiene i valori grezzi non normalizzati prodotti dal modello per ogni classe.\n",
    "\n",
    "        #outputs = outputs.logits  # Estrai i logits\n",
    "\n",
    "        # Calcolo la loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "\n",
    "        # --- Backward pass ---\n",
    "        \n",
    "        # Calcolo i gradienti della loss\n",
    "        loss.backward()\n",
    "\n",
    "        # Effettuo il clipping dei gradienti\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        # Aggiorno i pesi\n",
    "        optimizer.step()\n",
    "\n",
    "        # Aggiorno il learning rate\n",
    "        scheduler.step()\n",
    "\n",
    "        # Salvo la loss, le previsioni e le etichette\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        preds = (torch.sigmoid(outputs) > 0.5).long()    # trasformo i dati grezzi in etichette binarie\n",
    "        \n",
    "        all_preds.extend(preds.detach().cpu().numpy())\n",
    "        all_labels.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "    # Calcolo la loss e le metriche\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "   \n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d0dc67b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T22:48:00.953163Z",
     "iopub.status.busy": "2025-01-19T22:48:00.952934Z",
     "iopub.status.idle": "2025-01-19T22:48:00.958926Z",
     "shell.execute_reply": "2025-01-19T22:48:00.958319Z"
    },
    "papermill": {
     "duration": 0.017539,
     "end_time": "2025-01-19T22:48:00.959994",
     "exception": false,
     "start_time": "2025-01-19T22:48:00.942455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Funzione di valutazione\n",
    "def eval_model(model, data_loader, criterion, device):\n",
    "    \n",
    "    model = model.eval()    # imposto il modello in modalità valutavione\n",
    "\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            \n",
    "            # Sposto i dati sul device\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            token_type_ids = batch['token_type_ids'].to(device)\n",
    "            labels = batch['labels'].unsqueeze(1).to(device)\n",
    "\n",
    "            # Effettuo la previsione per il batch corrente\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids = token_type_ids\n",
    "            )\n",
    "            #outputs = outputs.logits  # Estrai i logits\n",
    "            \n",
    "            # Calcolo la loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Aggiorno la loss, salvo le previsioni e le etichette\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "            probs = torch.sigmoid(outputs)  # Calcolo le probabilità\n",
    "\n",
    "            preds = (probs > 0.5).long()  # Trasformo in etichette binarie\n",
    "            \n",
    "            all_preds.extend(preds.detach().cpu().numpy())\n",
    "            all_labels.extend(labels.detach().cpu().numpy())\n",
    "            all_probs.extend(probs.detach().cpu().numpy())\n",
    "\n",
    "        # Calcolo loss e metriche\n",
    "        avg_loss = total_loss / len(data_loader)\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n",
    "        roc_auc = roc_auc_score(all_labels, all_probs, average='weighted', multi_class='ovr')\n",
    "    \n",
    "    return avg_loss, accuracy, f1, roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a59f2eb",
   "metadata": {
    "papermill": {
     "duration": 0.009523,
     "end_time": "2025-01-19T22:48:00.979219",
     "exception": false,
     "start_time": "2025-01-19T22:48:00.969696",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Definisco le configurazion principali per il training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19d78f56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T22:48:00.999599Z",
     "iopub.status.busy": "2025-01-19T22:48:00.999390Z",
     "iopub.status.idle": "2025-01-19T22:48:01.579631Z",
     "shell.execute_reply": "2025-01-19T22:48:01.578897Z"
    },
    "papermill": {
     "duration": 0.592292,
     "end_time": "2025-01-19T22:48:01.581404",
     "exception": false,
     "start_time": "2025-01-19T22:48:00.989112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parametri principali\n",
    "learning_rate = 3e-5\n",
    "EPOCHS = 4\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "# Creo i DataLoader\n",
    "train_loader = DataLoader(training_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(validation_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "\n",
    "# Funzione di loss\n",
    "criterion = torch.nn.BCEWithLogitsLoss() # Applica automaticamente la sigmoide\n",
    "\n",
    "\n",
    "# Ottimizzatore\n",
    "optimizer = torch.optim.AdamW(params = full_model.parameters(), lr = learning_rate)\n",
    "\n",
    "# Scheduler\n",
    "scheduler = transformers.get_linear_schedule_with_warmup(optimizer = optimizer,\n",
    "                                                       num_warmup_steps = 0,\n",
    "                                                       num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0c04ee7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T22:48:01.603818Z",
     "iopub.status.busy": "2025-01-19T22:48:01.603372Z",
     "iopub.status.idle": "2025-01-19T22:59:07.936575Z",
     "shell.execute_reply": "2025-01-19T22:59:07.935624Z"
    },
    "papermill": {
     "duration": 666.346132,
     "end_time": "2025-01-19T22:59:07.937990",
     "exception": false,
     "start_time": "2025-01-19T22:48:01.591858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "Train loss: 0.3672, Train accuracy: 0.8342\n",
      "Validation loss: 0.3072, Validation accuracy: 0.8660\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "Train loss: 0.1908, Train accuracy: 0.9284\n",
      "Validation loss: 0.3086, Validation accuracy: 0.8900\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "Train loss: 0.0862, Train accuracy: 0.9722\n",
      "Validation loss: 0.4209, Validation accuracy: 0.8870\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "Train loss: 0.0362, Train accuracy: 0.9902\n",
      "Validation loss: 0.5490, Validation accuracy: 0.8820\n",
      "\n",
      "BERT Training Time: 666.33 seconds, 11.11 minutes.\n"
     ]
    }
   ],
   "source": [
    "history_bert, total_time_bert = train_and_evaluate_model(\n",
    "    full_model, \"full_model\", train_loader, val_loader, criterion, optimizer, scheduler, device, epochs=4\n",
    ")\n",
    "print(f\"\\nBERT Training Time: {total_time_bert:.2f} seconds, {total_time_bert/60:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f6edeb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T22:59:07.998769Z",
     "iopub.status.busy": "2025-01-19T22:59:07.998468Z",
     "iopub.status.idle": "2025-01-19T22:59:08.005747Z",
     "shell.execute_reply": "2025-01-19T22:59:08.005084Z"
    },
    "papermill": {
     "duration": 0.057577,
     "end_time": "2025-01-19T22:59:08.007005",
     "exception": false,
     "start_time": "2025-01-19T22:59:07.949428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parametri principali\n",
    "learning_rate = 5e-4\n",
    "EPOCHS = 4\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "\n",
    "# Creo i DataLoader\n",
    "train_loader = DataLoader(training_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(validation_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "\n",
    "# Funzione di loss\n",
    "criterion = torch.nn.BCEWithLogitsLoss() # Applica automaticamente la sigmoide\n",
    "\n",
    "# Ottimizzatore\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, lora_model.parameters()), lr = learning_rate)\n",
    "\n",
    "# Scheduler\n",
    "scheduler = transformers.get_linear_schedule_with_warmup(optimizer = optimizer,\n",
    "                                                       num_warmup_steps = 0,\n",
    "                                                       num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1dda2f02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T22:59:08.028546Z",
     "iopub.status.busy": "2025-01-19T22:59:08.028320Z",
     "iopub.status.idle": "2025-01-19T23:08:14.477205Z",
     "shell.execute_reply": "2025-01-19T23:08:14.476074Z"
    },
    "papermill": {
     "duration": 546.461255,
     "end_time": "2025-01-19T23:08:14.478787",
     "exception": false,
     "start_time": "2025-01-19T22:59:08.017532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "Train loss: 0.4022, Train accuracy: 0.8144\n",
      "Validation loss: 0.3351, Validation accuracy: 0.8580\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "Train loss: 0.3150, Train accuracy: 0.8626\n",
      "Validation loss: 0.3248, Validation accuracy: 0.8580\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "Train loss: 0.2919, Train accuracy: 0.8774\n",
      "Validation loss: 0.3186, Validation accuracy: 0.8660\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "Train loss: 0.2771, Train accuracy: 0.8855\n",
      "Validation loss: 0.3171, Validation accuracy: 0.8680\n",
      "BERT with LoRA Training Time: 546.44 seconds, 9.11 minutes.\n"
     ]
    }
   ],
   "source": [
    "history_lora, total_time_lora = train_and_evaluate_model(\n",
    "    lora_model,\"lora_model\", train_loader, val_loader, criterion, optimizer, scheduler, device, epochs=4\n",
    ")\n",
    "print(f\"BERT with LoRA Training Time: {total_time_lora:.2f} seconds, {total_time_lora/60:.2f} minutes.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b7a97a",
   "metadata": {
    "papermill": {
     "duration": 0.011356,
     "end_time": "2025-01-19T23:08:14.501515",
     "exception": false,
     "start_time": "2025-01-19T23:08:14.490159",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 4. Valutazione dei modelli\n",
    "Valuto i modello calcolando la loss sul test set, l'accuracy, l'F1-score e ROC AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "581e33f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T23:08:14.525035Z",
     "iopub.status.busy": "2025-01-19T23:08:14.524770Z",
     "iopub.status.idle": "2025-01-19T23:08:22.988985Z",
     "shell.execute_reply": "2025-01-19T23:08:22.988072Z"
    },
    "papermill": {
     "duration": 8.477755,
     "end_time": "2025-01-19T23:08:22.990542",
     "exception": false,
     "start_time": "2025-01-19T23:08:14.512787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-036bcb6f0380>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  full_model.load_state_dict(torch.load(\"imbd_best_full_model_state.bin\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fine-Tuning - Test loss: 0.3159, Accuracy: 0.8857, F1 score: 0.8856, ROC AUC: 0.9537\n"
     ]
    }
   ],
   "source": [
    "full_model.load_state_dict(torch.load(\"imbd_best_full_model_state.bin\"))\n",
    "\n",
    "test_loss, test_acc, test_f1, test_auc = eval_model(full_model, test_loader, criterion, device)\n",
    "print(f\"Full Fine-Tuning - Test loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}, F1 score: {test_f1:.4f}, ROC AUC: {test_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34460265",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T23:08:23.014568Z",
     "iopub.status.busy": "2025-01-19T23:08:23.014296Z",
     "iopub.status.idle": "2025-01-19T23:08:31.364958Z",
     "shell.execute_reply": "2025-01-19T23:08:31.363759Z"
    },
    "papermill": {
     "duration": 8.363748,
     "end_time": "2025-01-19T23:08:31.366321",
     "exception": false,
     "start_time": "2025-01-19T23:08:23.002573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-10f68d27c2db>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  lora_model.load_state_dict(torch.load(\"imbd_best_lora_model_state.bin\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA Fine-Tuning - Test loss: 0.3004, Accuracy: 0.8730, F1 score: 0.8730, ROC AUC: 0.9469\n"
     ]
    }
   ],
   "source": [
    "lora_model.load_state_dict(torch.load(\"imbd_best_lora_model_state.bin\"))\n",
    "\n",
    "lora_test_loss, lora_test_acc, lora_test_f1, lora_test_auc = eval_model(lora_model, test_loader, criterion, device)\n",
    "print(f\"LoRA Fine-Tuning - Test loss: {lora_test_loss:.4f}, Accuracy: {lora_test_acc:.4f}, F1 score: {lora_test_f1:.4f}, ROC AUC: {lora_test_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e497dbd",
   "metadata": {
    "papermill": {
     "duration": 0.010993,
     "end_time": "2025-01-19T23:08:31.388989",
     "exception": false,
     "start_time": "2025-01-19T23:08:31.377996",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Toxicity Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258cffb9",
   "metadata": {
    "papermill": {
     "duration": 0.010862,
     "end_time": "2025-01-19T23:08:31.411005",
     "exception": false,
     "start_time": "2025-01-19T23:08:31.400143",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1. Ottenimento dei dati e preprocessing  \n",
    "\n",
    "Confronto il fine-tuning completo e quello basato su LoRA sul task di classificazione multi-label utilizzando il dataset **Toxic Comment Classification**.  \n",
    "\n",
    "Il dataset contiene commenti testuali etichettati con sei classi: **toxic**, **severe_toxic**, **obscene**, **threat**, **insult**, e **identity_hate**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90672312",
   "metadata": {
    "papermill": {
     "duration": 0.010801,
     "end_time": "2025-01-19T23:08:31.432671",
     "exception": false,
     "start_time": "2025-01-19T23:08:31.421870",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Definisco una funzione per l'ottenimento dei dati e la loro divisione in training, validation e test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8087ccb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T23:08:31.455607Z",
     "iopub.status.busy": "2025-01-19T23:08:31.455339Z",
     "iopub.status.idle": "2025-01-19T23:08:31.458512Z",
     "shell.execute_reply": "2025-01-19T23:08:31.457837Z"
    },
    "papermill": {
     "duration": 0.016204,
     "end_time": "2025-01-19T23:08:31.459801",
     "exception": false,
     "start_time": "2025-01-19T23:08:31.443597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "N_CLASSES = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5531d09e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T23:08:31.482558Z",
     "iopub.status.busy": "2025-01-19T23:08:31.482329Z",
     "iopub.status.idle": "2025-01-19T23:08:31.487339Z",
     "shell.execute_reply": "2025-01-19T23:08:31.486680Z"
    },
    "papermill": {
     "duration": 0.01774,
     "end_time": "2025-01-19T23:08:31.488535",
     "exception": false,
     "start_time": "2025-01-19T23:08:31.470795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data(dataset_path, n_train=5000, n_val=500, n_test=1024): \n",
    "\n",
    "    # Leggo il dataset\n",
    "    dataset = pd.read_csv(dataset_path)\n",
    "\n",
    "    # Effettuo un mescolamento casuale dei dati\n",
    "    dataset = dataset.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    # Estraggo il testo e le etichette dal dataset\n",
    "    sentences = dataset[\"comment_text\"].fillna(\"null\").str.lower()\n",
    "    labels = dataset[classes].values.astype(np.float32)\n",
    "    \n",
    "    # Seleziono gli elementi da inserire nei set\n",
    "    train_sentences, train_labels = sentences[:n_train], labels[:n_train]\n",
    "    val_sentences, val_labels = sentences[n_train:n_train+n_val].reset_index(drop=True), labels[n_train:n_train+n_val]\n",
    "    test_sentences,test_labels = sentences[n_train+n_val:n_train+n_val+n_test].reset_index(drop=True), labels[n_train+n_val:n_train+n_val+n_test]\n",
    "\n",
    "    return train_sentences, train_labels, val_sentences, val_labels, test_sentences,test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4abe322",
   "metadata": {
    "papermill": {
     "duration": 0.01091,
     "end_time": "2025-01-19T23:08:31.510497",
     "exception": false,
     "start_time": "2025-01-19T23:08:31.499587",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Creo una classe Dataset personalizzata in cui viene effettuata la tokenizzaione delle recensioni e la conversione dei dati in tensori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc0bfa9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T23:08:31.533223Z",
     "iopub.status.busy": "2025-01-19T23:08:31.532980Z",
     "iopub.status.idle": "2025-01-19T23:08:31.538228Z",
     "shell.execute_reply": "2025-01-19T23:08:31.537375Z"
    },
    "papermill": {
     "duration": 0.018063,
     "end_time": "2025-01-19T23:08:31.539453",
     "exception": false,
     "start_time": "2025-01-19T23:08:31.521390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ToxicityDataset(Dataset):\n",
    "\n",
    "    def __init__(self, sentences, labels, tokenizer, max_len):\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sentence = self.sentences[index]\n",
    "        label = self.labels[index]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            sentence,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'token_type_ids': encoding[\"token_type_ids\"].flatten(),\n",
    "            'labels': torch.FloatTensor(label)\n",
    "        }     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d530ae",
   "metadata": {
    "papermill": {
     "duration": 0.010771,
     "end_time": "2025-01-19T23:08:31.561175",
     "exception": false,
     "start_time": "2025-01-19T23:08:31.550404",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Ottengo i dati grezzi, li divido in training, validation e test set con la funzione `get_data()`. Inizializzo il Tokenizer BERT per tokenizzare le frasi e creo i dataset personalizzati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd63f2c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T23:08:31.583850Z",
     "iopub.status.busy": "2025-01-19T23:08:31.583606Z",
     "iopub.status.idle": "2025-01-19T23:08:33.466449Z",
     "shell.execute_reply": "2025-01-19T23:08:33.465521Z"
    },
    "papermill": {
     "duration": 1.895855,
     "end_time": "2025-01-19T23:08:33.467964",
     "exception": false,
     "start_time": "2025-01-19T23:08:31.572109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "MAX_SEQ_LEN = 128\n",
    "\n",
    "# Ottengo i dati divisi in training set, validation set e test set\n",
    "dataset_path = \"/kaggle/input/toxisity-detection-dataset/train.csv\"\n",
    "\n",
    "train_sentences, train_labels, val_sentences, val_labels, test_sentences,test_labels = get_data(dataset_path)\n",
    "\n",
    "\n",
    "# Inizializzo il Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Ottengo i dataset\n",
    "train_dataset = ToxicityDataset(sentences = train_sentences,\n",
    "                                labels = train_labels, \n",
    "                                tokenizer = tokenizer, \n",
    "                                max_len = MAX_SEQ_LEN)\n",
    "\n",
    "validation_dataset = ToxicityDataset(sentences = val_sentences,\n",
    "                                labels = val_labels, \n",
    "                                tokenizer = tokenizer, \n",
    "                                max_len = MAX_SEQ_LEN)\n",
    "\n",
    "test_dataset = ToxicityDataset(sentences = test_sentences,\n",
    "                                labels = test_labels, \n",
    "                                tokenizer = tokenizer, \n",
    "                                max_len = MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3f3544",
   "metadata": {
    "papermill": {
     "duration": 0.011151,
     "end_time": "2025-01-19T23:08:33.490949",
     "exception": false,
     "start_time": "2025-01-19T23:08:33.479798",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Controllo che il caricamento dei dati sia avvenuto correttamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04df0d8",
   "metadata": {
    "papermill": {
     "duration": 0.010978,
     "end_time": "2025-01-19T23:08:33.513036",
     "exception": false,
     "start_time": "2025-01-19T23:08:33.502058",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 2. Configurazione dei modelli \n",
    "\n",
    "Definisco un classificatore basato su BERT per il task multi-label. Utilizzo il modello BERT pre-addestrato, seguito da un livello di dropout e un layer lineare con **N_CLASSES** neuroni di output. Se attivato, il modello integra LoRA per una fine-tuning efficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f71ab6a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T23:08:33.536286Z",
     "iopub.status.busy": "2025-01-19T23:08:33.535981Z",
     "iopub.status.idle": "2025-01-19T23:08:33.541359Z",
     "shell.execute_reply": "2025-01-19T23:08:33.540627Z"
    },
    "papermill": {
     "duration": 0.018712,
     "end_time": "2025-01-19T23:08:33.542768",
     "exception": false,
     "start_time": "2025-01-19T23:08:33.524056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "\n",
    "class BERTClassifierMultilabel(nn.Module):\n",
    "\n",
    "    def __init__(self, lora: bool = False, r: int = 16):\n",
    "        super(BERTClassifierMultilabel, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout = torch.nn.Dropout(p=0.3)\n",
    "        self.linear = torch.nn.Linear(self.bert.config.hidden_size, N_CLASSES)\n",
    "\n",
    "        if lora:\n",
    "            print(\"Adding LoRA to BERT\")\n",
    "            lora_utils.add_lora_to_bert(self.bert, r=r)\n",
    "            lora_utils.mark_only_lora_as_trainable(self.bert)\n",
    "\n",
    "\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output_bert = self.bert(\n",
    "            input_ids, \n",
    "            attention_mask=attention_mask, \n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        output_dropout = self.dropout(output_bert.pooler_output)\n",
    "        output = self.linear(output_dropout)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3ea10ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T23:08:33.575042Z",
     "iopub.status.busy": "2025-01-19T23:08:33.574769Z",
     "iopub.status.idle": "2025-01-19T23:08:33.578287Z",
     "shell.execute_reply": "2025-01-19T23:08:33.577466Z"
    },
    "papermill": {
     "duration": 0.019572,
     "end_time": "2025-01-19T23:08:33.579711",
     "exception": false,
     "start_time": "2025-01-19T23:08:33.560139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf7ad947",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T23:08:33.602927Z",
     "iopub.status.busy": "2025-01-19T23:08:33.602689Z",
     "iopub.status.idle": "2025-01-19T23:08:34.088597Z",
     "shell.execute_reply": "2025-01-19T23:08:34.087728Z"
    },
    "papermill": {
     "duration": 0.498956,
     "end_time": "2025-01-19T23:08:34.089961",
     "exception": false,
     "start_time": "2025-01-19T23:08:33.591005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERTClassifierMultilabel(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (linear): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODELLO STANDARD\n",
    "full_model = BERTClassifierMultilabel(lora=False)\n",
    "full_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42954b91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T23:08:34.114020Z",
     "iopub.status.busy": "2025-01-19T23:08:34.113767Z",
     "iopub.status.idle": "2025-01-19T23:08:34.745424Z",
     "shell.execute_reply": "2025-01-19T23:08:34.744567Z"
    },
    "papermill": {
     "duration": 0.645181,
     "end_time": "2025-01-19T23:08:34.746829",
     "exception": false,
     "start_time": "2025-01-19T23:08:34.101648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding LoRA to BERT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BERTClassifierMultilabel(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (linear): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODELLO CON LORA\n",
    "lora_model = BERTClassifierMultilabel(lora=True, r=16)\n",
    "lora_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fbb7cf",
   "metadata": {
    "papermill": {
     "duration": 0.011112,
     "end_time": "2025-01-19T23:08:34.769985",
     "exception": false,
     "start_time": "2025-01-19T23:08:34.758873",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3. Addestramento dei modelli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1749be53",
   "metadata": {
    "papermill": {
     "duration": 0.011453,
     "end_time": "2025-01-19T23:08:34.792616",
     "exception": false,
     "start_time": "2025-01-19T23:08:34.781163",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Definisco una serie di funzioni per l'addestramento e la valutazione di un modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d086ac6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T23:08:34.816432Z",
     "iopub.status.busy": "2025-01-19T23:08:34.816111Z",
     "iopub.status.idle": "2025-01-19T23:08:34.822246Z",
     "shell.execute_reply": "2025-01-19T23:08:34.821548Z"
    },
    "papermill": {
     "duration": 0.019685,
     "end_time": "2025-01-19T23:08:34.823641",
     "exception": false,
     "start_time": "2025-01-19T23:08:34.803956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "# Funzione di training e valutazione sul validation set\n",
    "\n",
    "def train_and_evaluate_model(model, model_name, train_loader, val_loader, criterion, optimizer, scheduler, device, epochs=4):\n",
    "\n",
    "    history = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "    best_accuracy = 0\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "        print('-' * 30)\n",
    "\n",
    "        # Training\n",
    "        train_loss, train_acc = train_model(model, train_loader, criterion, optimizer, scheduler, device)\n",
    "        print(f\"Train loss: {train_loss:.3f}, Train accuracy: {train_acc:.4f}\")\n",
    "\n",
    "        # Valutazione\n",
    "        val_loss, val_acc, val_f1, val_auc = eval_model(model, val_loader, criterion, device)\n",
    "        print(f\"Validation loss: {val_loss:.3f}, Validation accuracy: {val_acc:.3f}\")\n",
    "\n",
    "        # Salvataggio del modello migliore\n",
    "        if val_acc > best_accuracy:\n",
    "            torch.save(model.state_dict(),  f\"toxicity_best_{model_name}_state.bin\")\n",
    "            best_accuracy = val_acc\n",
    "\n",
    "        # Salvaggio delle metriche\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    total_training_time = end_time - start_time\n",
    "    \n",
    "    return history, total_training_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7feebb45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T23:08:34.847460Z",
     "iopub.status.busy": "2025-01-19T23:08:34.847194Z",
     "iopub.status.idle": "2025-01-19T23:08:34.853012Z",
     "shell.execute_reply": "2025-01-19T23:08:34.852340Z"
    },
    "papermill": {
     "duration": 0.019144,
     "end_time": "2025-01-19T23:08:34.854127",
     "exception": false,
     "start_time": "2025-01-19T23:08:34.834983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, data_loader, criterion, optimizer, scheduler, device):\n",
    "    \n",
    "    model.train()  # imposto il modello in modalità di aggiornamento\n",
    "\n",
    "    total_loss = 0 \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch in data_loader:\n",
    "        \n",
    "        # Sposto i dati sul device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # --- Forward pass ---\n",
    "        \n",
    "        # Azzero il gradiente\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Effettuo la previsione per il batch corrente\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids = token_type_ids\n",
    "        )\n",
    "        # output contiene i valori grezzi non normalizzati prodotti dal modello per ogni classe.\n",
    "        \n",
    "        # Calcolo la loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        \n",
    "        # --- Backward pass ---\n",
    "\n",
    "        # Calcolo i gradienti della loss\n",
    "        loss.backward()\n",
    "\n",
    "        # Effettuo il clipping dei gradienti\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        # Aggiorno i pesi\n",
    "        optimizer.step()\n",
    "\n",
    "        # Aggiorno il learning rate\n",
    "        scheduler.step()\n",
    "\n",
    "        \n",
    "        # Salvo la loss, le previsioni e le etichette\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        preds = (torch.sigmoid(outputs) > 0.5).long() #  trasformo i dati grezzi in etichette binarie\n",
    "\n",
    "        all_preds.extend(preds.detach().cpu().numpy()) # disconnetto il tensore dalla computazione del gradiente, lo sposto sulla cpu, lo trasformo in array numpy e aggiungo il risultato a all_preds\n",
    "        all_labels.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "\n",
    "    # Calcolo la loss e le metriche\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99529182",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T23:08:34.877502Z",
     "iopub.status.busy": "2025-01-19T23:08:34.877210Z",
     "iopub.status.idle": "2025-01-19T23:08:34.883252Z",
     "shell.execute_reply": "2025-01-19T23:08:34.882434Z"
    },
    "papermill": {
     "duration": 0.019002,
     "end_time": "2025-01-19T23:08:34.884498",
     "exception": false,
     "start_time": "2025-01-19T23:08:34.865496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, criterion, device):\n",
    "\n",
    "    model.eval()   # imposto il modello in modalità valutavione\n",
    "\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "\n",
    "            # Sposto i dati sul device\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            token_type_ids = batch['token_type_ids'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            # Effettuo la previsione per il batch corrente\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids = token_type_ids\n",
    "            )\n",
    "            \n",
    "            # Calcolo la loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Aggiorno la loss, e salvo le previsioni le etichette\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "            probs = torch.sigmoid(outputs)  # Calcolo le probabilità\n",
    "\n",
    "            preds = (probs > 0.5).long()  # Trasformo in etichette binarie\n",
    "            \n",
    "            all_preds.extend(preds.detach().cpu().numpy())\n",
    "            all_labels.extend(labels.detach().cpu().numpy())\n",
    "            all_probs.extend(probs.detach().cpu().numpy())\n",
    "\n",
    "        # Calcolo loss e metriche\n",
    "        avg_loss = total_loss / len(data_loader)\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n",
    "        roc_auc = roc_auc_score(all_labels, all_probs, average='weighted', multi_class='ovr')\n",
    "    \n",
    "    return avg_loss, accuracy, f1, roc_auc\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b133906f",
   "metadata": {
    "papermill": {
     "duration": 0.011202,
     "end_time": "2025-01-19T23:08:34.908340",
     "exception": false,
     "start_time": "2025-01-19T23:08:34.897138",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Definisco le configurazion principali per il training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b70d274",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T23:08:34.931929Z",
     "iopub.status.busy": "2025-01-19T23:08:34.931705Z",
     "iopub.status.idle": "2025-01-19T23:08:34.938038Z",
     "shell.execute_reply": "2025-01-19T23:08:34.937466Z"
    },
    "papermill": {
     "duration": 0.019641,
     "end_time": "2025-01-19T23:08:34.939213",
     "exception": false,
     "start_time": "2025-01-19T23:08:34.919572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parametri principali\n",
    "learning_rate = 3e-5\n",
    "EPOCHS = 4\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "\n",
    "# Creo i DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "\n",
    "\n",
    "# Funzione di loss\n",
    "criterion = torch.nn.BCEWithLogitsLoss() # Applica automaticamente la sigmoide\n",
    "\n",
    "\n",
    "# Ottimizzatore\n",
    "optimizer = torch.optim.AdamW(params = full_model.parameters(), lr = learning_rate)\n",
    "\n",
    "# Scheduler\n",
    "scheduler = transformers.get_linear_schedule_with_warmup(optimizer = optimizer,\n",
    "                                                       num_warmup_steps = 0,\n",
    "                                                       num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bceaba95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T23:08:34.962862Z",
     "iopub.status.busy": "2025-01-19T23:08:34.962621Z",
     "iopub.status.idle": "2025-01-19T23:14:51.668510Z",
     "shell.execute_reply": "2025-01-19T23:14:51.667553Z"
    },
    "papermill": {
     "duration": 376.719395,
     "end_time": "2025-01-19T23:14:51.670074",
     "exception": false,
     "start_time": "2025-01-19T23:08:34.950679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/4\n",
      "------------------------------\n",
      "Train loss: 0.107, Train accuracy: 0.8962\n",
      "Validation loss: 0.048, Validation accuracy: 0.929\n",
      "\n",
      "Epoch 2/4\n",
      "------------------------------\n",
      "Train loss: 0.046, Train accuracy: 0.9274\n",
      "Validation loss: 0.034, Validation accuracy: 0.948\n",
      "\n",
      "Epoch 3/4\n",
      "------------------------------\n",
      "Train loss: 0.034, Train accuracy: 0.9440\n",
      "Validation loss: 0.026, Validation accuracy: 0.959\n",
      "\n",
      "Epoch 4/4\n",
      "------------------------------\n",
      "Train loss: 0.027, Train accuracy: 0.9582\n",
      "Validation loss: 0.025, Validation accuracy: 0.969\n",
      "\n",
      "BERT Training Time: 376.70 seconds, 6.28 minutes.\n"
     ]
    }
   ],
   "source": [
    "history_bert, total_time_bert = train_and_evaluate_model(\n",
    "    full_model, \"full_model\", train_loader, train_loader, criterion, optimizer, scheduler, device, epochs=4\n",
    ")\n",
    "print(f\"\\nBERT Training Time: {total_time_bert:.2f} seconds, {total_time_bert/60:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ac25ff69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T23:14:51.695995Z",
     "iopub.status.busy": "2025-01-19T23:14:51.695731Z",
     "iopub.status.idle": "2025-01-19T23:14:51.703565Z",
     "shell.execute_reply": "2025-01-19T23:14:51.702678Z"
    },
    "papermill": {
     "duration": 0.022189,
     "end_time": "2025-01-19T23:14:51.704770",
     "exception": false,
     "start_time": "2025-01-19T23:14:51.682581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parametri principali\n",
    "learning_rate = 5e-4\n",
    "EPOCHS = 6\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Creo i DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "\n",
    "\n",
    "# Funzione di loss\n",
    "criterion = torch.nn.BCEWithLogitsLoss() # Applica automaticamente la sigmoide\n",
    "\n",
    "# Ottimizzatore\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, lora_model.parameters()), lr = learning_rate)\n",
    "\n",
    "# Scheduler\n",
    "scheduler = transformers.get_linear_schedule_with_warmup(optimizer = optimizer,\n",
    "                                                       num_warmup_steps = 0,\n",
    "                                                       num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c318aec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T23:14:51.729916Z",
     "iopub.status.busy": "2025-01-19T23:14:51.729661Z",
     "iopub.status.idle": "2025-01-19T23:20:02.676200Z",
     "shell.execute_reply": "2025-01-19T23:20:02.675345Z"
    },
    "papermill": {
     "duration": 310.961079,
     "end_time": "2025-01-19T23:20:02.677662",
     "exception": false,
     "start_time": "2025-01-19T23:14:51.716583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/6\n",
      "------------------------------\n",
      "Train loss: 0.114, Train accuracy: 0.8936\n",
      "Validation loss: 0.073, Validation accuracy: 0.894\n",
      "\n",
      "Epoch 2/6\n",
      "------------------------------\n",
      "Train loss: 0.059, Train accuracy: 0.9104\n",
      "Validation loss: 0.065, Validation accuracy: 0.894\n",
      "\n",
      "Epoch 3/6\n",
      "------------------------------\n",
      "Train loss: 0.051, Train accuracy: 0.9156\n",
      "Validation loss: 0.065, Validation accuracy: 0.896\n",
      "\n",
      "Epoch 4/6\n",
      "------------------------------\n",
      "Train loss: 0.046, Train accuracy: 0.9210\n",
      "Validation loss: 0.065, Validation accuracy: 0.888\n",
      "\n",
      "Epoch 5/6\n",
      "------------------------------\n",
      "Train loss: 0.043, Train accuracy: 0.9254\n",
      "Validation loss: 0.065, Validation accuracy: 0.892\n",
      "\n",
      "Epoch 6/6\n",
      "------------------------------\n",
      "Train loss: 0.041, Train accuracy: 0.9274\n",
      "Validation loss: 0.065, Validation accuracy: 0.888\n",
      "BERT with LoRA Training Time: 310.94 seconds, 5.18 minutes.\n"
     ]
    }
   ],
   "source": [
    "history_lora, total_time_lora = train_and_evaluate_model(\n",
    "    lora_model,\"lora_model\", train_loader, val_loader, criterion, optimizer, scheduler, device, epochs=EPOCHS\n",
    ")\n",
    "print(f\"BERT with LoRA Training Time: {total_time_lora:.2f} seconds, {total_time_lora/60:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c42f37",
   "metadata": {
    "papermill": {
     "duration": 0.013366,
     "end_time": "2025-01-19T23:20:02.704231",
     "exception": false,
     "start_time": "2025-01-19T23:20:02.690865",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 4. Valutazione dei modelli\n",
    "Valuto i modello calcolando la loss sul test set, l'accuracy, l'F1-score e ROC AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b781a3ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T23:20:02.731298Z",
     "iopub.status.busy": "2025-01-19T23:20:02.731004Z",
     "iopub.status.idle": "2025-01-19T23:20:08.064827Z",
     "shell.execute_reply": "2025-01-19T23:20:08.063799Z"
    },
    "papermill": {
     "duration": 5.349037,
     "end_time": "2025-01-19T23:20:08.066232",
     "exception": false,
     "start_time": "2025-01-19T23:20:02.717195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-38-5adac543eef7>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  full_model.load_state_dict(torch.load(\"toxicity_best_full_model_state.bin\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Fine-Tuning - Test loss: 0.0646, Accuracy: 0.9062, F1 score: 0.7164, ROC AUC: 0.9785\n"
     ]
    }
   ],
   "source": [
    "full_model.load_state_dict(torch.load(\"toxicity_best_full_model_state.bin\"))\n",
    "\n",
    "test_loss, test_acc, test_f1, test_auc = eval_model(full_model, test_loader, criterion, device)\n",
    "print(f\"Full Fine-Tuning - Test loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}, F1 score: {test_f1:.4f}, ROC AUC: {test_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4873c378",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T23:20:08.095409Z",
     "iopub.status.busy": "2025-01-19T23:20:08.095135Z",
     "iopub.status.idle": "2025-01-19T23:20:13.412879Z",
     "shell.execute_reply": "2025-01-19T23:20:13.411976Z"
    },
    "papermill": {
     "duration": 5.332594,
     "end_time": "2025-01-19T23:20:13.414211",
     "exception": false,
     "start_time": "2025-01-19T23:20:08.081617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-39-d1c6458ef167>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  lora_model.load_state_dict(torch.load(\"toxicity_best_lora_model_state.bin\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA Fine-Tuning - Test loss: 0.0621, Accuracy: 0.9082, F1 score: 0.7009, ROC AUC: 0.9739\n"
     ]
    }
   ],
   "source": [
    "lora_model.load_state_dict(torch.load(\"toxicity_best_lora_model_state.bin\"))\n",
    "\n",
    "lora_test_loss, lora_test_acc, lora_test_f1, lora_test_auc = eval_model(lora_model, test_loader, criterion, device)\n",
    "print(f\"LoRA Fine-Tuning - Test loss: {lora_test_loss:.4f}, Accuracy: {lora_test_acc:.4f}, F1 score: {lora_test_f1:.4f}, ROC AUC: {lora_test_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269267f2",
   "metadata": {
    "papermill": {
     "duration": 0.012919,
     "end_time": "2025-01-19T23:20:13.440523",
     "exception": false,
     "start_time": "2025-01-19T23:20:13.427604",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a href=\"/kaggle/working/imbd_best_lora_model_state.bin\"> Download File </a>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25227e46",
   "metadata": {
    "papermill": {
     "duration": 0.012737,
     "end_time": "2025-01-19T23:20:13.466116",
     "exception": false,
     "start_time": "2025-01-19T23:20:13.453379",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 134715,
     "sourceId": 320111,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6274971,
     "sourceId": 10161839,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6451663,
     "sourceId": 10410576,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1955.51623,
   "end_time": "2025-01-19T23:20:15.103666",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-19T22:47:39.587436",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "042cec451ddd4f1eb0d9f242bcc2d7b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "09941eb778fe441e8ba339f774abd19e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_37f725292d5743688fc019bf00b9c2ee",
       "max": 466062.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_55bc71dcd3144501a6e095baaabe8ea2",
       "tabbable": null,
       "tooltip": null,
       "value": 466062.0
      }
     },
     "0ed78b790c524da3a735d64aa935a85c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "133d6d922df94912b1ed0bdaff9b10ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1465d2b1622a4d34aa986789ae8c9ab2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1e5259059e064a838a4e74fb6e35d358": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "283eb040640f4b62b530aa3901d64db8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "28a7391080694d8690710bce772544f3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "28c600f0c33b4681a7ad55d3114ca542": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "306ee8a1a19b453498094660d4d1e530": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "307fcdd3fa404d9c9731bec04bbac63c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "34fd8611908147feb28b444301c12ecd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4262dd20ed3342599d7bdedfe96cc72a",
       "max": 48.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9024b09eb6c04d8598651958d534231b",
       "tabbable": null,
       "tooltip": null,
       "value": 48.0
      }
     },
     "37f725292d5743688fc019bf00b9c2ee": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3c38bc435e954f9d917bb0411e3098ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d309050bf9fc4243aa6f28b202614f89",
       "placeholder": "​",
       "style": "IPY_MODEL_306ee8a1a19b453498094660d4d1e530",
       "tabbable": null,
       "tooltip": null,
       "value": " 232k/232k [00:00&lt;00:00, 3.78MB/s]"
      }
     },
     "3ddbecfb87f84c82b770096234b5c511": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "407ce1609bb8474197247c5aa3f1dcf8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4262dd20ed3342599d7bdedfe96cc72a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "469a1caa8ddd45a1b9a4dea11f5f4990": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4a7cf3f403d343c1a9d6bfa3b1013135": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4d7c7142376847139affd4eff6ce2a99": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_28a7391080694d8690710bce772544f3",
       "placeholder": "​",
       "style": "IPY_MODEL_407ce1609bb8474197247c5aa3f1dcf8",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer.json: 100%"
      }
     },
     "4fa22da9510b4e8caebd40699e3ebde5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ab5ecf44b3cd459f85a4d81438b9c433",
       "placeholder": "​",
       "style": "IPY_MODEL_52f0ce71e46444b28545d42fe2f5af92",
       "tabbable": null,
       "tooltip": null,
       "value": " 440M/440M [00:01&lt;00:00, 247MB/s]"
      }
     },
     "51f8e57c7faa4fb5b3f5bd845fca4216": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_99d2b0e92b25479a939860927a634431",
       "placeholder": "​",
       "style": "IPY_MODEL_133d6d922df94912b1ed0bdaff9b10ef",
       "tabbable": null,
       "tooltip": null,
       "value": " 466k/466k [00:00&lt;00:00, 7.58MB/s]"
      }
     },
     "52f0ce71e46444b28545d42fe2f5af92": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "55bc71dcd3144501a6e095baaabe8ea2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5cfc58b69e134f889149ce34995c07ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_307fcdd3fa404d9c9731bec04bbac63c",
       "max": 231508.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7744e1bf230b446ba0f76f3d7f85cfa9",
       "tabbable": null,
       "tooltip": null,
       "value": 231508.0
      }
     },
     "5eb9b50665984e7781e1f178f57252f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6710abf8a40a49a7901ffb32fb316f73",
       "placeholder": "​",
       "style": "IPY_MODEL_042cec451ddd4f1eb0d9f242bcc2d7b8",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "5f2bea3fada348348cc93c9e9450c087": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "600eb3ae763f4b2494569e6a4dc242b1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7803cd6bc39c4fbd8f89df95cdb1ca62",
        "IPY_MODEL_5cfc58b69e134f889149ce34995c07ba",
        "IPY_MODEL_3c38bc435e954f9d917bb0411e3098ee"
       ],
       "layout": "IPY_MODEL_a0358afda1df40ddaab83b3677c8a822",
       "tabbable": null,
       "tooltip": null
      }
     },
     "61029a4ed71e4e53ba0a6efa9dfa8c49": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4d7c7142376847139affd4eff6ce2a99",
        "IPY_MODEL_09941eb778fe441e8ba339f774abd19e",
        "IPY_MODEL_51f8e57c7faa4fb5b3f5bd845fca4216"
       ],
       "layout": "IPY_MODEL_5f2bea3fada348348cc93c9e9450c087",
       "tabbable": null,
       "tooltip": null
      }
     },
     "6710abf8a40a49a7901ffb32fb316f73": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7744e1bf230b446ba0f76f3d7f85cfa9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "77ecac6cd59c4a6f9511f4d0a0a21196": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7803cd6bc39c4fbd8f89df95cdb1ca62": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_841359dd449e4286b74205fa60f095bc",
       "placeholder": "​",
       "style": "IPY_MODEL_77ecac6cd59c4a6f9511f4d0a0a21196",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt: 100%"
      }
     },
     "841359dd449e4286b74205fa60f095bc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8a82e08f287e4e7e894139502759c7d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_97e378f757104031b6212a2b93caa7eb",
        "IPY_MODEL_c65fb636005a489a9cb951e2e0ed8002",
        "IPY_MODEL_f43fa58012f24131922bf350d5f56c92"
       ],
       "layout": "IPY_MODEL_283eb040640f4b62b530aa3901d64db8",
       "tabbable": null,
       "tooltip": null
      }
     },
     "9024b09eb6c04d8598651958d534231b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "92a006fcb76c4648b81242d2c960eac4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5eb9b50665984e7781e1f178f57252f2",
        "IPY_MODEL_a2f456193e5840efb4152342b886a4fc",
        "IPY_MODEL_4fa22da9510b4e8caebd40699e3ebde5"
       ],
       "layout": "IPY_MODEL_b757d13023e742ecb5ad17f7760e50c8",
       "tabbable": null,
       "tooltip": null
      }
     },
     "97e378f757104031b6212a2b93caa7eb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3ddbecfb87f84c82b770096234b5c511",
       "placeholder": "​",
       "style": "IPY_MODEL_4a7cf3f403d343c1a9d6bfa3b1013135",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "99d2b0e92b25479a939860927a634431": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9b0fc9c109f240229c0b4cff1083ee8d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a0358afda1df40ddaab83b3677c8a822": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a2f456193e5840efb4152342b886a4fc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f283f22fb803436b93dcfcb3226c737b",
       "max": 440449768.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b2cf5a1cbe1e4fb3b08b1287bacb5f6d",
       "tabbable": null,
       "tooltip": null,
       "value": 440449768.0
      }
     },
     "ab5ecf44b3cd459f85a4d81438b9c433": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b2cf5a1cbe1e4fb3b08b1287bacb5f6d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b757d13023e742ecb5ad17f7760e50c8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b9b383715c0b4a849b0f5e8cc299a33b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9b0fc9c109f240229c0b4cff1083ee8d",
       "placeholder": "​",
       "style": "IPY_MODEL_1465d2b1622a4d34aa986789ae8c9ab2",
       "tabbable": null,
       "tooltip": null,
       "value": " 48.0/48.0 [00:00&lt;00:00, 4.40kB/s]"
      }
     },
     "bdca1cdc6c894b8e8d8ee536bd8d0c64": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c65fb636005a489a9cb951e2e0ed8002": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0ed78b790c524da3a735d64aa935a85c",
       "max": 570.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1e5259059e064a838a4e74fb6e35d358",
       "tabbable": null,
       "tooltip": null,
       "value": 570.0
      }
     },
     "cb650d6edc9d4060b54bf8a5fffaf2c6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d309050bf9fc4243aa6f28b202614f89": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d71ea3d5141f4c6d8430acb98d946174": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e6502cf67fe64b268abc84bd11c3a020": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_fbdf642845a54e1a8867fc84b6eb3afc",
        "IPY_MODEL_34fd8611908147feb28b444301c12ecd",
        "IPY_MODEL_b9b383715c0b4a849b0f5e8cc299a33b"
       ],
       "layout": "IPY_MODEL_d71ea3d5141f4c6d8430acb98d946174",
       "tabbable": null,
       "tooltip": null
      }
     },
     "f283f22fb803436b93dcfcb3226c737b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f43fa58012f24131922bf350d5f56c92": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_28c600f0c33b4681a7ad55d3114ca542",
       "placeholder": "​",
       "style": "IPY_MODEL_bdca1cdc6c894b8e8d8ee536bd8d0c64",
       "tabbable": null,
       "tooltip": null,
       "value": " 570/570 [00:00&lt;00:00, 64.1kB/s]"
      }
     },
     "fbdf642845a54e1a8867fc84b6eb3afc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_469a1caa8ddd45a1b9a4dea11f5f4990",
       "placeholder": "​",
       "style": "IPY_MODEL_cb650d6edc9d4060b54bf8a5fffaf2c6",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
